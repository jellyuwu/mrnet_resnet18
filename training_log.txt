Starting Meniscus Axial Training...
[SEED] Setting seeds for reproducibility...
src/models-to-submit/pretrained
[TRAIN] Creating logs folder: "./logs/20250310-231111_meniscus_axial"
[TRAIN] Loading Data Loaders
[DATALOADER] __init__ task: meniscus, plane: axial, train: train
[DATALOADER] __init__ weights: [1, 1.8463476070528968]
[DATALOADER] __init__ task: meniscus, plane: axial, train: valid
[DATALOADER] __init__ weights: [1, 1.3076923076923077]
[TRAIN] Instantiate Model
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[TRAIN] Defining Optimizer
[TRAIN] Starting Training!
[TRAIN] Epochs = 200
[TRAIN] EPOCH # 1
[TRAIN] Train model
Epoch [1 / 200] Step: [100 / 1130] avg_train_loss: 1.0018 | train_auc: 0.406 | lr : 1e-05
Epoch [1 / 200] Step: [200 / 1130] avg_train_loss: 0.9671 | train_auc: 0.4666 | lr : 1e-05
Epoch [1 / 200] Step: [300 / 1130] avg_train_loss: 0.9571 | train_auc: 0.4715 | lr : 1e-05
Epoch [1 / 200] Step: [400 / 1130] avg_train_loss: 0.9384 | train_auc: 0.5154 | lr : 1e-05
Epoch [1 / 200] Step: [500 / 1130] avg_train_loss: 0.9395 | train_auc: 0.5024 | lr : 1e-05
Epoch [1 / 200] Step: [600 / 1130] avg_train_loss: 0.9309 | train_auc: 0.5245 | lr : 1e-05
Epoch [1 / 200] Step: [700 / 1130] avg_train_loss: 0.9256 | train_auc: 0.5321 | lr : 1e-05
Epoch [1 / 200] Step: [800 / 1130] avg_train_loss: 0.92 | train_auc: 0.5391 | lr : 1e-05
Epoch [1 / 200] Step: [900 / 1130] avg_train_loss: 0.9147 | train_auc: 0.544 | lr : 1e-05
Epoch [1 / 200] Step: [1000 / 1130] avg_train_loss: 0.9135 | train_auc: 0.5425 | lr : 1e-05
Epoch [1 / 200] Step: [1100 / 1130] avg_train_loss: 0.9152 | train_auc: 0.5437 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 1 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.6287 | val_auc: nan | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.6371 | val_auc: nan | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6819 | val_auc: 0.6429 | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.7166 | val_auc: 0.6469 | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7388 | val_auc: 0.6582 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.5426_val_auc_0.6708_train_loss_0.9150_val_loss_0.7635_epoch_1_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 2
[TRAIN] Train model
Epoch [2 / 200] Step: [100 / 1130] avg_train_loss: 0.8487 | train_auc: 0.7364 | lr : 1e-05
Epoch [2 / 200] Step: [200 / 1130] avg_train_loss: 0.8552 | train_auc: 0.6978 | lr : 1e-05
Epoch [2 / 200] Step: [300 / 1130] avg_train_loss: 0.8664 | train_auc: 0.6799 | lr : 1e-05
Epoch [2 / 200] Step: [400 / 1130] avg_train_loss: 0.8675 | train_auc: 0.6568 | lr : 1e-05
Epoch [2 / 200] Step: [500 / 1130] avg_train_loss: 0.8677 | train_auc: 0.6563 | lr : 1e-05
Epoch [2 / 200] Step: [600 / 1130] avg_train_loss: 0.8736 | train_auc: 0.6464 | lr : 1e-05
Epoch [2 / 200] Step: [700 / 1130] avg_train_loss: 0.8821 | train_auc: 0.6368 | lr : 1e-05
Epoch [2 / 200] Step: [800 / 1130] avg_train_loss: 0.8809 | train_auc: 0.6402 | lr : 1e-05
Epoch [2 / 200] Step: [900 / 1130] avg_train_loss: 0.8768 | train_auc: 0.6437 | lr : 1e-05
Epoch [2 / 200] Step: [1000 / 1130] avg_train_loss: 0.8757 | train_auc: 0.6424 | lr : 1e-05
Epoch [2 / 200] Step: [1100 / 1130] avg_train_loss: 0.8722 | train_auc: 0.6447 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 2 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.4779 | val_auc: nan | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.5077 | val_auc: nan | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6069 | val_auc: 0.3307 | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6654 | val_auc: 0.5832 | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7114 | val_auc: 0.6408 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.6432_val_auc_0.6725_train_loss_0.8712_val_loss_0.7631_epoch_2_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 3
[TRAIN] Train model
Epoch [3 / 200] Step: [100 / 1130] avg_train_loss: 0.8051 | train_auc: 0.7547 | lr : 1e-05
Epoch [3 / 200] Step: [200 / 1130] avg_train_loss: 0.8508 | train_auc: 0.6952 | lr : 1e-05
Epoch [3 / 200] Step: [300 / 1130] avg_train_loss: 0.8262 | train_auc: 0.7371 | lr : 1e-05
Epoch [3 / 200] Step: [400 / 1130] avg_train_loss: 0.8272 | train_auc: 0.7306 | lr : 1e-05
Epoch [3 / 200] Step: [500 / 1130] avg_train_loss: 0.8291 | train_auc: 0.7276 | lr : 1e-05
Epoch [3 / 200] Step: [600 / 1130] avg_train_loss: 0.8229 | train_auc: 0.737 | lr : 1e-05
Epoch [3 / 200] Step: [700 / 1130] avg_train_loss: 0.8208 | train_auc: 0.7299 | lr : 1e-05
Epoch [3 / 200] Step: [800 / 1130] avg_train_loss: 0.8171 | train_auc: 0.7327 | lr : 1e-05
Epoch [3 / 200] Step: [900 / 1130] avg_train_loss: 0.8138 | train_auc: 0.7293 | lr : 1e-05
Epoch [3 / 200] Step: [1000 / 1130] avg_train_loss: 0.804 | train_auc: 0.7371 | lr : 1e-05
Epoch [3 / 200] Step: [1100 / 1130] avg_train_loss: 0.8027 | train_auc: 0.7359 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 3 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.5891 | val_auc: nan | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.624 | val_auc: nan | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6896 | val_auc: 0.537 | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.7165 | val_auc: 0.6681 | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7014 | val_auc: 0.7201 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.7387_val_auc_0.7178_train_loss_0.8012_val_loss_0.7066_epoch_3_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 4
[TRAIN] Train model
Epoch [4 / 200] Step: [100 / 1130] avg_train_loss: 0.7929 | train_auc: 0.6803 | lr : 1e-05
Epoch [4 / 200] Step: [200 / 1130] avg_train_loss: 0.7871 | train_auc: 0.69 | lr : 1e-05
Epoch [4 / 200] Step: [300 / 1130] avg_train_loss: 0.7825 | train_auc: 0.6989 | lr : 1e-05
Epoch [4 / 200] Step: [400 / 1130] avg_train_loss: 0.7727 | train_auc: 0.7203 | lr : 1e-05
Epoch [4 / 200] Step: [500 / 1130] avg_train_loss: 0.7742 | train_auc: 0.732 | lr : 1e-05
Epoch [4 / 200] Step: [600 / 1130] avg_train_loss: 0.7811 | train_auc: 0.7288 | lr : 1e-05
Epoch [4 / 200] Step: [700 / 1130] avg_train_loss: 0.7848 | train_auc: 0.7312 | lr : 1e-05
Epoch [4 / 200] Step: [800 / 1130] avg_train_loss: 0.781 | train_auc: 0.7359 | lr : 1e-05
Epoch [4 / 200] Step: [900 / 1130] avg_train_loss: 0.7881 | train_auc: 0.7342 | lr : 1e-05
Epoch [4 / 200] Step: [1000 / 1130] avg_train_loss: 0.7901 | train_auc: 0.7382 | lr : 1e-05
Epoch [4 / 200] Step: [1100 / 1130] avg_train_loss: 0.7837 | train_auc: 0.7494 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 4 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3924 | val_auc: nan | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.4018 | val_auc: nan | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5378 | val_auc: 0.3889 | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6229 | val_auc: 0.6239 | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6694 | val_auc: 0.7014 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 5
[TRAIN] Train model
Epoch [5 / 200] Step: [100 / 1130] avg_train_loss: 0.7326 | train_auc: 0.8074 | lr : 1e-05
Epoch [5 / 200] Step: [200 / 1130] avg_train_loss: 0.7249 | train_auc: 0.8003 | lr : 1e-05
Epoch [5 / 200] Step: [300 / 1130] avg_train_loss: 0.7135 | train_auc: 0.8074 | lr : 1e-05
Epoch [5 / 200] Step: [400 / 1130] avg_train_loss: 0.7358 | train_auc: 0.7895 | lr : 1e-05
Epoch [5 / 200] Step: [500 / 1130] avg_train_loss: 0.7337 | train_auc: 0.7919 | lr : 1e-05
Epoch [5 / 200] Step: [600 / 1130] avg_train_loss: 0.7248 | train_auc: 0.7996 | lr : 1e-05
Epoch [5 / 200] Step: [700 / 1130] avg_train_loss: 0.7212 | train_auc: 0.8029 | lr : 1e-05
Epoch [5 / 200] Step: [800 / 1130] avg_train_loss: 0.7148 | train_auc: 0.8083 | lr : 1e-05
Epoch [5 / 200] Step: [900 / 1130] avg_train_loss: 0.7021 | train_auc: 0.8189 | lr : 1e-05
Epoch [5 / 200] Step: [1000 / 1130] avg_train_loss: 0.6997 | train_auc: 0.8226 | lr : 1e-05
Epoch [5 / 200] Step: [1100 / 1130] avg_train_loss: 0.7063 | train_auc: 0.8168 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 5 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.419 | val_auc: nan | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.4466 | val_auc: nan | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5545 | val_auc: 0.7302 | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6195 | val_auc: 0.7292 | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6243 | val_auc: 0.7772 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.8195_val_auc_0.7605_train_loss_0.7035_val_loss_0.6648_epoch_5_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 6
[TRAIN] Train model
Epoch [6 / 200] Step: [100 / 1130] avg_train_loss: 0.7478 | train_auc: 0.7919 | lr : 1e-05
Epoch [6 / 200] Step: [200 / 1130] avg_train_loss: 0.7397 | train_auc: 0.7875 | lr : 1e-05
Epoch [6 / 200] Step: [300 / 1130] avg_train_loss: 0.6955 | train_auc: 0.8256 | lr : 1e-05
Epoch [6 / 200] Step: [400 / 1130] avg_train_loss: 0.679 | train_auc: 0.8355 | lr : 1e-05
Epoch [6 / 200] Step: [500 / 1130] avg_train_loss: 0.6579 | train_auc: 0.8466 | lr : 1e-05
Epoch [6 / 200] Step: [600 / 1130] avg_train_loss: 0.6491 | train_auc: 0.8495 | lr : 1e-05
Epoch [6 / 200] Step: [700 / 1130] avg_train_loss: 0.6547 | train_auc: 0.8483 | lr : 1e-05
Epoch [6 / 200] Step: [800 / 1130] avg_train_loss: 0.6624 | train_auc: 0.8383 | lr : 1e-05
Epoch [6 / 200] Step: [900 / 1130] avg_train_loss: 0.6783 | train_auc: 0.8274 | lr : 1e-05
Epoch [6 / 200] Step: [1000 / 1130] avg_train_loss: 0.6802 | train_auc: 0.8255 | lr : 1e-05
Epoch [6 / 200] Step: [1100 / 1130] avg_train_loss: 0.6751 | train_auc: 0.8283 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 6 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3394 | val_auc: nan | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.355 | val_auc: nan | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4785 | val_auc: 0.7857 | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5626 | val_auc: 0.7878 | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5637 | val_auc: 0.8235 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.8272_val_auc_0.7930_train_loss_0.6769_val_loss_0.6359_epoch_6_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 7
[TRAIN] Train model
Epoch [7 / 200] Step: [100 / 1130] avg_train_loss: 0.6815 | train_auc: 0.8435 | lr : 1e-05
Epoch [7 / 200] Step: [200 / 1130] avg_train_loss: 0.6329 | train_auc: 0.8664 | lr : 1e-05
Epoch [7 / 200] Step: [300 / 1130] avg_train_loss: 0.6582 | train_auc: 0.8518 | lr : 1e-05
Epoch [7 / 200] Step: [400 / 1130] avg_train_loss: 0.6312 | train_auc: 0.8652 | lr : 1e-05
Epoch [7 / 200] Step: [500 / 1130] avg_train_loss: 0.6308 | train_auc: 0.8635 | lr : 1e-05
Epoch [7 / 200] Step: [600 / 1130] avg_train_loss: 0.6154 | train_auc: 0.8706 | lr : 1e-05
Epoch [7 / 200] Step: [700 / 1130] avg_train_loss: 0.6221 | train_auc: 0.8638 | lr : 1e-05
Epoch [7 / 200] Step: [800 / 1130] avg_train_loss: 0.6009 | train_auc: 0.8745 | lr : 1e-05
Epoch [7 / 200] Step: [900 / 1130] avg_train_loss: 0.6206 | train_auc: 0.862 | lr : 1e-05
Epoch [7 / 200] Step: [1000 / 1130] avg_train_loss: 0.6205 | train_auc: 0.8619 | lr : 1e-05
Epoch [7 / 200] Step: [1100 / 1130] avg_train_loss: 0.6209 | train_auc: 0.8618 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 7 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.229 | val_auc: nan | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2262 | val_auc: nan | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4081 | val_auc: 0.7831 | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.544 | val_auc: 0.8175 | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5982 | val_auc: 0.8289 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.8635_val_auc_0.8148_train_loss_0.6186_val_loss_0.7181_epoch_7_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 8
[TRAIN] Train model
Epoch [8 / 200] Step: [100 / 1130] avg_train_loss: 0.5717 | train_auc: 0.8699 | lr : 1e-05
Epoch [8 / 200] Step: [200 / 1130] avg_train_loss: 0.5628 | train_auc: 0.8833 | lr : 1e-05
Epoch [8 / 200] Step: [300 / 1130] avg_train_loss: 0.5598 | train_auc: 0.8883 | lr : 1e-05
Epoch [8 / 200] Step: [400 / 1130] avg_train_loss: 0.5762 | train_auc: 0.8851 | lr : 1e-05
Epoch [8 / 200] Step: [500 / 1130] avg_train_loss: 0.5628 | train_auc: 0.8873 | lr : 1e-05
Epoch [8 / 200] Step: [600 / 1130] avg_train_loss: 0.5817 | train_auc: 0.8768 | lr : 1e-05
Epoch [8 / 200] Step: [700 / 1130] avg_train_loss: 0.5636 | train_auc: 0.8883 | lr : 1e-05
Epoch [8 / 200] Step: [800 / 1130] avg_train_loss: 0.5621 | train_auc: 0.8881 | lr : 1e-05
Epoch [8 / 200] Step: [900 / 1130] avg_train_loss: 0.5622 | train_auc: 0.888 | lr : 1e-05
Epoch [8 / 200] Step: [1000 / 1130] avg_train_loss: 0.5747 | train_auc: 0.8794 | lr : 1e-05
Epoch [8 / 200] Step: [1100 / 1130] avg_train_loss: 0.5805 | train_auc: 0.8753 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 8 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2689 | val_auc: nan | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2718 | val_auc: nan | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4481 | val_auc: 0.7434 | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5599 | val_auc: 0.781 | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5833 | val_auc: 0.8155 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 9
[TRAIN] Train model
Epoch [9 / 200] Step: [100 / 1130] avg_train_loss: 0.6477 | train_auc: 0.8302 | lr : 1e-05
Epoch [9 / 200] Step: [200 / 1130] avg_train_loss: 0.6204 | train_auc: 0.8518 | lr : 1e-05
Epoch [9 / 200] Step: [300 / 1130] avg_train_loss: 0.5816 | train_auc: 0.8672 | lr : 1e-05
Epoch [9 / 200] Step: [400 / 1130] avg_train_loss: 0.5716 | train_auc: 0.8774 | lr : 1e-05
Epoch [9 / 200] Step: [500 / 1130] avg_train_loss: 0.5773 | train_auc: 0.8719 | lr : 1e-05
Epoch [9 / 200] Step: [600 / 1130] avg_train_loss: 0.5832 | train_auc: 0.874 | lr : 1e-05
Epoch [9 / 200] Step: [700 / 1130] avg_train_loss: 0.5915 | train_auc: 0.8705 | lr : 1e-05
Epoch [9 / 200] Step: [800 / 1130] avg_train_loss: 0.5739 | train_auc: 0.8787 | lr : 1e-05
Epoch [9 / 200] Step: [900 / 1130] avg_train_loss: 0.5729 | train_auc: 0.878 | lr : 1e-05
Epoch [9 / 200] Step: [1000 / 1130] avg_train_loss: 0.5884 | train_auc: 0.8687 | lr : 1e-05
Epoch [9 / 200] Step: [1100 / 1130] avg_train_loss: 0.5868 | train_auc: 0.8701 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 9 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.424 | val_auc: nan | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.3986 | val_auc: nan | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5684 | val_auc: 0.7434 | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6399 | val_auc: 0.7767 | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6344 | val_auc: 0.8053 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 10
[TRAIN] Train model
Epoch [10 / 200] Step: [100 / 1130] avg_train_loss: 0.4641 | train_auc: 0.9222 | lr : 1e-05
Epoch [10 / 200] Step: [200 / 1130] avg_train_loss: 0.4689 | train_auc: 0.9326 | lr : 1e-05
Epoch [10 / 200] Step: [300 / 1130] avg_train_loss: 0.5127 | train_auc: 0.9152 | lr : 1e-05
Epoch [10 / 200] Step: [400 / 1130] avg_train_loss: 0.489 | train_auc: 0.9249 | lr : 1e-05
Epoch [10 / 200] Step: [500 / 1130] avg_train_loss: 0.4992 | train_auc: 0.9179 | lr : 1e-05
Epoch [10 / 200] Step: [600 / 1130] avg_train_loss: 0.5126 | train_auc: 0.9137 | lr : 1e-05
Epoch [10 / 200] Step: [700 / 1130] avg_train_loss: 0.505 | train_auc: 0.9153 | lr : 1e-05
Epoch [10 / 200] Step: [800 / 1130] avg_train_loss: 0.5124 | train_auc: 0.9098 | lr : 1e-05
Epoch [10 / 200] Step: [900 / 1130] avg_train_loss: 0.5137 | train_auc: 0.9096 | lr : 1e-05
Epoch [10 / 200] Step: [1000 / 1130] avg_train_loss: 0.5207 | train_auc: 0.906 | lr : 1e-05
Epoch [10 / 200] Step: [1100 / 1130] avg_train_loss: 0.5189 | train_auc: 0.9052 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 10 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1892 | val_auc: nan | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1691 | val_auc: nan | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4021 | val_auc: 0.7037 | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6039 | val_auc: 0.7496 | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7015 | val_auc: 0.7629 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 11
[TRAIN] Train model
Epoch [11 / 200] Step: [100 / 1130] avg_train_loss: 0.5902 | train_auc: 0.8897 | lr : 3e-06
Epoch [11 / 200] Step: [200 / 1130] avg_train_loss: 0.5 | train_auc: 0.9135 | lr : 3e-06
Epoch [11 / 200] Step: [300 / 1130] avg_train_loss: 0.4528 | train_auc: 0.9302 | lr : 3e-06
Epoch [11 / 200] Step: [400 / 1130] avg_train_loss: 0.4538 | train_auc: 0.9367 | lr : 3e-06
Epoch [11 / 200] Step: [500 / 1130] avg_train_loss: 0.4518 | train_auc: 0.9358 | lr : 3e-06
Epoch [11 / 200] Step: [600 / 1130] avg_train_loss: 0.4282 | train_auc: 0.9428 | lr : 3e-06
Epoch [11 / 200] Step: [700 / 1130] avg_train_loss: 0.4331 | train_auc: 0.9404 | lr : 3e-06
Epoch [11 / 200] Step: [800 / 1130] avg_train_loss: 0.4226 | train_auc: 0.9431 | lr : 3e-06
Epoch [11 / 200] Step: [900 / 1130] avg_train_loss: 0.4224 | train_auc: 0.9434 | lr : 3e-06
Epoch [11 / 200] Step: [1000 / 1130] avg_train_loss: 0.4355 | train_auc: 0.9387 | lr : 3e-06
Epoch [11 / 200] Step: [1100 / 1130] avg_train_loss: 0.434 | train_auc: 0.9389 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 11 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2164 | val_auc: nan | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.179 | val_auc: nan | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.391 | val_auc: 0.6508 | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5295 | val_auc: 0.7742 | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5906 | val_auc: 0.8119 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 12
[TRAIN] Train model
Epoch [12 / 200] Step: [100 / 1130] avg_train_loss: 0.4221 | train_auc: 0.9247 | lr : 3e-06
Epoch [12 / 200] Step: [200 / 1130] avg_train_loss: 0.3538 | train_auc: 0.9569 | lr : 3e-06
Epoch [12 / 200] Step: [300 / 1130] avg_train_loss: 0.3687 | train_auc: 0.9544 | lr : 3e-06
Epoch [12 / 200] Step: [400 / 1130] avg_train_loss: 0.3822 | train_auc: 0.9488 | lr : 3e-06
Epoch [12 / 200] Step: [500 / 1130] avg_train_loss: 0.368 | train_auc: 0.9542 | lr : 3e-06
Epoch [12 / 200] Step: [600 / 1130] avg_train_loss: 0.3557 | train_auc: 0.9562 | lr : 3e-06
Epoch [12 / 200] Step: [700 / 1130] avg_train_loss: 0.3773 | train_auc: 0.9488 | lr : 3e-06
Epoch [12 / 200] Step: [800 / 1130] avg_train_loss: 0.3777 | train_auc: 0.9508 | lr : 3e-06
Epoch [12 / 200] Step: [900 / 1130] avg_train_loss: 0.372 | train_auc: 0.9524 | lr : 3e-06
Epoch [12 / 200] Step: [1000 / 1130] avg_train_loss: 0.3759 | train_auc: 0.9516 | lr : 3e-06
Epoch [12 / 200] Step: [1100 / 1130] avg_train_loss: 0.3776 | train_auc: 0.9522 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 12 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3772 | val_auc: nan | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2652 | val_auc: nan | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4191 | val_auc: 0.7937 | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5029 | val_auc: 0.8489 | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5605 | val_auc: 0.8627 | lr: 3e-06
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.9510_val_auc_0.8371_train_loss_0.3811_val_loss_0.6676_epoch_12_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 13
[TRAIN] Train model
Epoch [13 / 200] Step: [100 / 1130] avg_train_loss: 0.4144 | train_auc: 0.929 | lr : 3e-06
Epoch [13 / 200] Step: [200 / 1130] avg_train_loss: 0.3908 | train_auc: 0.9442 | lr : 3e-06
Epoch [13 / 200] Step: [300 / 1130] avg_train_loss: 0.4064 | train_auc: 0.94 | lr : 3e-06
Epoch [13 / 200] Step: [400 / 1130] avg_train_loss: 0.384 | train_auc: 0.9495 | lr : 3e-06
Epoch [13 / 200] Step: [500 / 1130] avg_train_loss: 0.3824 | train_auc: 0.953 | lr : 3e-06
Epoch [13 / 200] Step: [600 / 1130] avg_train_loss: 0.3908 | train_auc: 0.9487 | lr : 3e-06
Epoch [13 / 200] Step: [700 / 1130] avg_train_loss: 0.3812 | train_auc: 0.9514 | lr : 3e-06
Epoch [13 / 200] Step: [800 / 1130] avg_train_loss: 0.3753 | train_auc: 0.9542 | lr : 3e-06
Epoch [13 / 200] Step: [900 / 1130] avg_train_loss: 0.3695 | train_auc: 0.9548 | lr : 3e-06
Epoch [13 / 200] Step: [1000 / 1130] avg_train_loss: 0.3762 | train_auc: 0.9544 | lr : 3e-06
Epoch [13 / 200] Step: [1100 / 1130] avg_train_loss: 0.3734 | train_auc: 0.9545 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 13 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3783 | val_auc: nan | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.3042 | val_auc: nan | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5757 | val_auc: 0.7354 | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6341 | val_auc: 0.8158 | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6307 | val_auc: 0.8534 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 14
[TRAIN] Train model
Epoch [14 / 200] Step: [100 / 1130] avg_train_loss: 0.384 | train_auc: 0.9504 | lr : 3e-06
Epoch [14 / 200] Step: [200 / 1130] avg_train_loss: 0.3722 | train_auc: 0.9574 | lr : 3e-06
Epoch [14 / 200] Step: [300 / 1130] avg_train_loss: 0.3372 | train_auc: 0.9658 | lr : 3e-06
Epoch [14 / 200] Step: [400 / 1130] avg_train_loss: 0.334 | train_auc: 0.9646 | lr : 3e-06
Epoch [14 / 200] Step: [500 / 1130] avg_train_loss: 0.3399 | train_auc: 0.9638 | lr : 3e-06
Epoch [14 / 200] Step: [600 / 1130] avg_train_loss: 0.3394 | train_auc: 0.9646 | lr : 3e-06
Epoch [14 / 200] Step: [700 / 1130] avg_train_loss: 0.3315 | train_auc: 0.968 | lr : 3e-06
Epoch [14 / 200] Step: [800 / 1130] avg_train_loss: 0.3295 | train_auc: 0.9686 | lr : 3e-06
Epoch [14 / 200] Step: [900 / 1130] avg_train_loss: 0.3243 | train_auc: 0.9693 | lr : 3e-06
Epoch [14 / 200] Step: [1000 / 1130] avg_train_loss: 0.3197 | train_auc: 0.9705 | lr : 3e-06
Epoch [14 / 200] Step: [1100 / 1130] avg_train_loss: 0.3187 | train_auc: 0.9704 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 14 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2574 | val_auc: nan | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2062 | val_auc: nan | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4628 | val_auc: 0.6984 | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.532 | val_auc: 0.8166 | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5675 | val_auc: 0.8503 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 15
[TRAIN] Train model
Epoch [15 / 200] Step: [100 / 1130] avg_train_loss: 0.461 | train_auc: 0.9169 | lr : 9e-07
Epoch [15 / 200] Step: [200 / 1130] avg_train_loss: 0.3682 | train_auc: 0.9434 | lr : 9e-07
Epoch [15 / 200] Step: [300 / 1130] avg_train_loss: 0.338 | train_auc: 0.9584 | lr : 9e-07
Epoch [15 / 200] Step: [400 / 1130] avg_train_loss: 0.3228 | train_auc: 0.963 | lr : 9e-07
Epoch [15 / 200] Step: [500 / 1130] avg_train_loss: 0.313 | train_auc: 0.9672 | lr : 9e-07
Epoch [15 / 200] Step: [600 / 1130] avg_train_loss: 0.3099 | train_auc: 0.9683 | lr : 9e-07
Epoch [15 / 200] Step: [700 / 1130] avg_train_loss: 0.3238 | train_auc: 0.967 | lr : 9e-07
Epoch [15 / 200] Step: [800 / 1130] avg_train_loss: 0.3297 | train_auc: 0.9654 | lr : 9e-07
Epoch [15 / 200] Step: [900 / 1130] avg_train_loss: 0.3226 | train_auc: 0.9675 | lr : 9e-07
Epoch [15 / 200] Step: [1000 / 1130] avg_train_loss: 0.3221 | train_auc: 0.9668 | lr : 9e-07
Epoch [15 / 200] Step: [1100 / 1130] avg_train_loss: 0.3205 | train_auc: 0.9676 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 15 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2411 | val_auc: nan | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1931 | val_auc: nan | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4429 | val_auc: 0.7275 | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5135 | val_auc: 0.8217 | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5295 | val_auc: 0.8556 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 16
[TRAIN] Train model
Epoch [16 / 200] Step: [100 / 1130] avg_train_loss: 0.1847 | train_auc: 0.9968 | lr : 9e-07
Epoch [16 / 200] Step: [200 / 1130] avg_train_loss: 0.2346 | train_auc: 0.9908 | lr : 9e-07
Epoch [16 / 200] Step: [300 / 1130] avg_train_loss: 0.2778 | train_auc: 0.9775 | lr : 9e-07
Epoch [16 / 200] Step: [400 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9786 | lr : 9e-07
Epoch [16 / 200] Step: [500 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9764 | lr : 9e-07
Epoch [16 / 200] Step: [600 / 1130] avg_train_loss: 0.2786 | train_auc: 0.9761 | lr : 9e-07
Epoch [16 / 200] Step: [700 / 1130] avg_train_loss: 0.2832 | train_auc: 0.9735 | lr : 9e-07
Epoch [16 / 200] Step: [800 / 1130] avg_train_loss: 0.3014 | train_auc: 0.9698 | lr : 9e-07
Epoch [16 / 200] Step: [900 / 1130] avg_train_loss: 0.2882 | train_auc: 0.973 | lr : 9e-07
Epoch [16 / 200] Step: [1000 / 1130] avg_train_loss: 0.2923 | train_auc: 0.9723 | lr : 9e-07
Epoch [16 / 200] Step: [1100 / 1130] avg_train_loss: 0.2886 | train_auc: 0.9734 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 16 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3422 | val_auc: nan | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2587 | val_auc: nan | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4846 | val_auc: 0.7646 | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5345 | val_auc: 0.8404 | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5736 | val_auc: 0.8632 | lr: 9e-07
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.9732_val_auc_0.8374_train_loss_0.2891_val_loss_0.6738_epoch_16_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 17
[TRAIN] Train model
Epoch [17 / 200] Step: [100 / 1130] avg_train_loss: 0.3083 | train_auc: 0.9732 | lr : 9e-07
Epoch [17 / 200] Step: [200 / 1130] avg_train_loss: 0.2902 | train_auc: 0.9751 | lr : 9e-07
Epoch [17 / 200] Step: [300 / 1130] avg_train_loss: 0.2778 | train_auc: 0.9779 | lr : 9e-07
Epoch [17 / 200] Step: [400 / 1130] avg_train_loss: 0.2817 | train_auc: 0.9787 | lr : 9e-07
Epoch [17 / 200] Step: [500 / 1130] avg_train_loss: 0.2716 | train_auc: 0.981 | lr : 9e-07
Epoch [17 / 200] Step: [600 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9808 | lr : 9e-07
Epoch [17 / 200] Step: [700 / 1130] avg_train_loss: 0.2752 | train_auc: 0.9795 | lr : 9e-07
Epoch [17 / 200] Step: [800 / 1130] avg_train_loss: 0.2771 | train_auc: 0.9798 | lr : 9e-07
Epoch [17 / 200] Step: [900 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9777 | lr : 9e-07
Epoch [17 / 200] Step: [1000 / 1130] avg_train_loss: 0.277 | train_auc: 0.9782 | lr : 9e-07
Epoch [17 / 200] Step: [1100 / 1130] avg_train_loss: 0.2811 | train_auc: 0.9774 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 17 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2242 | val_auc: nan | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1674 | val_auc: nan | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4442 | val_auc: 0.6455 | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.545 | val_auc: 0.7861 | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.58 | val_auc: 0.8373 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 18
[TRAIN] Train model
Epoch [18 / 200] Step: [100 / 1130] avg_train_loss: 0.2717 | train_auc: 0.9782 | lr : 9e-07
Epoch [18 / 200] Step: [200 / 1130] avg_train_loss: 0.264 | train_auc: 0.9767 | lr : 9e-07
Epoch [18 / 200] Step: [300 / 1130] avg_train_loss: 0.266 | train_auc: 0.9786 | lr : 9e-07
Epoch [18 / 200] Step: [400 / 1130] avg_train_loss: 0.2619 | train_auc: 0.9797 | lr : 9e-07
Epoch [18 / 200] Step: [500 / 1130] avg_train_loss: 0.2701 | train_auc: 0.9779 | lr : 9e-07
Epoch [18 / 200] Step: [600 / 1130] avg_train_loss: 0.2662 | train_auc: 0.9789 | lr : 9e-07
Epoch [18 / 200] Step: [700 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9799 | lr : 9e-07
Epoch [18 / 200] Step: [800 / 1130] avg_train_loss: 0.2579 | train_auc: 0.9814 | lr : 9e-07
Epoch [18 / 200] Step: [900 / 1130] avg_train_loss: 0.2589 | train_auc: 0.9811 | lr : 9e-07
Epoch [18 / 200] Step: [1000 / 1130] avg_train_loss: 0.259 | train_auc: 0.9809 | lr : 9e-07
Epoch [18 / 200] Step: [1100 / 1130] avg_train_loss: 0.2604 | train_auc: 0.981 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 18 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2355 | val_auc: nan | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1844 | val_auc: nan | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4393 | val_auc: 0.6931 | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.524 | val_auc: 0.8192 | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5592 | val_auc: 0.8489 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 19
[TRAIN] Train model
Epoch [19 / 200] Step: [100 / 1130] avg_train_loss: 0.331 | train_auc: 0.9554 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [200 / 1130] avg_train_loss: 0.313 | train_auc: 0.965 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [300 / 1130] avg_train_loss: 0.2895 | train_auc: 0.9723 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [400 / 1130] avg_train_loss: 0.2601 | train_auc: 0.9791 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [500 / 1130] avg_train_loss: 0.2498 | train_auc: 0.9823 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [600 / 1130] avg_train_loss: 0.257 | train_auc: 0.9819 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [700 / 1130] avg_train_loss: 0.2751 | train_auc: 0.9794 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [800 / 1130] avg_train_loss: 0.2837 | train_auc: 0.9779 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [900 / 1130] avg_train_loss: 0.2883 | train_auc: 0.9768 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [1000 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9768 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [1100 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9786 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 19 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2443 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1853 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.449 | val_auc: 0.7196 | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5429 | val_auc: 0.8175 | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5687 | val_auc: 0.8476 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 20
[TRAIN] Train model
Epoch [20 / 200] Step: [100 / 1130] avg_train_loss: 0.306 | train_auc: 0.9688 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [200 / 1130] avg_train_loss: 0.2909 | train_auc: 0.9703 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [300 / 1130] avg_train_loss: 0.2953 | train_auc: 0.972 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [400 / 1130] avg_train_loss: 0.2964 | train_auc: 0.9732 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [500 / 1130] avg_train_loss: 0.2862 | train_auc: 0.9746 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [600 / 1130] avg_train_loss: 0.2851 | train_auc: 0.9766 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [700 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9773 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [800 / 1130] avg_train_loss: 0.2757 | train_auc: 0.9783 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [900 / 1130] avg_train_loss: 0.2687 | train_auc: 0.9798 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [1000 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9809 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [1100 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9791 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 20 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1392 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.118 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.415 | val_auc: 0.6905 | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5412 | val_auc: 0.8124 | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.594 | val_auc: 0.8476 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 21
[TRAIN] Train model
Epoch [21 / 200] Step: [100 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9853 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [200 / 1130] avg_train_loss: 0.226 | train_auc: 0.9898 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [300 / 1130] avg_train_loss: 0.2372 | train_auc: 0.9857 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [400 / 1130] avg_train_loss: 0.241 | train_auc: 0.9852 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [500 / 1130] avg_train_loss: 0.2386 | train_auc: 0.986 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [600 / 1130] avg_train_loss: 0.2657 | train_auc: 0.9804 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [700 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9793 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [800 / 1130] avg_train_loss: 0.2708 | train_auc: 0.9795 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [900 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9796 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [1000 / 1130] avg_train_loss: 0.2753 | train_auc: 0.9787 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [1100 / 1130] avg_train_loss: 0.2712 | train_auc: 0.9795 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 21 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1925 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1425 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4165 | val_auc: 0.6958 | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.541 | val_auc: 0.8065 | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5992 | val_auc: 0.8382 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 22
[TRAIN] Train model
Epoch [22 / 200] Step: [100 / 1130] avg_train_loss: 0.2253 | train_auc: 0.9907 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [200 / 1130] avg_train_loss: 0.2643 | train_auc: 0.981 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [300 / 1130] avg_train_loss: 0.2652 | train_auc: 0.9825 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [400 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9833 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [500 / 1130] avg_train_loss: 0.2662 | train_auc: 0.9818 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [600 / 1130] avg_train_loss: 0.2649 | train_auc: 0.982 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [700 / 1130] avg_train_loss: 0.2697 | train_auc: 0.9805 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [800 / 1130] avg_train_loss: 0.2653 | train_auc: 0.9812 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [900 / 1130] avg_train_loss: 0.264 | train_auc: 0.9812 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [1000 / 1130] avg_train_loss: 0.2735 | train_auc: 0.979 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [1100 / 1130] avg_train_loss: 0.2658 | train_auc: 0.9807 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 22 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1605 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1288 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4183 | val_auc: 0.709 | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5448 | val_auc: 0.8065 | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5818 | val_auc: 0.8503 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 23
[TRAIN] Train model
Epoch [23 / 200] Step: [100 / 1130] avg_train_loss: 0.2668 | train_auc: 0.9807 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [200 / 1130] avg_train_loss: 0.2431 | train_auc: 0.9852 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [300 / 1130] avg_train_loss: 0.2338 | train_auc: 0.9862 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [400 / 1130] avg_train_loss: 0.2483 | train_auc: 0.9842 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [500 / 1130] avg_train_loss: 0.2444 | train_auc: 0.9852 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [600 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9864 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [700 / 1130] avg_train_loss: 0.2242 | train_auc: 0.9888 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [800 / 1130] avg_train_loss: 0.2213 | train_auc: 0.9897 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [900 / 1130] avg_train_loss: 0.2325 | train_auc: 0.9877 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [1000 / 1130] avg_train_loss: 0.2252 | train_auc: 0.9888 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [1100 / 1130] avg_train_loss: 0.229 | train_auc: 0.9882 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 23 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1158 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0995 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4053 | val_auc: 0.6614 | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5781 | val_auc: 0.7716 | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6408 | val_auc: 0.8266 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 24
[TRAIN] Train model
Epoch [24 / 200] Step: [100 / 1130] avg_train_loss: 0.2148 | train_auc: 0.9915 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [200 / 1130] avg_train_loss: 0.2231 | train_auc: 0.991 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [300 / 1130] avg_train_loss: 0.2262 | train_auc: 0.9903 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [400 / 1130] avg_train_loss: 0.2272 | train_auc: 0.9882 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [500 / 1130] avg_train_loss: 0.2051 | train_auc: 0.9913 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [600 / 1130] avg_train_loss: 0.2096 | train_auc: 0.991 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [700 / 1130] avg_train_loss: 0.2025 | train_auc: 0.992 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [800 / 1130] avg_train_loss: 0.2135 | train_auc: 0.9905 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [900 / 1130] avg_train_loss: 0.2235 | train_auc: 0.9878 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [1000 / 1130] avg_train_loss: 0.2237 | train_auc: 0.9872 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [1100 / 1130] avg_train_loss: 0.2212 | train_auc: 0.9868 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 24 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2218 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1636 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4499 | val_auc: 0.7116 | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5582 | val_auc: 0.8031 | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.587 | val_auc: 0.8382 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 25
[TRAIN] Train model
Epoch [25 / 200] Step: [100 / 1130] avg_train_loss: 0.2376 | train_auc: 0.9848 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [200 / 1130] avg_train_loss: 0.278 | train_auc: 0.9749 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [300 / 1130] avg_train_loss: 0.263 | train_auc: 0.9793 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [400 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9841 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [500 / 1130] avg_train_loss: 0.2628 | train_auc: 0.982 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [600 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9838 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [700 / 1130] avg_train_loss: 0.2552 | train_auc: 0.9845 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [800 / 1130] avg_train_loss: 0.2675 | train_auc: 0.9811 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [900 / 1130] avg_train_loss: 0.2609 | train_auc: 0.9826 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [1000 / 1130] avg_train_loss: 0.2538 | train_auc: 0.9838 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [1100 / 1130] avg_train_loss: 0.2549 | train_auc: 0.9837 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 25 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3021 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2174 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4831 | val_auc: 0.6825 | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5663 | val_auc: 0.7971 | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5958 | val_auc: 0.8333 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 26
[TRAIN] Train model
Epoch [26 / 200] Step: [100 / 1130] avg_train_loss: 0.2008 | train_auc: 0.9949 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [200 / 1130] avg_train_loss: 0.2727 | train_auc: 0.9772 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [300 / 1130] avg_train_loss: 0.2408 | train_auc: 0.9831 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [400 / 1130] avg_train_loss: 0.2442 | train_auc: 0.9837 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [500 / 1130] avg_train_loss: 0.2483 | train_auc: 0.9839 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [600 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9848 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [700 / 1130] avg_train_loss: 0.2351 | train_auc: 0.9862 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [800 / 1130] avg_train_loss: 0.2335 | train_auc: 0.9856 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [900 / 1130] avg_train_loss: 0.2308 | train_auc: 0.986 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [1000 / 1130] avg_train_loss: 0.2373 | train_auc: 0.9851 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [1100 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9845 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 26 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2498 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1886 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4633 | val_auc: 0.7169 | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5515 | val_auc: 0.809 | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.569 | val_auc: 0.8427 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 27
[TRAIN] Train model
Epoch [27 / 200] Step: [100 / 1130] avg_train_loss: 0.2892 | train_auc: 0.9795 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [200 / 1130] avg_train_loss: 0.2342 | train_auc: 0.988 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [300 / 1130] avg_train_loss: 0.221 | train_auc: 0.99 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [400 / 1130] avg_train_loss: 0.2263 | train_auc: 0.9859 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [500 / 1130] avg_train_loss: 0.2151 | train_auc: 0.9884 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [600 / 1130] avg_train_loss: 0.2122 | train_auc: 0.9893 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [700 / 1130] avg_train_loss: 0.2285 | train_auc: 0.9853 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [800 / 1130] avg_train_loss: 0.2365 | train_auc: 0.9843 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [900 / 1130] avg_train_loss: 0.2373 | train_auc: 0.9846 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [1000 / 1130] avg_train_loss: 0.2348 | train_auc: 0.9841 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [1100 / 1130] avg_train_loss: 0.2392 | train_auc: 0.9836 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 27 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.183 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1479 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4338 | val_auc: 0.7143 | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5563 | val_auc: 0.7963 | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5862 | val_auc: 0.8391 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 28
[TRAIN] Train model
Epoch [28 / 200] Step: [100 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9817 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [200 / 1130] avg_train_loss: 0.252 | train_auc: 0.9836 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [300 / 1130] avg_train_loss: 0.2418 | train_auc: 0.985 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [400 / 1130] avg_train_loss: 0.2667 | train_auc: 0.9784 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [500 / 1130] avg_train_loss: 0.2652 | train_auc: 0.9798 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [600 / 1130] avg_train_loss: 0.2714 | train_auc: 0.9791 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [700 / 1130] avg_train_loss: 0.2695 | train_auc: 0.9789 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [800 / 1130] avg_train_loss: 0.2647 | train_auc: 0.98 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [900 / 1130] avg_train_loss: 0.2665 | train_auc: 0.9783 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [1000 / 1130] avg_train_loss: 0.2654 | train_auc: 0.9788 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [1100 / 1130] avg_train_loss: 0.2648 | train_auc: 0.9785 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 28 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1344 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.119 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4015 | val_auc: 0.7037 | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5618 | val_auc: 0.764 | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6398 | val_auc: 0.7977 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 29
[TRAIN] Train model
Epoch [29 / 200] Step: [100 / 1130] avg_train_loss: 0.221 | train_auc: 0.9886 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [200 / 1130] avg_train_loss: 0.2879 | train_auc: 0.9738 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [300 / 1130] avg_train_loss: 0.2542 | train_auc: 0.9825 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [400 / 1130] avg_train_loss: 0.2408 | train_auc: 0.9857 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [500 / 1130] avg_train_loss: 0.2426 | train_auc: 0.9845 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [600 / 1130] avg_train_loss: 0.2424 | train_auc: 0.9845 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [700 / 1130] avg_train_loss: 0.2391 | train_auc: 0.9853 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [800 / 1130] avg_train_loss: 0.2289 | train_auc: 0.9872 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [900 / 1130] avg_train_loss: 0.2261 | train_auc: 0.9879 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [1000 / 1130] avg_train_loss: 0.2212 | train_auc: 0.9885 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [1100 / 1130] avg_train_loss: 0.2182 | train_auc: 0.9892 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 29 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2349 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1675 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.453 | val_auc: 0.7116 | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5637 | val_auc: 0.8048 | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5979 | val_auc: 0.8378 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 30
[TRAIN] Train model
Epoch [30 / 200] Step: [100 / 1130] avg_train_loss: 0.2572 | train_auc: 0.9825 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [200 / 1130] avg_train_loss: 0.2835 | train_auc: 0.9732 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [300 / 1130] avg_train_loss: 0.2541 | train_auc: 0.9804 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [400 / 1130] avg_train_loss: 0.2449 | train_auc: 0.9824 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [500 / 1130] avg_train_loss: 0.2561 | train_auc: 0.9814 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [600 / 1130] avg_train_loss: 0.2469 | train_auc: 0.9822 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [700 / 1130] avg_train_loss: 0.2398 | train_auc: 0.9839 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [800 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9841 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [900 / 1130] avg_train_loss: 0.2351 | train_auc: 0.985 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [1000 / 1130] avg_train_loss: 0.233 | train_auc: 0.9854 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [1100 / 1130] avg_train_loss: 0.2332 | train_auc: 0.986 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 30 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2956 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.22 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4807 | val_auc: 0.6958 | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5527 | val_auc: 0.8098 | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5775 | val_auc: 0.8489 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 31
[TRAIN] Train model
Epoch [31 / 200] Step: [100 / 1130] avg_train_loss: 0.3856 | train_auc: 0.9548 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [200 / 1130] avg_train_loss: 0.3253 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [300 / 1130] avg_train_loss: 0.3161 | train_auc: 0.9695 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [400 / 1130] avg_train_loss: 0.312 | train_auc: 0.9709 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [500 / 1130] avg_train_loss: 0.293 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [600 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [700 / 1130] avg_train_loss: 0.2826 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [800 / 1130] avg_train_loss: 0.2727 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [900 / 1130] avg_train_loss: 0.262 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [1000 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [1100 / 1130] avg_train_loss: 0.2557 | train_auc: 0.9813 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 31 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2419 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1751 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4372 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.541 | val_auc: 0.8124 | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5634 | val_auc: 0.8471 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 32
[TRAIN] Train model
Epoch [32 / 200] Step: [100 / 1130] avg_train_loss: 0.2383 | train_auc: 0.9893 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [200 / 1130] avg_train_loss: 0.2541 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [300 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [400 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [500 / 1130] avg_train_loss: 0.2575 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [600 / 1130] avg_train_loss: 0.2541 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [700 / 1130] avg_train_loss: 0.2533 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [800 / 1130] avg_train_loss: 0.2567 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [900 / 1130] avg_train_loss: 0.2585 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [1000 / 1130] avg_train_loss: 0.2583 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [1100 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9817 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 32 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2106 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1567 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4613 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.563 | val_auc: 0.8031 | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5865 | val_auc: 0.8485 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 33
[TRAIN] Train model
Epoch [33 / 200] Step: [100 / 1130] avg_train_loss: 0.2234 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [200 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [300 / 1130] avg_train_loss: 0.2955 | train_auc: 0.9668 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [400 / 1130] avg_train_loss: 0.2974 | train_auc: 0.9688 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [500 / 1130] avg_train_loss: 0.2743 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [600 / 1130] avg_train_loss: 0.2662 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [700 / 1130] avg_train_loss: 0.2697 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [800 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [900 / 1130] avg_train_loss: 0.2562 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [1000 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [1100 / 1130] avg_train_loss: 0.2503 | train_auc: 0.9815 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 33 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1635 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1342 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4093 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5359 | val_auc: 0.798 | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6078 | val_auc: 0.8284 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 34
[TRAIN] Train model
Epoch [34 / 200] Step: [100 / 1130] avg_train_loss: 0.1755 | train_auc: 0.9928 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [200 / 1130] avg_train_loss: 0.1874 | train_auc: 0.9931 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [300 / 1130] avg_train_loss: 0.1973 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [400 / 1130] avg_train_loss: 0.215 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [500 / 1130] avg_train_loss: 0.2182 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [600 / 1130] avg_train_loss: 0.2175 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [700 / 1130] avg_train_loss: 0.2163 | train_auc: 0.9895 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [800 / 1130] avg_train_loss: 0.2288 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [900 / 1130] avg_train_loss: 0.2286 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [1000 / 1130] avg_train_loss: 0.23 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [1100 / 1130] avg_train_loss: 0.2374 | train_auc: 0.9838 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 34 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.219 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1546 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4466 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5674 | val_auc: 0.8031 | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6002 | val_auc: 0.8422 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 35
[TRAIN] Train model
Epoch [35 / 200] Step: [100 / 1130] avg_train_loss: 0.2203 | train_auc: 0.9955 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [200 / 1130] avg_train_loss: 0.2186 | train_auc: 0.9928 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [300 / 1130] avg_train_loss: 0.1927 | train_auc: 0.9952 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [400 / 1130] avg_train_loss: 0.2001 | train_auc: 0.9931 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [500 / 1130] avg_train_loss: 0.2012 | train_auc: 0.9927 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [600 / 1130] avg_train_loss: 0.2133 | train_auc: 0.9908 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [700 / 1130] avg_train_loss: 0.2182 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [800 / 1130] avg_train_loss: 0.2291 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [900 / 1130] avg_train_loss: 0.2396 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [1000 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [1100 / 1130] avg_train_loss: 0.2344 | train_auc: 0.986 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 35 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1693 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1379 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4061 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.541 | val_auc: 0.8022 | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5889 | val_auc: 0.8351 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 36
[TRAIN] Train model
Epoch [36 / 200] Step: [100 / 1130] avg_train_loss: 0.3363 | train_auc: 0.9586 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [200 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [300 / 1130] avg_train_loss: 0.2382 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [400 / 1130] avg_train_loss: 0.2302 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [500 / 1130] avg_train_loss: 0.249 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [600 / 1130] avg_train_loss: 0.2795 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [700 / 1130] avg_train_loss: 0.2668 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [800 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [900 / 1130] avg_train_loss: 0.2582 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [1000 / 1130] avg_train_loss: 0.2504 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [1100 / 1130] avg_train_loss: 0.2555 | train_auc: 0.9788 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 36 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1786 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1362 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4157 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5357 | val_auc: 0.8226 | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5878 | val_auc: 0.8494 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 37
[TRAIN] Train model
Epoch [37 / 200] Step: [100 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [200 / 1130] avg_train_loss: 0.2476 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [300 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [400 / 1130] avg_train_loss: 0.2489 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [500 / 1130] avg_train_loss: 0.2584 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [600 / 1130] avg_train_loss: 0.2542 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [700 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [800 / 1130] avg_train_loss: 0.2516 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [900 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [1000 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [1100 / 1130] avg_train_loss: 0.2584 | train_auc: 0.9805 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 37 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.232 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1696 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4399 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5382 | val_auc: 0.8209 | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5737 | val_auc: 0.8538 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 38
[TRAIN] Train model
Epoch [38 / 200] Step: [100 / 1130] avg_train_loss: 0.244 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [200 / 1130] avg_train_loss: 0.2422 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [300 / 1130] avg_train_loss: 0.2444 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [400 / 1130] avg_train_loss: 0.2712 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [500 / 1130] avg_train_loss: 0.2674 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [600 / 1130] avg_train_loss: 0.2748 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [700 / 1130] avg_train_loss: 0.2578 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [800 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [900 / 1130] avg_train_loss: 0.2618 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [1000 / 1130] avg_train_loss: 0.2584 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [1100 / 1130] avg_train_loss: 0.2619 | train_auc: 0.9801 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 38 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.267 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1863 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4366 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5233 | val_auc: 0.8285 | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5654 | val_auc: 0.8601 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 39
[TRAIN] Train model
Epoch [39 / 200] Step: [100 / 1130] avg_train_loss: 0.3092 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [200 / 1130] avg_train_loss: 0.2996 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [300 / 1130] avg_train_loss: 0.2837 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [400 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [500 / 1130] avg_train_loss: 0.2857 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [600 / 1130] avg_train_loss: 0.2814 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [700 / 1130] avg_train_loss: 0.2868 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [800 / 1130] avg_train_loss: 0.2833 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [900 / 1130] avg_train_loss: 0.2687 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [1000 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [1100 / 1130] avg_train_loss: 0.2667 | train_auc: 0.9802 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 39 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2155 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1642 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4451 | val_auc: 0.7275 | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5526 | val_auc: 0.8149 | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5774 | val_auc: 0.8525 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 40
[TRAIN] Train model
Epoch [40 / 200] Step: [100 / 1130] avg_train_loss: 0.2498 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [200 / 1130] avg_train_loss: 0.298 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [300 / 1130] avg_train_loss: 0.2616 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [400 / 1130] avg_train_loss: 0.2519 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [500 / 1130] avg_train_loss: 0.2552 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [600 / 1130] avg_train_loss: 0.259 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [700 / 1130] avg_train_loss: 0.2558 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [800 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [900 / 1130] avg_train_loss: 0.2469 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [1000 / 1130] avg_train_loss: 0.2361 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [1100 / 1130] avg_train_loss: 0.2411 | train_auc: 0.9848 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 40 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.131 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1088 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4332 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5849 | val_auc: 0.7742 | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6352 | val_auc: 0.8226 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 41
[TRAIN] Train model
Epoch [41 / 200] Step: [100 / 1130] avg_train_loss: 0.3302 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [200 / 1130] avg_train_loss: 0.2529 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [300 / 1130] avg_train_loss: 0.2514 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [400 / 1130] avg_train_loss: 0.2445 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [500 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [600 / 1130] avg_train_loss: 0.2233 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [700 / 1130] avg_train_loss: 0.2204 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [800 / 1130] avg_train_loss: 0.2382 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [900 / 1130] avg_train_loss: 0.2365 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [1000 / 1130] avg_train_loss: 0.2296 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [1100 / 1130] avg_train_loss: 0.2308 | train_auc: 0.9843 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 41 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1248 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1049 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4171 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5965 | val_auc: 0.7555 | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6552 | val_auc: 0.8061 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 42
[TRAIN] Train model
Epoch [42 / 200] Step: [100 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [200 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [300 / 1130] avg_train_loss: 0.2517 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [400 / 1130] avg_train_loss: 0.2589 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [500 / 1130] avg_train_loss: 0.2524 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [600 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [700 / 1130] avg_train_loss: 0.2481 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [800 / 1130] avg_train_loss: 0.2663 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [900 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [1000 / 1130] avg_train_loss: 0.2563 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [1100 / 1130] avg_train_loss: 0.2514 | train_auc: 0.9831 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 42 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1072 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0919 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4102 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6076 | val_auc: 0.7504 | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6725 | val_auc: 0.8079 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 43
[TRAIN] Train model
Epoch [43 / 200] Step: [100 / 1130] avg_train_loss: 0.2317 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [200 / 1130] avg_train_loss: 0.2229 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [300 / 1130] avg_train_loss: 0.2215 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [400 / 1130] avg_train_loss: 0.2424 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [500 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [600 / 1130] avg_train_loss: 0.2537 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [700 / 1130] avg_train_loss: 0.2485 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [800 / 1130] avg_train_loss: 0.2467 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [900 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [1000 / 1130] avg_train_loss: 0.2497 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [1100 / 1130] avg_train_loss: 0.2533 | train_auc: 0.9842 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 43 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1571 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1175 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4129 | val_auc: 0.6667 | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5622 | val_auc: 0.7954 | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6194 | val_auc: 0.8454 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 44
[TRAIN] Train model
Epoch [44 / 200] Step: [100 / 1130] avg_train_loss: 0.2292 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [200 / 1130] avg_train_loss: 0.2634 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [300 / 1130] avg_train_loss: 0.2384 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [400 / 1130] avg_train_loss: 0.2828 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [500 / 1130] avg_train_loss: 0.2643 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [600 / 1130] avg_train_loss: 0.2481 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [700 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [800 / 1130] avg_train_loss: 0.2623 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [900 / 1130] avg_train_loss: 0.2513 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [1000 / 1130] avg_train_loss: 0.2526 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [1100 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9838 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 44 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2495 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1858 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4516 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5494 | val_auc: 0.8132 | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5636 | val_auc: 0.8516 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 45
[TRAIN] Train model
Epoch [45 / 200] Step: [100 / 1130] avg_train_loss: 0.2652 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [200 / 1130] avg_train_loss: 0.2646 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [300 / 1130] avg_train_loss: 0.2389 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [400 / 1130] avg_train_loss: 0.241 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [500 / 1130] avg_train_loss: 0.2383 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [600 / 1130] avg_train_loss: 0.2325 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [700 / 1130] avg_train_loss: 0.2456 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [800 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [900 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [1000 / 1130] avg_train_loss: 0.2373 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [1100 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9843 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 45 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1464 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1177 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4011 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5546 | val_auc: 0.7869 | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6076 | val_auc: 0.8342 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 46
[TRAIN] Train model
Epoch [46 / 200] Step: [100 / 1130] avg_train_loss: 0.1782 | train_auc: 0.9957 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [200 / 1130] avg_train_loss: 0.2216 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [300 / 1130] avg_train_loss: 0.2243 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [400 / 1130] avg_train_loss: 0.2394 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [500 / 1130] avg_train_loss: 0.2219 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [600 / 1130] avg_train_loss: 0.2249 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [700 / 1130] avg_train_loss: 0.2176 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [800 / 1130] avg_train_loss: 0.2166 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [900 / 1130] avg_train_loss: 0.2181 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [1000 / 1130] avg_train_loss: 0.2201 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [1100 / 1130] avg_train_loss: 0.2236 | train_auc: 0.9872 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 46 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2299 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1673 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4478 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5548 | val_auc: 0.8073 | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5711 | val_auc: 0.8503 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 47
[TRAIN] Train model
Epoch [47 / 200] Step: [100 / 1130] avg_train_loss: 0.2528 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [200 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [300 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [400 / 1130] avg_train_loss: 0.2219 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [500 / 1130] avg_train_loss: 0.2185 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [600 / 1130] avg_train_loss: 0.2232 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [700 / 1130] avg_train_loss: 0.2294 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [800 / 1130] avg_train_loss: 0.2237 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [900 / 1130] avg_train_loss: 0.2279 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [1000 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [1100 / 1130] avg_train_loss: 0.2294 | train_auc: 0.9864 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 47 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1977 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1522 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.423 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5532 | val_auc: 0.8005 | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5946 | val_auc: 0.8351 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 48
[TRAIN] Train model
Epoch [48 / 200] Step: [100 / 1130] avg_train_loss: 0.2271 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [200 / 1130] avg_train_loss: 0.233 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [300 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [400 / 1130] avg_train_loss: 0.2266 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [500 / 1130] avg_train_loss: 0.2395 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [600 / 1130] avg_train_loss: 0.2382 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [700 / 1130] avg_train_loss: 0.2489 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [800 / 1130] avg_train_loss: 0.2487 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [900 / 1130] avg_train_loss: 0.2476 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [1000 / 1130] avg_train_loss: 0.2483 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [1100 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9837 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 48 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1995 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1498 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.432 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.553 | val_auc: 0.8192 | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6042 | val_auc: 0.8543 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 49
[TRAIN] Train model
Epoch [49 / 200] Step: [100 / 1130] avg_train_loss: 0.1883 | train_auc: 0.9949 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [200 / 1130] avg_train_loss: 0.2185 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [300 / 1130] avg_train_loss: 0.2157 | train_auc: 0.9911 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [400 / 1130] avg_train_loss: 0.2375 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [500 / 1130] avg_train_loss: 0.2686 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [600 / 1130] avg_train_loss: 0.2786 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [700 / 1130] avg_train_loss: 0.2789 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [800 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [900 / 1130] avg_train_loss: 0.2778 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [1000 / 1130] avg_train_loss: 0.2709 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [1100 / 1130] avg_train_loss: 0.2733 | train_auc: 0.9801 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 49 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2283 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1749 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4394 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5337 | val_auc: 0.8158 | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5594 | val_auc: 0.8463 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 50
[TRAIN] Train model
Epoch [50 / 200] Step: [100 / 1130] avg_train_loss: 0.2356 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [200 / 1130] avg_train_loss: 0.235 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [300 / 1130] avg_train_loss: 0.2408 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [400 / 1130] avg_train_loss: 0.2692 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [500 / 1130] avg_train_loss: 0.2636 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [600 / 1130] avg_train_loss: 0.2475 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [700 / 1130] avg_train_loss: 0.2661 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [800 / 1130] avg_train_loss: 0.2584 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [900 / 1130] avg_train_loss: 0.251 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [1000 / 1130] avg_train_loss: 0.243 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [1100 / 1130] avg_train_loss: 0.2375 | train_auc: 0.9861 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 50 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1485 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.115 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4312 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5827 | val_auc: 0.792 | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6385 | val_auc: 0.8382 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 51
[TRAIN] Train model
Epoch [51 / 200] Step: [100 / 1130] avg_train_loss: 0.2409 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [200 / 1130] avg_train_loss: 0.2762 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [300 / 1130] avg_train_loss: 0.2844 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [400 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [500 / 1130] avg_train_loss: 0.2602 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [600 / 1130] avg_train_loss: 0.2661 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [700 / 1130] avg_train_loss: 0.2621 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [800 / 1130] avg_train_loss: 0.2557 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [900 / 1130] avg_train_loss: 0.269 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [1000 / 1130] avg_train_loss: 0.2762 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [1100 / 1130] avg_train_loss: 0.2762 | train_auc: 0.9765 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 51 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2282 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1713 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4413 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5428 | val_auc: 0.8107 | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5836 | val_auc: 0.8422 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 52
[TRAIN] Train model
Epoch [52 / 200] Step: [100 / 1130] avg_train_loss: 0.2692 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [200 / 1130] avg_train_loss: 0.2325 | train_auc: 0.991 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [300 / 1130] avg_train_loss: 0.2226 | train_auc: 0.9928 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [400 / 1130] avg_train_loss: 0.2294 | train_auc: 0.9907 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [500 / 1130] avg_train_loss: 0.2247 | train_auc: 0.9909 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [600 / 1130] avg_train_loss: 0.2271 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [700 / 1130] avg_train_loss: 0.222 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [800 / 1130] avg_train_loss: 0.2265 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [900 / 1130] avg_train_loss: 0.2283 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [1000 / 1130] avg_train_loss: 0.237 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [1100 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9859 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 52 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2134 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1587 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4269 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5357 | val_auc: 0.8268 | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5812 | val_auc: 0.848 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 53
[TRAIN] Train model
Epoch [53 / 200] Step: [100 / 1130] avg_train_loss: 0.2719 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [200 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [300 / 1130] avg_train_loss: 0.2673 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [400 / 1130] avg_train_loss: 0.2725 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [500 / 1130] avg_train_loss: 0.2877 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [600 / 1130] avg_train_loss: 0.2811 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [700 / 1130] avg_train_loss: 0.2738 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [800 / 1130] avg_train_loss: 0.2598 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [900 / 1130] avg_train_loss: 0.2534 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [1000 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [1100 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9851 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 53 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.223 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1557 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4547 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5783 | val_auc: 0.7946 | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6296 | val_auc: 0.8298 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 54
[TRAIN] Train model
Epoch [54 / 200] Step: [100 / 1130] avg_train_loss: 0.2317 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [200 / 1130] avg_train_loss: 0.2525 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [300 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [400 / 1130] avg_train_loss: 0.2452 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [500 / 1130] avg_train_loss: 0.2452 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [600 / 1130] avg_train_loss: 0.2417 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [700 / 1130] avg_train_loss: 0.2473 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [800 / 1130] avg_train_loss: 0.2517 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [900 / 1130] avg_train_loss: 0.2494 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [1000 / 1130] avg_train_loss: 0.2534 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [1100 / 1130] avg_train_loss: 0.2477 | train_auc: 0.983 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 54 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1659 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1344 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4238 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5673 | val_auc: 0.7971 | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6216 | val_auc: 0.8369 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 55
[TRAIN] Train model
Epoch [55 / 200] Step: [100 / 1130] avg_train_loss: 0.1925 | train_auc: 0.9991 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [200 / 1130] avg_train_loss: 0.1896 | train_auc: 0.9936 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [300 / 1130] avg_train_loss: 0.1903 | train_auc: 0.9939 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [400 / 1130] avg_train_loss: 0.1927 | train_auc: 0.9932 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [500 / 1130] avg_train_loss: 0.1988 | train_auc: 0.9927 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [600 / 1130] avg_train_loss: 0.2085 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [700 / 1130] avg_train_loss: 0.2105 | train_auc: 0.9913 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [800 / 1130] avg_train_loss: 0.222 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [900 / 1130] avg_train_loss: 0.2211 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [1000 / 1130] avg_train_loss: 0.2213 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [1100 / 1130] avg_train_loss: 0.2329 | train_auc: 0.9862 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 55 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3458 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2406 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4819 | val_auc: 0.746 | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5518 | val_auc: 0.8311 | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.556 | val_auc: 0.8685 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_axial_train_auc_0.9862_val_auc_0.8388_train_loss_0.2329_val_loss_0.6567_epoch_55_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 56
[TRAIN] Train model
Epoch [56 / 200] Step: [100 / 1130] avg_train_loss: 0.1659 | train_auc: 0.9953 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [200 / 1130] avg_train_loss: 0.1853 | train_auc: 0.9933 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [300 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [400 / 1130] avg_train_loss: 0.2317 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [500 / 1130] avg_train_loss: 0.2255 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [600 / 1130] avg_train_loss: 0.2235 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [700 / 1130] avg_train_loss: 0.2398 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [800 / 1130] avg_train_loss: 0.228 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [900 / 1130] avg_train_loss: 0.2295 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [1000 / 1130] avg_train_loss: 0.2318 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [1100 / 1130] avg_train_loss: 0.2293 | train_auc: 0.9845 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 56 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.11 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0963 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3986 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5809 | val_auc: 0.7683 | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6542 | val_auc: 0.8164 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 57
[TRAIN] Train model
Epoch [57 / 200] Step: [100 / 1130] avg_train_loss: 0.2659 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [200 / 1130] avg_train_loss: 0.2649 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [300 / 1130] avg_train_loss: 0.2677 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [400 / 1130] avg_train_loss: 0.2472 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [500 / 1130] avg_train_loss: 0.251 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [600 / 1130] avg_train_loss: 0.2521 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [700 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [800 / 1130] avg_train_loss: 0.245 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [900 / 1130] avg_train_loss: 0.2394 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [1000 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [1100 / 1130] avg_train_loss: 0.2515 | train_auc: 0.9809 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 57 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1491 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1254 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4257 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5618 | val_auc: 0.7759 | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6039 | val_auc: 0.8289 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 58
[TRAIN] Train model
Epoch [58 / 200] Step: [100 / 1130] avg_train_loss: 0.1988 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [200 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [300 / 1130] avg_train_loss: 0.2609 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [400 / 1130] avg_train_loss: 0.261 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [500 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [600 / 1130] avg_train_loss: 0.254 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [700 / 1130] avg_train_loss: 0.2681 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [800 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [900 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [1000 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [1100 / 1130] avg_train_loss: 0.2592 | train_auc: 0.9799 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 58 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1322 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1075 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4142 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5608 | val_auc: 0.7818 | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6157 | val_auc: 0.8298 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 59
[TRAIN] Train model
Epoch [59 / 200] Step: [100 / 1130] avg_train_loss: 0.2256 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [200 / 1130] avg_train_loss: 0.2415 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [300 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [400 / 1130] avg_train_loss: 0.2462 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [500 / 1130] avg_train_loss: 0.2504 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [600 / 1130] avg_train_loss: 0.2551 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [700 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [800 / 1130] avg_train_loss: 0.2654 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [900 / 1130] avg_train_loss: 0.2731 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [1000 / 1130] avg_train_loss: 0.2754 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [1100 / 1130] avg_train_loss: 0.2667 | train_auc: 0.9776 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 59 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2397 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1726 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4493 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5536 | val_auc: 0.8081 | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5938 | val_auc: 0.8463 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 60
[TRAIN] Train model
Epoch [60 / 200] Step: [100 / 1130] avg_train_loss: 0.3052 | train_auc: 0.9671 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [200 / 1130] avg_train_loss: 0.2766 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [300 / 1130] avg_train_loss: 0.2915 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [400 / 1130] avg_train_loss: 0.271 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [500 / 1130] avg_train_loss: 0.2488 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [600 / 1130] avg_train_loss: 0.2535 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [700 / 1130] avg_train_loss: 0.2564 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [800 / 1130] avg_train_loss: 0.2525 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [900 / 1130] avg_train_loss: 0.2561 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [1000 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [1100 / 1130] avg_train_loss: 0.2497 | train_auc: 0.9836 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 60 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1364 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1116 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4105 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5816 | val_auc: 0.7699 | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6429 | val_auc: 0.8195 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 61
[TRAIN] Train model
Epoch [61 / 200] Step: [100 / 1130] avg_train_loss: 0.2444 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [200 / 1130] avg_train_loss: 0.2818 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [300 / 1130] avg_train_loss: 0.2705 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [400 / 1130] avg_train_loss: 0.2762 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [500 / 1130] avg_train_loss: 0.2925 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [600 / 1130] avg_train_loss: 0.2899 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [700 / 1130] avg_train_loss: 0.2828 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [800 / 1130] avg_train_loss: 0.2725 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [900 / 1130] avg_train_loss: 0.2728 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [1000 / 1130] avg_train_loss: 0.263 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [1100 / 1130] avg_train_loss: 0.2642 | train_auc: 0.9791 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 61 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1227 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1005 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4041 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5832 | val_auc: 0.7776 | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6607 | val_auc: 0.8293 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 62
[TRAIN] Train model
Epoch [62 / 200] Step: [100 / 1130] avg_train_loss: 0.1678 | train_auc: 0.997 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [200 / 1130] avg_train_loss: 0.2041 | train_auc: 0.9927 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [300 / 1130] avg_train_loss: 0.2062 | train_auc: 0.9917 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [400 / 1130] avg_train_loss: 0.2004 | train_auc: 0.992 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [500 / 1130] avg_train_loss: 0.2108 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [600 / 1130] avg_train_loss: 0.2055 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [700 / 1130] avg_train_loss: 0.2041 | train_auc: 0.9913 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [800 / 1130] avg_train_loss: 0.1993 | train_auc: 0.9921 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [900 / 1130] avg_train_loss: 0.2057 | train_auc: 0.9911 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [1000 / 1130] avg_train_loss: 0.2105 | train_auc: 0.9901 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [1100 / 1130] avg_train_loss: 0.2169 | train_auc: 0.9887 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 62 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1409 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1151 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4099 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5725 | val_auc: 0.7716 | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6304 | val_auc: 0.8222 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 63
[TRAIN] Train model
Epoch [63 / 200] Step: [100 / 1130] avg_train_loss: 0.2389 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [200 / 1130] avg_train_loss: 0.2992 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [300 / 1130] avg_train_loss: 0.2762 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [400 / 1130] avg_train_loss: 0.2883 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [500 / 1130] avg_train_loss: 0.2804 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [600 / 1130] avg_train_loss: 0.2661 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [700 / 1130] avg_train_loss: 0.2549 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [800 / 1130] avg_train_loss: 0.2452 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [900 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [1000 / 1130] avg_train_loss: 0.2466 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [1100 / 1130] avg_train_loss: 0.2468 | train_auc: 0.9835 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 63 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2403 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1735 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.463 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5659 | val_auc: 0.8056 | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5956 | val_auc: 0.8387 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 64
[TRAIN] Train model
Epoch [64 / 200] Step: [100 / 1130] avg_train_loss: 0.1911 | train_auc: 0.9962 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [200 / 1130] avg_train_loss: 0.2199 | train_auc: 0.9905 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [300 / 1130] avg_train_loss: 0.2508 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [400 / 1130] avg_train_loss: 0.2503 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [500 / 1130] avg_train_loss: 0.2401 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [600 / 1130] avg_train_loss: 0.245 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [700 / 1130] avg_train_loss: 0.2529 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [800 / 1130] avg_train_loss: 0.2601 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [900 / 1130] avg_train_loss: 0.255 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [1000 / 1130] avg_train_loss: 0.2674 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [1100 / 1130] avg_train_loss: 0.2633 | train_auc: 0.9794 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 64 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2996 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2099 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4651 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5559 | val_auc: 0.8124 | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5767 | val_auc: 0.8494 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 65
[TRAIN] Train model
Epoch [65 / 200] Step: [100 / 1130] avg_train_loss: 0.2074 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [200 / 1130] avg_train_loss: 0.2421 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [300 / 1130] avg_train_loss: 0.2522 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [400 / 1130] avg_train_loss: 0.2413 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [500 / 1130] avg_train_loss: 0.2502 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [600 / 1130] avg_train_loss: 0.2364 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [700 / 1130] avg_train_loss: 0.2341 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [800 / 1130] avg_train_loss: 0.2516 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [900 / 1130] avg_train_loss: 0.2428 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [1000 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [1100 / 1130] avg_train_loss: 0.2398 | train_auc: 0.984 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 65 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2516 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1772 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4704 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5731 | val_auc: 0.8073 | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6047 | val_auc: 0.8431 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 66
[TRAIN] Train model
Epoch [66 / 200] Step: [100 / 1130] avg_train_loss: 0.1425 | train_auc: 0.9979 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [200 / 1130] avg_train_loss: 0.1602 | train_auc: 0.9968 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [300 / 1130] avg_train_loss: 0.182 | train_auc: 0.9954 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [400 / 1130] avg_train_loss: 0.2086 | train_auc: 0.9917 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [500 / 1130] avg_train_loss: 0.2041 | train_auc: 0.9931 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [600 / 1130] avg_train_loss: 0.216 | train_auc: 0.9899 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [700 / 1130] avg_train_loss: 0.2223 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [800 / 1130] avg_train_loss: 0.218 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [900 / 1130] avg_train_loss: 0.2206 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [1000 / 1130] avg_train_loss: 0.2221 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [1100 / 1130] avg_train_loss: 0.2177 | train_auc: 0.9888 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 66 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1364 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.107 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4179 | val_auc: 0.664 | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6004 | val_auc: 0.7708 | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.673 | val_auc: 0.8137 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 67
[TRAIN] Train model
Epoch [67 / 200] Step: [100 / 1130] avg_train_loss: 0.2663 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [200 / 1130] avg_train_loss: 0.268 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [300 / 1130] avg_train_loss: 0.2743 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [400 / 1130] avg_train_loss: 0.2747 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [500 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [600 / 1130] avg_train_loss: 0.2454 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [700 / 1130] avg_train_loss: 0.238 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [800 / 1130] avg_train_loss: 0.2302 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [900 / 1130] avg_train_loss: 0.2404 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [1000 / 1130] avg_train_loss: 0.2374 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [1100 / 1130] avg_train_loss: 0.2351 | train_auc: 0.9843 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 67 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2727 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1948 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4658 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5513 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5767 | val_auc: 0.852 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 68
[TRAIN] Train model
Epoch [68 / 200] Step: [100 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [200 / 1130] avg_train_loss: 0.2316 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [300 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [400 / 1130] avg_train_loss: 0.251 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [500 / 1130] avg_train_loss: 0.2494 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [600 / 1130] avg_train_loss: 0.2388 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [700 / 1130] avg_train_loss: 0.2508 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [800 / 1130] avg_train_loss: 0.2527 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [900 / 1130] avg_train_loss: 0.2474 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [1000 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [1100 / 1130] avg_train_loss: 0.2538 | train_auc: 0.9807 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 68 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2123 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1544 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4279 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5332 | val_auc: 0.8141 | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5968 | val_auc: 0.8418 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 69
[TRAIN] Train model
Epoch [69 / 200] Step: [100 / 1130] avg_train_loss: 0.1924 | train_auc: 0.9935 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [200 / 1130] avg_train_loss: 0.2617 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [300 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [400 / 1130] avg_train_loss: 0.245 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [500 / 1130] avg_train_loss: 0.2223 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [600 / 1130] avg_train_loss: 0.2472 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [700 / 1130] avg_train_loss: 0.2445 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [800 / 1130] avg_train_loss: 0.251 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [900 / 1130] avg_train_loss: 0.255 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [1000 / 1130] avg_train_loss: 0.2445 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [1100 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9841 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 69 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1149 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0996 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4095 | val_auc: 0.672 | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5873 | val_auc: 0.7632 | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6649 | val_auc: 0.8146 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 70
[TRAIN] Train model
Epoch [70 / 200] Step: [100 / 1130] avg_train_loss: 0.2424 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [200 / 1130] avg_train_loss: 0.2232 | train_auc: 0.9889 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [300 / 1130] avg_train_loss: 0.2415 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [400 / 1130] avg_train_loss: 0.2464 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [500 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [600 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [700 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [800 / 1130] avg_train_loss: 0.2816 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [900 / 1130] avg_train_loss: 0.2776 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [1000 / 1130] avg_train_loss: 0.264 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [1100 / 1130] avg_train_loss: 0.269 | train_auc: 0.9788 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 70 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.22 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1636 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.448 | val_auc: 0.7434 | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5782 | val_auc: 0.8039 | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6079 | val_auc: 0.8427 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 71
[TRAIN] Train model
Epoch [71 / 200] Step: [100 / 1130] avg_train_loss: 0.1845 | train_auc: 0.9942 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [200 / 1130] avg_train_loss: 0.2201 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [300 / 1130] avg_train_loss: 0.2003 | train_auc: 0.9918 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [400 / 1130] avg_train_loss: 0.2129 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [500 / 1130] avg_train_loss: 0.2382 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [600 / 1130] avg_train_loss: 0.2294 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [700 / 1130] avg_train_loss: 0.2389 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [800 / 1130] avg_train_loss: 0.2334 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [900 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [1000 / 1130] avg_train_loss: 0.2369 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [1100 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9856 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 71 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2265 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1668 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4573 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5656 | val_auc: 0.8098 | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5936 | val_auc: 0.848 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 72
[TRAIN] Train model
Epoch [72 / 200] Step: [100 / 1130] avg_train_loss: 0.2742 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [200 / 1130] avg_train_loss: 0.2663 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [300 / 1130] avg_train_loss: 0.2804 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [400 / 1130] avg_train_loss: 0.2582 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [500 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [600 / 1130] avg_train_loss: 0.2615 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [700 / 1130] avg_train_loss: 0.2503 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [800 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [900 / 1130] avg_train_loss: 0.2377 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [1000 / 1130] avg_train_loss: 0.24 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [1100 / 1130] avg_train_loss: 0.2445 | train_auc: 0.9834 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 72 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2654 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1934 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4642 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5546 | val_auc: 0.8073 | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.573 | val_auc: 0.8422 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 73
[TRAIN] Train model
Epoch [73 / 200] Step: [100 / 1130] avg_train_loss: 0.28 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [200 / 1130] avg_train_loss: 0.2611 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [300 / 1130] avg_train_loss: 0.2257 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [400 / 1130] avg_train_loss: 0.2238 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [500 / 1130] avg_train_loss: 0.2337 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [600 / 1130] avg_train_loss: 0.2324 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [700 / 1130] avg_train_loss: 0.2247 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [800 / 1130] avg_train_loss: 0.2253 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [900 / 1130] avg_train_loss: 0.242 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [1000 / 1130] avg_train_loss: 0.2386 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [1100 / 1130] avg_train_loss: 0.2376 | train_auc: 0.9848 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 73 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1832 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.147 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4529 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5768 | val_auc: 0.8039 | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6008 | val_auc: 0.8494 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 74
[TRAIN] Train model
Epoch [74 / 200] Step: [100 / 1130] avg_train_loss: 0.2391 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [200 / 1130] avg_train_loss: 0.213 | train_auc: 0.9895 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [300 / 1130] avg_train_loss: 0.223 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [400 / 1130] avg_train_loss: 0.2169 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [500 / 1130] avg_train_loss: 0.2273 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [600 / 1130] avg_train_loss: 0.2395 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [700 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [800 / 1130] avg_train_loss: 0.241 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [900 / 1130] avg_train_loss: 0.2356 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [1000 / 1130] avg_train_loss: 0.2399 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [1100 / 1130] avg_train_loss: 0.2387 | train_auc: 0.984 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 74 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1407 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1137 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4111 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5652 | val_auc: 0.7903 | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6214 | val_auc: 0.8378 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 75
[TRAIN] Train model
Epoch [75 / 200] Step: [100 / 1130] avg_train_loss: 0.2092 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [200 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [300 / 1130] avg_train_loss: 0.2344 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [400 / 1130] avg_train_loss: 0.2656 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [500 / 1130] avg_train_loss: 0.2634 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [600 / 1130] avg_train_loss: 0.2601 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [700 / 1130] avg_train_loss: 0.2514 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [800 / 1130] avg_train_loss: 0.2589 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [900 / 1130] avg_train_loss: 0.253 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [1000 / 1130] avg_train_loss: 0.2599 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [1100 / 1130] avg_train_loss: 0.2555 | train_auc: 0.981 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 75 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1778 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1345 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4332 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5595 | val_auc: 0.798 | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6207 | val_auc: 0.8405 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 76
[TRAIN] Train model
Epoch [76 / 200] Step: [100 / 1130] avg_train_loss: 0.2565 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [200 / 1130] avg_train_loss: 0.2478 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [300 / 1130] avg_train_loss: 0.2552 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [400 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [500 / 1130] avg_train_loss: 0.2661 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [600 / 1130] avg_train_loss: 0.2664 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [700 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [800 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [900 / 1130] avg_train_loss: 0.2533 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [1000 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [1100 / 1130] avg_train_loss: 0.2476 | train_auc: 0.9828 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 76 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1692 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1264 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4192 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5577 | val_auc: 0.8166 | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6202 | val_auc: 0.8463 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 77
[TRAIN] Train model
Epoch [77 / 200] Step: [100 / 1130] avg_train_loss: 0.3095 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [200 / 1130] avg_train_loss: 0.2721 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [300 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [400 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [500 / 1130] avg_train_loss: 0.239 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [600 / 1130] avg_train_loss: 0.2307 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [700 / 1130] avg_train_loss: 0.237 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [800 / 1130] avg_train_loss: 0.2329 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [900 / 1130] avg_train_loss: 0.2343 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [1000 / 1130] avg_train_loss: 0.2318 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [1100 / 1130] avg_train_loss: 0.2253 | train_auc: 0.988 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 77 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2992 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2189 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4747 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5591 | val_auc: 0.7997 | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5819 | val_auc: 0.8405 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 78
[TRAIN] Train model
Epoch [78 / 200] Step: [100 / 1130] avg_train_loss: 0.1863 | train_auc: 0.995 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [200 / 1130] avg_train_loss: 0.2247 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [300 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [400 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [500 / 1130] avg_train_loss: 0.2472 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [600 / 1130] avg_train_loss: 0.2548 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [700 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [800 / 1130] avg_train_loss: 0.2525 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [900 / 1130] avg_train_loss: 0.2428 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [1000 / 1130] avg_train_loss: 0.2355 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [1100 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9852 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 78 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1516 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1168 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4231 | val_auc: 0.6455 | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5719 | val_auc: 0.7818 | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6268 | val_auc: 0.8307 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 79
[TRAIN] Train model
Epoch [79 / 200] Step: [100 / 1130] avg_train_loss: 0.3182 | train_auc: 0.9666 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [200 / 1130] avg_train_loss: 0.2723 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [300 / 1130] avg_train_loss: 0.2671 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [400 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [500 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [600 / 1130] avg_train_loss: 0.2675 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [700 / 1130] avg_train_loss: 0.25 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [800 / 1130] avg_train_loss: 0.2445 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [900 / 1130] avg_train_loss: 0.2483 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [1000 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [1100 / 1130] avg_train_loss: 0.2515 | train_auc: 0.9823 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 79 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.211 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1534 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4579 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5837 | val_auc: 0.7929 | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6049 | val_auc: 0.8333 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 80
[TRAIN] Train model
Epoch [80 / 200] Step: [100 / 1130] avg_train_loss: 0.3128 | train_auc: 0.9527 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [200 / 1130] avg_train_loss: 0.2861 | train_auc: 0.9679 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [300 / 1130] avg_train_loss: 0.2958 | train_auc: 0.9698 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [400 / 1130] avg_train_loss: 0.278 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [500 / 1130] avg_train_loss: 0.286 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [600 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [700 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [800 / 1130] avg_train_loss: 0.2616 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [900 / 1130] avg_train_loss: 0.2571 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [1000 / 1130] avg_train_loss: 0.2561 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [1100 / 1130] avg_train_loss: 0.2578 | train_auc: 0.981 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 80 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2975 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2072 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4649 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5382 | val_auc: 0.8217 | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5564 | val_auc: 0.8587 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 81
[TRAIN] Train model
Epoch [81 / 200] Step: [100 / 1130] avg_train_loss: 0.1989 | train_auc: 0.99 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [200 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [300 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [400 / 1130] avg_train_loss: 0.2617 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [500 / 1130] avg_train_loss: 0.278 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [600 / 1130] avg_train_loss: 0.2695 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [700 / 1130] avg_train_loss: 0.2571 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [800 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [900 / 1130] avg_train_loss: 0.2477 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [1000 / 1130] avg_train_loss: 0.2474 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [1100 / 1130] avg_train_loss: 0.2396 | train_auc: 0.9852 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 81 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2108 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1587 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4514 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5681 | val_auc: 0.8039 | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5853 | val_auc: 0.8454 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 82
[TRAIN] Train model
Epoch [82 / 200] Step: [100 / 1130] avg_train_loss: 0.2484 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [200 / 1130] avg_train_loss: 0.2511 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [300 / 1130] avg_train_loss: 0.2839 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [400 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [500 / 1130] avg_train_loss: 0.2704 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [600 / 1130] avg_train_loss: 0.2572 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [700 / 1130] avg_train_loss: 0.2416 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [800 / 1130] avg_train_loss: 0.2397 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [900 / 1130] avg_train_loss: 0.2383 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [1000 / 1130] avg_train_loss: 0.2355 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [1100 / 1130] avg_train_loss: 0.2308 | train_auc: 0.9857 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 82 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2096 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1525 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4426 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5629 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6044 | val_auc: 0.8543 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 83
[TRAIN] Train model
Epoch [83 / 200] Step: [100 / 1130] avg_train_loss: 0.1681 | train_auc: 0.9955 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [200 / 1130] avg_train_loss: 0.2016 | train_auc: 0.9926 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [300 / 1130] avg_train_loss: 0.2314 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [400 / 1130] avg_train_loss: 0.2535 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [500 / 1130] avg_train_loss: 0.2546 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [600 / 1130] avg_train_loss: 0.2552 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [700 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [800 / 1130] avg_train_loss: 0.2558 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [900 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [1000 / 1130] avg_train_loss: 0.2541 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [1100 / 1130] avg_train_loss: 0.2503 | train_auc: 0.9825 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 83 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2913 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2134 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.468 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5463 | val_auc: 0.8226 | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5626 | val_auc: 0.8552 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 84
[TRAIN] Train model
Epoch [84 / 200] Step: [100 / 1130] avg_train_loss: 0.2266 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [200 / 1130] avg_train_loss: 0.2946 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [300 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [400 / 1130] avg_train_loss: 0.25 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [500 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [600 / 1130] avg_train_loss: 0.2546 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [700 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [800 / 1130] avg_train_loss: 0.2451 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [900 / 1130] avg_train_loss: 0.2418 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [1000 / 1130] avg_train_loss: 0.248 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [1100 / 1130] avg_train_loss: 0.2482 | train_auc: 0.9833 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 84 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1624 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1244 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4363 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5826 | val_auc: 0.7776 | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6335 | val_auc: 0.8378 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 85
[TRAIN] Train model
Epoch [85 / 200] Step: [100 / 1130] avg_train_loss: 0.3395 | train_auc: 0.9648 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [200 / 1130] avg_train_loss: 0.2659 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [300 / 1130] avg_train_loss: 0.2671 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [400 / 1130] avg_train_loss: 0.2614 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [500 / 1130] avg_train_loss: 0.2587 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [600 / 1130] avg_train_loss: 0.2514 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [700 / 1130] avg_train_loss: 0.2464 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [800 / 1130] avg_train_loss: 0.2469 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [900 / 1130] avg_train_loss: 0.2546 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [1000 / 1130] avg_train_loss: 0.2467 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [1100 / 1130] avg_train_loss: 0.2443 | train_auc: 0.9846 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 85 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1893 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1508 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4356 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.556 | val_auc: 0.7912 | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5943 | val_auc: 0.8275 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 86
[TRAIN] Train model
Epoch [86 / 200] Step: [100 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [200 / 1130] avg_train_loss: 0.2358 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [300 / 1130] avg_train_loss: 0.251 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [400 / 1130] avg_train_loss: 0.2377 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [500 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [600 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [700 / 1130] avg_train_loss: 0.2692 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [800 / 1130] avg_train_loss: 0.2604 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [900 / 1130] avg_train_loss: 0.2613 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [1000 / 1130] avg_train_loss: 0.2557 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [1100 / 1130] avg_train_loss: 0.2658 | train_auc: 0.9793 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 86 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1391 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1178 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4101 | val_auc: 0.672 | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5805 | val_auc: 0.7691 | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6483 | val_auc: 0.8128 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 87
[TRAIN] Train model
Epoch [87 / 200] Step: [100 / 1130] avg_train_loss: 0.1858 | train_auc: 0.9955 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [200 / 1130] avg_train_loss: 0.2287 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [300 / 1130] avg_train_loss: 0.2363 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [400 / 1130] avg_train_loss: 0.2268 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [500 / 1130] avg_train_loss: 0.2178 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [600 / 1130] avg_train_loss: 0.2167 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [700 / 1130] avg_train_loss: 0.2104 | train_auc: 0.9914 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [800 / 1130] avg_train_loss: 0.2137 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [900 / 1130] avg_train_loss: 0.2269 | train_auc: 0.9893 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [1000 / 1130] avg_train_loss: 0.2314 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [1100 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9881 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 87 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2902 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2008 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4647 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5516 | val_auc: 0.8192 | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5764 | val_auc: 0.8543 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 88
[TRAIN] Train model
Epoch [88 / 200] Step: [100 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [200 / 1130] avg_train_loss: 0.2536 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [300 / 1130] avg_train_loss: 0.2401 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [400 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [500 / 1130] avg_train_loss: 0.2447 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [600 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [700 / 1130] avg_train_loss: 0.2391 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [800 / 1130] avg_train_loss: 0.2592 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [900 / 1130] avg_train_loss: 0.2527 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [1000 / 1130] avg_train_loss: 0.2526 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [1100 / 1130] avg_train_loss: 0.2495 | train_auc: 0.9829 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 88 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1066 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0884 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4162 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6024 | val_auc: 0.7759 | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6812 | val_auc: 0.828 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 89
[TRAIN] Train model
Epoch [89 / 200] Step: [100 / 1130] avg_train_loss: 0.2441 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [200 / 1130] avg_train_loss: 0.2603 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [300 / 1130] avg_train_loss: 0.2633 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [400 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [500 / 1130] avg_train_loss: 0.274 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [600 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [700 / 1130] avg_train_loss: 0.2718 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [800 / 1130] avg_train_loss: 0.2646 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [900 / 1130] avg_train_loss: 0.2639 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [1000 / 1130] avg_train_loss: 0.2596 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [1100 / 1130] avg_train_loss: 0.247 | train_auc: 0.9818 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 89 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1392 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1083 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4136 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5822 | val_auc: 0.7835 | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6402 | val_auc: 0.8298 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 90
[TRAIN] Train model
Epoch [90 / 200] Step: [100 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9925 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [200 / 1130] avg_train_loss: 0.1834 | train_auc: 0.995 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [300 / 1130] avg_train_loss: 0.1804 | train_auc: 0.9956 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [400 / 1130] avg_train_loss: 0.2053 | train_auc: 0.9925 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [500 / 1130] avg_train_loss: 0.2123 | train_auc: 0.9908 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [600 / 1130] avg_train_loss: 0.2164 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [700 / 1130] avg_train_loss: 0.2185 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [800 / 1130] avg_train_loss: 0.227 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [900 / 1130] avg_train_loss: 0.2352 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [1000 / 1130] avg_train_loss: 0.2347 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [1100 / 1130] avg_train_loss: 0.2393 | train_auc: 0.9845 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 90 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2768 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1979 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4701 | val_auc: 0.7434 | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5676 | val_auc: 0.8251 | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5891 | val_auc: 0.852 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 91
[TRAIN] Train model
Epoch [91 / 200] Step: [100 / 1130] avg_train_loss: 0.233 | train_auc: 0.998 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [200 / 1130] avg_train_loss: 0.1979 | train_auc: 0.9968 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [300 / 1130] avg_train_loss: 0.2089 | train_auc: 0.9937 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [400 / 1130] avg_train_loss: 0.2124 | train_auc: 0.9942 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [500 / 1130] avg_train_loss: 0.2169 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [600 / 1130] avg_train_loss: 0.2192 | train_auc: 0.9913 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [700 / 1130] avg_train_loss: 0.2115 | train_auc: 0.9926 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [800 / 1130] avg_train_loss: 0.217 | train_auc: 0.9913 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [900 / 1130] avg_train_loss: 0.2158 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [1000 / 1130] avg_train_loss: 0.2126 | train_auc: 0.9915 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [1100 / 1130] avg_train_loss: 0.2206 | train_auc: 0.9877 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 91 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1601 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.121 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4256 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5798 | val_auc: 0.8056 | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6418 | val_auc: 0.8449 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 92
[TRAIN] Train model
Epoch [92 / 200] Step: [100 / 1130] avg_train_loss: 0.2373 | train_auc: 0.9677 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [200 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [300 / 1130] avg_train_loss: 0.248 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [400 / 1130] avg_train_loss: 0.2518 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [500 / 1130] avg_train_loss: 0.2517 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [600 / 1130] avg_train_loss: 0.2565 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [700 / 1130] avg_train_loss: 0.249 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [800 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [900 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [1000 / 1130] avg_train_loss: 0.2477 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [1100 / 1130] avg_train_loss: 0.247 | train_auc: 0.9836 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 92 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3255 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.227 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4923 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.557 | val_auc: 0.8192 | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5754 | val_auc: 0.8543 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 93
[TRAIN] Train model
Epoch [93 / 200] Step: [100 / 1130] avg_train_loss: 0.2444 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [200 / 1130] avg_train_loss: 0.2221 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [300 / 1130] avg_train_loss: 0.2248 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [400 / 1130] avg_train_loss: 0.2325 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [500 / 1130] avg_train_loss: 0.2373 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [600 / 1130] avg_train_loss: 0.2276 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [700 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [800 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [900 / 1130] avg_train_loss: 0.2427 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [1000 / 1130] avg_train_loss: 0.2378 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [1100 / 1130] avg_train_loss: 0.2369 | train_auc: 0.9847 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 93 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1004 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.094 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4086 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5853 | val_auc: 0.7572 | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6511 | val_auc: 0.8061 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 94
[TRAIN] Train model
Epoch [94 / 200] Step: [100 / 1130] avg_train_loss: 0.261 | train_auc: 0.9899 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [200 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9898 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [300 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [400 / 1130] avg_train_loss: 0.2408 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [500 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [600 / 1130] avg_train_loss: 0.2401 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [700 / 1130] avg_train_loss: 0.2339 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [800 / 1130] avg_train_loss: 0.2388 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [900 / 1130] avg_train_loss: 0.2427 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [1000 / 1130] avg_train_loss: 0.2396 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [1100 / 1130] avg_train_loss: 0.2424 | train_auc: 0.9851 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 94 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2044 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1491 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4445 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5662 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6067 | val_auc: 0.8552 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 95
[TRAIN] Train model
Epoch [95 / 200] Step: [100 / 1130] avg_train_loss: 0.2087 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [200 / 1130] avg_train_loss: 0.1998 | train_auc: 0.9934 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [300 / 1130] avg_train_loss: 0.2205 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [400 / 1130] avg_train_loss: 0.226 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [500 / 1130] avg_train_loss: 0.2362 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [600 / 1130] avg_train_loss: 0.2425 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [700 / 1130] avg_train_loss: 0.2487 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [800 / 1130] avg_train_loss: 0.251 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [900 / 1130] avg_train_loss: 0.2476 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [1000 / 1130] avg_train_loss: 0.2502 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [1100 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9857 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 95 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2947 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2159 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4719 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5439 | val_auc: 0.8234 | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5587 | val_auc: 0.8552 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 96
[TRAIN] Train model
Epoch [96 / 200] Step: [100 / 1130] avg_train_loss: 0.2797 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [200 / 1130] avg_train_loss: 0.2731 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [300 / 1130] avg_train_loss: 0.251 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [400 / 1130] avg_train_loss: 0.2496 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [500 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [600 / 1130] avg_train_loss: 0.2522 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [700 / 1130] avg_train_loss: 0.2587 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [800 / 1130] avg_train_loss: 0.2536 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [900 / 1130] avg_train_loss: 0.2472 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [1000 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [1100 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9835 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 96 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2545 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1877 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4408 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5319 | val_auc: 0.8294 | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5601 | val_auc: 0.8552 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 97
[TRAIN] Train model
Epoch [97 / 200] Step: [100 / 1130] avg_train_loss: 0.2705 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [200 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [300 / 1130] avg_train_loss: 0.2408 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [400 / 1130] avg_train_loss: 0.2372 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [500 / 1130] avg_train_loss: 0.2235 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [600 / 1130] avg_train_loss: 0.2227 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [700 / 1130] avg_train_loss: 0.2268 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [800 / 1130] avg_train_loss: 0.2228 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [900 / 1130] avg_train_loss: 0.2261 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [1000 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [1100 / 1130] avg_train_loss: 0.2337 | train_auc: 0.9865 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 97 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1631 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1273 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4217 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5694 | val_auc: 0.8014 | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6111 | val_auc: 0.8373 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 98
[TRAIN] Train model
Epoch [98 / 200] Step: [100 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [200 / 1130] avg_train_loss: 0.273 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [300 / 1130] avg_train_loss: 0.2388 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [400 / 1130] avg_train_loss: 0.2393 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [500 / 1130] avg_train_loss: 0.252 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [600 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [700 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [800 / 1130] avg_train_loss: 0.2402 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [900 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [1000 / 1130] avg_train_loss: 0.2516 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [1100 / 1130] avg_train_loss: 0.2518 | train_auc: 0.983 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 98 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1495 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4442 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5567 | val_auc: 0.809 | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5889 | val_auc: 0.8471 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 99
[TRAIN] Train model
Epoch [99 / 200] Step: [100 / 1130] avg_train_loss: 0.198 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [200 / 1130] avg_train_loss: 0.2374 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [300 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [400 / 1130] avg_train_loss: 0.2404 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [500 / 1130] avg_train_loss: 0.2315 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [600 / 1130] avg_train_loss: 0.2355 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [700 / 1130] avg_train_loss: 0.2352 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [800 / 1130] avg_train_loss: 0.2407 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [900 / 1130] avg_train_loss: 0.2354 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [1000 / 1130] avg_train_loss: 0.2377 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [1100 / 1130] avg_train_loss: 0.2371 | train_auc: 0.9849 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 99 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2332 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.174 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4421 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5512 | val_auc: 0.8192 | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5774 | val_auc: 0.8525 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 100
[TRAIN] Train model
Epoch [100 / 200] Step: [100 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [200 / 1130] avg_train_loss: 0.2276 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [300 / 1130] avg_train_loss: 0.2312 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [400 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [500 / 1130] avg_train_loss: 0.2489 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [600 / 1130] avg_train_loss: 0.2469 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [700 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [800 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [900 / 1130] avg_train_loss: 0.2292 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [1000 / 1130] avg_train_loss: 0.2299 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [1100 / 1130] avg_train_loss: 0.2332 | train_auc: 0.9839 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 100 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2977 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.211 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4606 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5319 | val_auc: 0.8226 | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5509 | val_auc: 0.8552 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 101
[TRAIN] Train model
Epoch [101 / 200] Step: [100 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [200 / 1130] avg_train_loss: 0.2658 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [300 / 1130] avg_train_loss: 0.2277 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [400 / 1130] avg_train_loss: 0.2422 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [500 / 1130] avg_train_loss: 0.2429 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [600 / 1130] avg_train_loss: 0.2425 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [700 / 1130] avg_train_loss: 0.2474 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [800 / 1130] avg_train_loss: 0.248 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [900 / 1130] avg_train_loss: 0.2429 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [1000 / 1130] avg_train_loss: 0.2335 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [1100 / 1130] avg_train_loss: 0.2297 | train_auc: 0.9861 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 101 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3062 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2259 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4998 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5783 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.596 | val_auc: 0.8543 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 102
[TRAIN] Train model
Epoch [102 / 200] Step: [100 / 1130] avg_train_loss: 0.1436 | train_auc: 0.9949 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [200 / 1130] avg_train_loss: 0.1679 | train_auc: 0.9952 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [300 / 1130] avg_train_loss: 0.2024 | train_auc: 0.9918 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [400 / 1130] avg_train_loss: 0.2009 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [500 / 1130] avg_train_loss: 0.2046 | train_auc: 0.9907 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [600 / 1130] avg_train_loss: 0.2116 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [700 / 1130] avg_train_loss: 0.2056 | train_auc: 0.9893 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [800 / 1130] avg_train_loss: 0.2177 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [900 / 1130] avg_train_loss: 0.2144 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [1000 / 1130] avg_train_loss: 0.2179 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [1100 / 1130] avg_train_loss: 0.2248 | train_auc: 0.9875 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 102 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1692 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.128 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4309 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5685 | val_auc: 0.8073 | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6183 | val_auc: 0.8445 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 103
[TRAIN] Train model
Epoch [103 / 200] Step: [100 / 1130] avg_train_loss: 0.2204 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [200 / 1130] avg_train_loss: 0.2138 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [300 / 1130] avg_train_loss: 0.2403 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [400 / 1130] avg_train_loss: 0.2646 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [500 / 1130] avg_train_loss: 0.2747 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [600 / 1130] avg_train_loss: 0.263 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [700 / 1130] avg_train_loss: 0.2779 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [800 / 1130] avg_train_loss: 0.2764 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [900 / 1130] avg_train_loss: 0.2641 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [1000 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [1100 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9798 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 103 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.217 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1587 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4324 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5514 | val_auc: 0.809 | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5887 | val_auc: 0.8467 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 104
[TRAIN] Train model
Epoch [104 / 200] Step: [100 / 1130] avg_train_loss: 0.301 | train_auc: 0.9538 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [200 / 1130] avg_train_loss: 0.2667 | train_auc: 0.9727 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [300 / 1130] avg_train_loss: 0.2227 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [400 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [500 / 1130] avg_train_loss: 0.2352 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [600 / 1130] avg_train_loss: 0.2244 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [700 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [800 / 1130] avg_train_loss: 0.2378 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [900 / 1130] avg_train_loss: 0.2486 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [1000 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [1100 / 1130] avg_train_loss: 0.2489 | train_auc: 0.9828 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 104 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1234 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1032 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.404 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5728 | val_auc: 0.775 | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.631 | val_auc: 0.8311 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 105
[TRAIN] Train model
Epoch [105 / 200] Step: [100 / 1130] avg_train_loss: 0.3342 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [200 / 1130] avg_train_loss: 0.2433 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [300 / 1130] avg_train_loss: 0.2425 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [400 / 1130] avg_train_loss: 0.2543 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [500 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [600 / 1130] avg_train_loss: 0.2516 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [700 / 1130] avg_train_loss: 0.2493 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [800 / 1130] avg_train_loss: 0.2473 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [900 / 1130] avg_train_loss: 0.2487 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [1000 / 1130] avg_train_loss: 0.2482 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [1100 / 1130] avg_train_loss: 0.2609 | train_auc: 0.9815 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 105 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1637 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1296 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4425 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5815 | val_auc: 0.7852 | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6116 | val_auc: 0.8311 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 106
[TRAIN] Train model
Epoch [106 / 200] Step: [100 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9686 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [200 / 1130] avg_train_loss: 0.2144 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [300 / 1130] avg_train_loss: 0.2066 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [400 / 1130] avg_train_loss: 0.2025 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [500 / 1130] avg_train_loss: 0.1995 | train_auc: 0.991 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [600 / 1130] avg_train_loss: 0.2096 | train_auc: 0.9899 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [700 / 1130] avg_train_loss: 0.2133 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [800 / 1130] avg_train_loss: 0.2117 | train_auc: 0.9895 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [900 / 1130] avg_train_loss: 0.2133 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [1000 / 1130] avg_train_loss: 0.2192 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [1100 / 1130] avg_train_loss: 0.2136 | train_auc: 0.9894 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 106 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2071 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1505 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4502 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5564 | val_auc: 0.7988 | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6053 | val_auc: 0.8427 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 107
[TRAIN] Train model
Epoch [107 / 200] Step: [100 / 1130] avg_train_loss: 0.1766 | train_auc: 0.9958 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [200 / 1130] avg_train_loss: 0.2048 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [300 / 1130] avg_train_loss: 0.202 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [400 / 1130] avg_train_loss: 0.2158 | train_auc: 0.9901 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [500 / 1130] avg_train_loss: 0.2174 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [600 / 1130] avg_train_loss: 0.2213 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [700 / 1130] avg_train_loss: 0.2376 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [800 / 1130] avg_train_loss: 0.2351 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [900 / 1130] avg_train_loss: 0.2412 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [1000 / 1130] avg_train_loss: 0.2452 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [1100 / 1130] avg_train_loss: 0.2501 | train_auc: 0.9827 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 107 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.254 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1842 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4525 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5579 | val_auc: 0.8217 | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5809 | val_auc: 0.8552 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 108
[TRAIN] Train model
Epoch [108 / 200] Step: [100 / 1130] avg_train_loss: 0.1899 | train_auc: 0.9946 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [200 / 1130] avg_train_loss: 0.2581 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [300 / 1130] avg_train_loss: 0.2667 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [400 / 1130] avg_train_loss: 0.2718 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [500 / 1130] avg_train_loss: 0.2543 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [600 / 1130] avg_train_loss: 0.2521 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [700 / 1130] avg_train_loss: 0.2402 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [800 / 1130] avg_train_loss: 0.2507 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [900 / 1130] avg_train_loss: 0.242 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [1000 / 1130] avg_train_loss: 0.2366 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [1100 / 1130] avg_train_loss: 0.2449 | train_auc: 0.9842 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 108 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1142 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0968 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4002 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5933 | val_auc: 0.7649 | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6772 | val_auc: 0.8168 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 109
[TRAIN] Train model
Epoch [109 / 200] Step: [100 / 1130] avg_train_loss: 0.3087 | train_auc: 0.9654 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [200 / 1130] avg_train_loss: 0.2793 | train_auc: 0.9677 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [300 / 1130] avg_train_loss: 0.3193 | train_auc: 0.9627 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [400 / 1130] avg_train_loss: 0.2995 | train_auc: 0.9683 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [500 / 1130] avg_train_loss: 0.2916 | train_auc: 0.9708 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [600 / 1130] avg_train_loss: 0.2672 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [700 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [800 / 1130] avg_train_loss: 0.2805 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [900 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [1000 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [1100 / 1130] avg_train_loss: 0.2731 | train_auc: 0.9752 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 109 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.185 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1495 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4407 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.542 | val_auc: 0.792 | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5672 | val_auc: 0.8414 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 110
[TRAIN] Train model
Epoch [110 / 200] Step: [100 / 1130] avg_train_loss: 0.2833 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [200 / 1130] avg_train_loss: 0.2675 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [300 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [400 / 1130] avg_train_loss: 0.2361 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [500 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [600 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [700 / 1130] avg_train_loss: 0.233 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [800 / 1130] avg_train_loss: 0.2356 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [900 / 1130] avg_train_loss: 0.2385 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [1000 / 1130] avg_train_loss: 0.2339 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [1100 / 1130] avg_train_loss: 0.228 | train_auc: 0.9877 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 110 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1996 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1497 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4316 | val_auc: 0.7407 | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5585 | val_auc: 0.8158 | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.597 | val_auc: 0.8422 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 111
[TRAIN] Train model
Epoch [111 / 200] Step: [100 / 1130] avg_train_loss: 0.3898 | train_auc: 0.9494 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [200 / 1130] avg_train_loss: 0.2839 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [300 / 1130] avg_train_loss: 0.2719 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [400 / 1130] avg_train_loss: 0.2619 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [500 / 1130] avg_train_loss: 0.2526 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [600 / 1130] avg_train_loss: 0.2615 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [700 / 1130] avg_train_loss: 0.2503 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [800 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [900 / 1130] avg_train_loss: 0.2643 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [1000 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [1100 / 1130] avg_train_loss: 0.256 | train_auc: 0.9807 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 111 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1686 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.124 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4232 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5612 | val_auc: 0.8115 | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.608 | val_auc: 0.8485 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 112
[TRAIN] Train model
Epoch [112 / 200] Step: [100 / 1130] avg_train_loss: 0.2018 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [200 / 1130] avg_train_loss: 0.2523 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [300 / 1130] avg_train_loss: 0.2735 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [400 / 1130] avg_train_loss: 0.2759 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [500 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [600 / 1130] avg_train_loss: 0.2479 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [700 / 1130] avg_train_loss: 0.2385 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [800 / 1130] avg_train_loss: 0.2376 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [900 / 1130] avg_train_loss: 0.2479 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [1000 / 1130] avg_train_loss: 0.2474 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [1100 / 1130] avg_train_loss: 0.2467 | train_auc: 0.9812 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 112 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2631 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1929 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.437 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5384 | val_auc: 0.8132 | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5554 | val_auc: 0.8525 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 113
[TRAIN] Train model
Epoch [113 / 200] Step: [100 / 1130] avg_train_loss: 0.3714 | train_auc: 0.955 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [200 / 1130] avg_train_loss: 0.2981 | train_auc: 0.9681 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [300 / 1130] avg_train_loss: 0.2854 | train_auc: 0.9682 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [400 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [500 / 1130] avg_train_loss: 0.2487 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [600 / 1130] avg_train_loss: 0.2432 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [700 / 1130] avg_train_loss: 0.2456 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [800 / 1130] avg_train_loss: 0.2385 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [900 / 1130] avg_train_loss: 0.2385 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [1000 / 1130] avg_train_loss: 0.24 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [1100 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9827 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 113 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2467 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1833 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.456 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5584 | val_auc: 0.7997 | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5801 | val_auc: 0.8503 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 114
[TRAIN] Train model
Epoch [114 / 200] Step: [100 / 1130] avg_train_loss: 0.3105 | train_auc: 0.9612 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [200 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [300 / 1130] avg_train_loss: 0.2219 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [400 / 1130] avg_train_loss: 0.2412 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [500 / 1130] avg_train_loss: 0.2285 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [600 / 1130] avg_train_loss: 0.2377 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [700 / 1130] avg_train_loss: 0.2331 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [800 / 1130] avg_train_loss: 0.2306 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [900 / 1130] avg_train_loss: 0.2277 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [1000 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [1100 / 1130] avg_train_loss: 0.2259 | train_auc: 0.9863 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 114 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1789 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1368 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4177 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5447 | val_auc: 0.8022 | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5915 | val_auc: 0.8373 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 115
[TRAIN] Train model
Epoch [115 / 200] Step: [100 / 1130] avg_train_loss: 0.1846 | train_auc: 0.9909 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [200 / 1130] avg_train_loss: 0.2643 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [300 / 1130] avg_train_loss: 0.2717 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [400 / 1130] avg_train_loss: 0.2768 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [500 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [600 / 1130] avg_train_loss: 0.2506 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [700 / 1130] avg_train_loss: 0.2407 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [800 / 1130] avg_train_loss: 0.2356 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [900 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [1000 / 1130] avg_train_loss: 0.2405 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [1100 / 1130] avg_train_loss: 0.2349 | train_auc: 0.9849 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 115 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1231 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.103 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4081 | val_auc: 0.6455 | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5903 | val_auc: 0.7581 | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.66 | val_auc: 0.8151 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 116
[TRAIN] Train model
Epoch [116 / 200] Step: [100 / 1130] avg_train_loss: 0.1879 | train_auc: 0.9956 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [200 / 1130] avg_train_loss: 0.2048 | train_auc: 0.993 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [300 / 1130] avg_train_loss: 0.1913 | train_auc: 0.9948 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [400 / 1130] avg_train_loss: 0.2118 | train_auc: 0.9915 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [500 / 1130] avg_train_loss: 0.2209 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [600 / 1130] avg_train_loss: 0.2297 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [700 / 1130] avg_train_loss: 0.2363 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [800 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [900 / 1130] avg_train_loss: 0.2292 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [1000 / 1130] avg_train_loss: 0.2265 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [1100 / 1130] avg_train_loss: 0.226 | train_auc: 0.9866 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 116 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3528 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2471 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4965 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5627 | val_auc: 0.8226 | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5948 | val_auc: 0.8547 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 117
[TRAIN] Train model
Epoch [117 / 200] Step: [100 / 1130] avg_train_loss: 0.3214 | train_auc: 0.9673 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [200 / 1130] avg_train_loss: 0.3197 | train_auc: 0.9652 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [300 / 1130] avg_train_loss: 0.3024 | train_auc: 0.9693 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [400 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [500 / 1130] avg_train_loss: 0.2872 | train_auc: 0.9699 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [600 / 1130] avg_train_loss: 0.2801 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [700 / 1130] avg_train_loss: 0.2815 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [800 / 1130] avg_train_loss: 0.277 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [900 / 1130] avg_train_loss: 0.2721 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [1000 / 1130] avg_train_loss: 0.258 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [1100 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9794 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 117 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1139 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.097 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4202 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6032 | val_auc: 0.7606 | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6722 | val_auc: 0.8204 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 118
[TRAIN] Train model
Epoch [118 / 200] Step: [100 / 1130] avg_train_loss: 0.2705 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [200 / 1130] avg_train_loss: 0.2496 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [300 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [400 / 1130] avg_train_loss: 0.2495 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [500 / 1130] avg_train_loss: 0.2381 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [600 / 1130] avg_train_loss: 0.2365 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [700 / 1130] avg_train_loss: 0.2311 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [800 / 1130] avg_train_loss: 0.2252 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [900 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [1000 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [1100 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9856 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 118 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1886 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1385 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4381 | val_auc: 0.6376 | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5702 | val_auc: 0.7929 | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6102 | val_auc: 0.8396 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 119
[TRAIN] Train model
Epoch [119 / 200] Step: [100 / 1130] avg_train_loss: 0.2629 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [200 / 1130] avg_train_loss: 0.2274 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [300 / 1130] avg_train_loss: 0.2378 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [400 / 1130] avg_train_loss: 0.2276 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [500 / 1130] avg_train_loss: 0.2357 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [600 / 1130] avg_train_loss: 0.233 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [700 / 1130] avg_train_loss: 0.2299 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [800 / 1130] avg_train_loss: 0.2369 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [900 / 1130] avg_train_loss: 0.2383 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [1000 / 1130] avg_train_loss: 0.247 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [1100 / 1130] avg_train_loss: 0.2475 | train_auc: 0.983 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 119 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1186 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0963 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4234 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5975 | val_auc: 0.7767 | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6757 | val_auc: 0.8271 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 120
[TRAIN] Train model
Epoch [120 / 200] Step: [100 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [200 / 1130] avg_train_loss: 0.2716 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [300 / 1130] avg_train_loss: 0.2954 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [400 / 1130] avg_train_loss: 0.2818 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [500 / 1130] avg_train_loss: 0.2952 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [600 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [700 / 1130] avg_train_loss: 0.2674 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [800 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [900 / 1130] avg_train_loss: 0.263 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [1000 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [1100 / 1130] avg_train_loss: 0.262 | train_auc: 0.9789 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 120 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1148 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0952 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4114 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5786 | val_auc: 0.7767 | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6369 | val_auc: 0.8329 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 121
[TRAIN] Train model
Epoch [121 / 200] Step: [100 / 1130] avg_train_loss: 0.2338 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [200 / 1130] avg_train_loss: 0.221 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [300 / 1130] avg_train_loss: 0.2174 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [400 / 1130] avg_train_loss: 0.2318 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [500 / 1130] avg_train_loss: 0.2302 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [600 / 1130] avg_train_loss: 0.2272 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [700 / 1130] avg_train_loss: 0.228 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [800 / 1130] avg_train_loss: 0.2258 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [900 / 1130] avg_train_loss: 0.2177 | train_auc: 0.9876 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [1000 / 1130] avg_train_loss: 0.2162 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [1100 / 1130] avg_train_loss: 0.2241 | train_auc: 0.9871 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 121 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2954 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2093 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4534 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5344 | val_auc: 0.8226 | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5601 | val_auc: 0.8534 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 122
[TRAIN] Train model
Epoch [122 / 200] Step: [100 / 1130] avg_train_loss: 0.363 | train_auc: 0.9584 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [200 / 1130] avg_train_loss: 0.3241 | train_auc: 0.9671 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [300 / 1130] avg_train_loss: 0.3015 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [400 / 1130] avg_train_loss: 0.2737 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [500 / 1130] avg_train_loss: 0.2647 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [600 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [700 / 1130] avg_train_loss: 0.2449 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [800 / 1130] avg_train_loss: 0.241 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [900 / 1130] avg_train_loss: 0.2387 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [1000 / 1130] avg_train_loss: 0.2431 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [1100 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9838 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 122 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3169 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2233 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4884 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5659 | val_auc: 0.8039 | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5831 | val_auc: 0.8471 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 123
[TRAIN] Train model
Epoch [123 / 200] Step: [100 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [200 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [300 / 1130] avg_train_loss: 0.2559 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [400 / 1130] avg_train_loss: 0.2509 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [500 / 1130] avg_train_loss: 0.2333 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [600 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [700 / 1130] avg_train_loss: 0.2289 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [800 / 1130] avg_train_loss: 0.2272 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [900 / 1130] avg_train_loss: 0.2323 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [1000 / 1130] avg_train_loss: 0.2343 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [1100 / 1130] avg_train_loss: 0.2324 | train_auc: 0.9848 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 123 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1618 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.122 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.427 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5654 | val_auc: 0.7903 | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6134 | val_auc: 0.84 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 124
[TRAIN] Train model
Epoch [124 / 200] Step: [100 / 1130] avg_train_loss: 0.2072 | train_auc: 0.9927 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [200 / 1130] avg_train_loss: 0.2377 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [300 / 1130] avg_train_loss: 0.2205 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [400 / 1130] avg_train_loss: 0.2133 | train_auc: 0.9889 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [500 / 1130] avg_train_loss: 0.2322 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [600 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [700 / 1130] avg_train_loss: 0.232 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [800 / 1130] avg_train_loss: 0.2308 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [900 / 1130] avg_train_loss: 0.2447 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [1000 / 1130] avg_train_loss: 0.239 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [1100 / 1130] avg_train_loss: 0.2443 | train_auc: 0.9813 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 124 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2819 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2015 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4596 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5398 | val_auc: 0.8132 | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5645 | val_auc: 0.8489 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 125
[TRAIN] Train model
Epoch [125 / 200] Step: [100 / 1130] avg_train_loss: 0.2604 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [200 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [300 / 1130] avg_train_loss: 0.2229 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [400 / 1130] avg_train_loss: 0.2491 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [500 / 1130] avg_train_loss: 0.2476 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [600 / 1130] avg_train_loss: 0.2493 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [700 / 1130] avg_train_loss: 0.2391 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [800 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [900 / 1130] avg_train_loss: 0.2439 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [1000 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [1100 / 1130] avg_train_loss: 0.2363 | train_auc: 0.9856 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 125 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3555 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2491 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5092 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5689 | val_auc: 0.8149 | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5832 | val_auc: 0.8512 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 126
[TRAIN] Train model
Epoch [126 / 200] Step: [100 / 1130] avg_train_loss: 0.2087 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [200 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [300 / 1130] avg_train_loss: 0.2312 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [400 / 1130] avg_train_loss: 0.2358 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [500 / 1130] avg_train_loss: 0.232 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [600 / 1130] avg_train_loss: 0.227 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [700 / 1130] avg_train_loss: 0.2403 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [800 / 1130] avg_train_loss: 0.2412 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [900 / 1130] avg_train_loss: 0.2333 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [1000 / 1130] avg_train_loss: 0.2291 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [1100 / 1130] avg_train_loss: 0.2326 | train_auc: 0.9864 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 126 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1692 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1245 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4404 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5811 | val_auc: 0.7929 | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.626 | val_auc: 0.8409 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 127
[TRAIN] Train model
Epoch [127 / 200] Step: [100 / 1130] avg_train_loss: 0.2685 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [200 / 1130] avg_train_loss: 0.2337 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [300 / 1130] avg_train_loss: 0.2561 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [400 / 1130] avg_train_loss: 0.25 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [500 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [600 / 1130] avg_train_loss: 0.259 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [700 / 1130] avg_train_loss: 0.2549 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [800 / 1130] avg_train_loss: 0.2552 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [900 / 1130] avg_train_loss: 0.2517 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [1000 / 1130] avg_train_loss: 0.2507 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [1100 / 1130] avg_train_loss: 0.2476 | train_auc: 0.982 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 127 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1163 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0982 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3969 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5786 | val_auc: 0.7683 | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6592 | val_auc: 0.8186 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 128
[TRAIN] Train model
Epoch [128 / 200] Step: [100 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9737 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [200 / 1130] avg_train_loss: 0.245 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [300 / 1130] avg_train_loss: 0.2424 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [400 / 1130] avg_train_loss: 0.2429 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [500 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [600 / 1130] avg_train_loss: 0.2518 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [700 / 1130] avg_train_loss: 0.2415 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [800 / 1130] avg_train_loss: 0.2484 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [900 / 1130] avg_train_loss: 0.2447 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [1000 / 1130] avg_train_loss: 0.2422 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [1100 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9825 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 128 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1761 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.136 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4302 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5666 | val_auc: 0.792 | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5984 | val_auc: 0.8365 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 129
[TRAIN] Train model
Epoch [129 / 200] Step: [100 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [200 / 1130] avg_train_loss: 0.2861 | train_auc: 0.9696 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [300 / 1130] avg_train_loss: 0.2491 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [400 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [500 / 1130] avg_train_loss: 0.2498 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [600 / 1130] avg_train_loss: 0.2629 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [700 / 1130] avg_train_loss: 0.26 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [800 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [900 / 1130] avg_train_loss: 0.2566 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [1000 / 1130] avg_train_loss: 0.2588 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [1100 / 1130] avg_train_loss: 0.2503 | train_auc: 0.9823 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 129 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3516 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2433 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4985 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.566 | val_auc: 0.8149 | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6037 | val_auc: 0.8512 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 130
[TRAIN] Train model
Epoch [130 / 200] Step: [100 / 1130] avg_train_loss: 0.284 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [200 / 1130] avg_train_loss: 0.2612 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [300 / 1130] avg_train_loss: 0.2298 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [400 / 1130] avg_train_loss: 0.235 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [500 / 1130] avg_train_loss: 0.253 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [600 / 1130] avg_train_loss: 0.2448 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [700 / 1130] avg_train_loss: 0.264 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [800 / 1130] avg_train_loss: 0.2557 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [900 / 1130] avg_train_loss: 0.2619 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [1000 / 1130] avg_train_loss: 0.2645 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [1100 / 1130] avg_train_loss: 0.2676 | train_auc: 0.9801 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 130 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2464 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1769 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4334 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5369 | val_auc: 0.8217 | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.576 | val_auc: 0.8471 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 131
[TRAIN] Train model
Epoch [131 / 200] Step: [100 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [200 / 1130] avg_train_loss: 0.245 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [300 / 1130] avg_train_loss: 0.2428 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [400 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [500 / 1130] avg_train_loss: 0.2559 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [600 / 1130] avg_train_loss: 0.2538 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [700 / 1130] avg_train_loss: 0.2347 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [800 / 1130] avg_train_loss: 0.2357 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [900 / 1130] avg_train_loss: 0.235 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [1000 / 1130] avg_train_loss: 0.2289 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [1100 / 1130] avg_train_loss: 0.2343 | train_auc: 0.9853 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 131 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2737 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.195 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.462 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5396 | val_auc: 0.8217 | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5613 | val_auc: 0.8525 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 132
[TRAIN] Train model
Epoch [132 / 200] Step: [100 / 1130] avg_train_loss: 0.1904 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [200 / 1130] avg_train_loss: 0.2606 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [300 / 1130] avg_train_loss: 0.2515 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [400 / 1130] avg_train_loss: 0.2453 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [500 / 1130] avg_train_loss: 0.2262 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [600 / 1130] avg_train_loss: 0.2263 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [700 / 1130] avg_train_loss: 0.2244 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [800 / 1130] avg_train_loss: 0.24 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [900 / 1130] avg_train_loss: 0.237 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [1000 / 1130] avg_train_loss: 0.2416 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [1100 / 1130] avg_train_loss: 0.2407 | train_auc: 0.983 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 132 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1243 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1009 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4108 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.574 | val_auc: 0.7912 | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6478 | val_auc: 0.8347 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 133
[TRAIN] Train model
Epoch [133 / 200] Step: [100 / 1130] avg_train_loss: 0.2487 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [200 / 1130] avg_train_loss: 0.2259 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [300 / 1130] avg_train_loss: 0.2327 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [400 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [500 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [600 / 1130] avg_train_loss: 0.2363 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [700 / 1130] avg_train_loss: 0.2271 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [800 / 1130] avg_train_loss: 0.231 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [900 / 1130] avg_train_loss: 0.2265 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [1000 / 1130] avg_train_loss: 0.2284 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [1100 / 1130] avg_train_loss: 0.2357 | train_auc: 0.9857 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 133 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3743 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2842 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5314 | val_auc: 0.7593 | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.603 | val_auc: 0.826 | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6119 | val_auc: 0.8592 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 134
[TRAIN] Train model
Epoch [134 / 200] Step: [100 / 1130] avg_train_loss: 0.2467 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [200 / 1130] avg_train_loss: 0.2188 | train_auc: 0.9899 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [300 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [400 / 1130] avg_train_loss: 0.2314 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [500 / 1130] avg_train_loss: 0.24 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [600 / 1130] avg_train_loss: 0.2407 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [700 / 1130] avg_train_loss: 0.2415 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [800 / 1130] avg_train_loss: 0.2519 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [900 / 1130] avg_train_loss: 0.2527 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [1000 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [1100 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9798 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 134 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.085 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0806 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3978 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6114 | val_auc: 0.7683 | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7001 | val_auc: 0.8151 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 135
[TRAIN] Train model
Epoch [135 / 200] Step: [100 / 1130] avg_train_loss: 0.2105 | train_auc: 0.9932 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [200 / 1130] avg_train_loss: 0.2473 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [300 / 1130] avg_train_loss: 0.2615 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [400 / 1130] avg_train_loss: 0.2335 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [500 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [600 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [700 / 1130] avg_train_loss: 0.2504 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [800 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [900 / 1130] avg_train_loss: 0.2612 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [1000 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [1100 / 1130] avg_train_loss: 0.2539 | train_auc: 0.979 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 135 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1443 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1168 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4091 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5727 | val_auc: 0.7699 | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6254 | val_auc: 0.8213 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 136
[TRAIN] Train model
Epoch [136 / 200] Step: [100 / 1130] avg_train_loss: 0.1617 | train_auc: 0.9973 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [200 / 1130] avg_train_loss: 0.248 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [300 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [400 / 1130] avg_train_loss: 0.2416 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [500 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [600 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [700 / 1130] avg_train_loss: 0.2429 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [800 / 1130] avg_train_loss: 0.2413 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [900 / 1130] avg_train_loss: 0.2381 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [1000 / 1130] avg_train_loss: 0.2356 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [1100 / 1130] avg_train_loss: 0.2325 | train_auc: 0.9859 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 136 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1954 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1467 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4368 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5592 | val_auc: 0.8081 | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5955 | val_auc: 0.8454 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 137
[TRAIN] Train model
Epoch [137 / 200] Step: [100 / 1130] avg_train_loss: 0.3045 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [200 / 1130] avg_train_loss: 0.2971 | train_auc: 0.9737 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [300 / 1130] avg_train_loss: 0.3258 | train_auc: 0.9682 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [400 / 1130] avg_train_loss: 0.3037 | train_auc: 0.9726 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [500 / 1130] avg_train_loss: 0.2747 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [600 / 1130] avg_train_loss: 0.2664 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [700 / 1130] avg_train_loss: 0.2496 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [800 / 1130] avg_train_loss: 0.2455 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [900 / 1130] avg_train_loss: 0.2479 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [1000 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [1100 / 1130] avg_train_loss: 0.2426 | train_auc: 0.9847 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 137 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1107 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0981 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4159 | val_auc: 0.6481 | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6038 | val_auc: 0.7504 | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6747 | val_auc: 0.8079 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 138
[TRAIN] Train model
Epoch [138 / 200] Step: [100 / 1130] avg_train_loss: 0.2231 | train_auc: 0.9907 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [200 / 1130] avg_train_loss: 0.2372 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [300 / 1130] avg_train_loss: 0.2403 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [400 / 1130] avg_train_loss: 0.2528 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [500 / 1130] avg_train_loss: 0.2534 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [600 / 1130] avg_train_loss: 0.2411 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [700 / 1130] avg_train_loss: 0.2515 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [800 / 1130] avg_train_loss: 0.2527 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [900 / 1130] avg_train_loss: 0.2467 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [1000 / 1130] avg_train_loss: 0.247 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [1100 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9851 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 138 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3106 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2279 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4868 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5701 | val_auc: 0.8065 | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5761 | val_auc: 0.848 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 139
[TRAIN] Train model
Epoch [139 / 200] Step: [100 / 1130] avg_train_loss: 0.2194 | train_auc: 0.993 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [200 / 1130] avg_train_loss: 0.2207 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [300 / 1130] avg_train_loss: 0.1968 | train_auc: 0.9937 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [400 / 1130] avg_train_loss: 0.2139 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [500 / 1130] avg_train_loss: 0.2347 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [600 / 1130] avg_train_loss: 0.2297 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [700 / 1130] avg_train_loss: 0.2278 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [800 / 1130] avg_train_loss: 0.2228 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [900 / 1130] avg_train_loss: 0.2229 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [1000 / 1130] avg_train_loss: 0.2279 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [1100 / 1130] avg_train_loss: 0.2253 | train_auc: 0.9849 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 139 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2816 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1958 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4399 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5235 | val_auc: 0.8268 | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5497 | val_auc: 0.8614 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 140
[TRAIN] Train model
Epoch [140 / 200] Step: [100 / 1130] avg_train_loss: 0.3008 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [200 / 1130] avg_train_loss: 0.3007 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [300 / 1130] avg_train_loss: 0.3208 | train_auc: 0.9702 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [400 / 1130] avg_train_loss: 0.3114 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [500 / 1130] avg_train_loss: 0.2889 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [600 / 1130] avg_train_loss: 0.2797 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [700 / 1130] avg_train_loss: 0.2749 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [800 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [900 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [1000 / 1130] avg_train_loss: 0.273 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [1100 / 1130] avg_train_loss: 0.2742 | train_auc: 0.9783 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 140 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1416 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1082 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4192 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5879 | val_auc: 0.7895 | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6521 | val_auc: 0.8311 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 141
[TRAIN] Train model
Epoch [141 / 200] Step: [100 / 1130] avg_train_loss: 0.238 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [200 / 1130] avg_train_loss: 0.2132 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [300 / 1130] avg_train_loss: 0.2245 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [400 / 1130] avg_train_loss: 0.2219 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [500 / 1130] avg_train_loss: 0.2229 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [600 / 1130] avg_train_loss: 0.236 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [700 / 1130] avg_train_loss: 0.229 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [800 / 1130] avg_train_loss: 0.2463 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [900 / 1130] avg_train_loss: 0.2404 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [1000 / 1130] avg_train_loss: 0.2403 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [1100 / 1130] avg_train_loss: 0.2425 | train_auc: 0.984 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 141 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1513 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1236 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4165 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5654 | val_auc: 0.7869 | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6046 | val_auc: 0.8356 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 142
[TRAIN] Train model
Epoch [142 / 200] Step: [100 / 1130] avg_train_loss: 0.1718 | train_auc: 0.9978 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [200 / 1130] avg_train_loss: 0.1847 | train_auc: 0.9933 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [300 / 1130] avg_train_loss: 0.2108 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [400 / 1130] avg_train_loss: 0.2393 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [500 / 1130] avg_train_loss: 0.2247 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [600 / 1130] avg_train_loss: 0.2134 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [700 / 1130] avg_train_loss: 0.2132 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [800 / 1130] avg_train_loss: 0.2046 | train_auc: 0.9909 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [900 / 1130] avg_train_loss: 0.202 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [1000 / 1130] avg_train_loss: 0.2009 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [1100 / 1130] avg_train_loss: 0.203 | train_auc: 0.9911 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 142 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2991 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.214 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4803 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.568 | val_auc: 0.8081 | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5752 | val_auc: 0.8436 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 143
[TRAIN] Train model
Epoch [143 / 200] Step: [100 / 1130] avg_train_loss: 0.1682 | train_auc: 0.9949 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [200 / 1130] avg_train_loss: 0.2239 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [300 / 1130] avg_train_loss: 0.2287 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [400 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [500 / 1130] avg_train_loss: 0.2415 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [600 / 1130] avg_train_loss: 0.2462 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [700 / 1130] avg_train_loss: 0.2406 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [800 / 1130] avg_train_loss: 0.2384 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [900 / 1130] avg_train_loss: 0.2327 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [1000 / 1130] avg_train_loss: 0.2361 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [1100 / 1130] avg_train_loss: 0.2409 | train_auc: 0.9842 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 143 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1001 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0876 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4001 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5985 | val_auc: 0.7521 | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6839 | val_auc: 0.8048 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 144
[TRAIN] Train model
Epoch [144 / 200] Step: [100 / 1130] avg_train_loss: 0.1771 | train_auc: 1.0 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [200 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [300 / 1130] avg_train_loss: 0.25 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [400 / 1130] avg_train_loss: 0.2551 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [500 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [600 / 1130] avg_train_loss: 0.2428 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [700 / 1130] avg_train_loss: 0.2381 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [800 / 1130] avg_train_loss: 0.2496 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [900 / 1130] avg_train_loss: 0.2631 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [1000 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [1100 / 1130] avg_train_loss: 0.2534 | train_auc: 0.9831 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 144 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2256 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1774 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4362 | val_auc: 0.746 | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5274 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5513 | val_auc: 0.8503 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 145
[TRAIN] Train model
Epoch [145 / 200] Step: [100 / 1130] avg_train_loss: 0.2377 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [200 / 1130] avg_train_loss: 0.2262 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [300 / 1130] avg_train_loss: 0.2372 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [400 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [500 / 1130] avg_train_loss: 0.2603 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [600 / 1130] avg_train_loss: 0.2561 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [700 / 1130] avg_train_loss: 0.2635 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [800 / 1130] avg_train_loss: 0.2685 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [900 / 1130] avg_train_loss: 0.2713 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [1000 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [1100 / 1130] avg_train_loss: 0.2569 | train_auc: 0.9815 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 145 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2745 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1986 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4605 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5432 | val_auc: 0.826 | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5696 | val_auc: 0.8601 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 146
[TRAIN] Train model
Epoch [146 / 200] Step: [100 / 1130] avg_train_loss: 0.2251 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [200 / 1130] avg_train_loss: 0.1822 | train_auc: 0.9917 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [300 / 1130] avg_train_loss: 0.2028 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [400 / 1130] avg_train_loss: 0.2413 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [500 / 1130] avg_train_loss: 0.2486 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [600 / 1130] avg_train_loss: 0.254 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [700 / 1130] avg_train_loss: 0.2653 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [800 / 1130] avg_train_loss: 0.2739 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [900 / 1130] avg_train_loss: 0.2601 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [1000 / 1130] avg_train_loss: 0.2508 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [1100 / 1130] avg_train_loss: 0.2562 | train_auc: 0.9806 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 146 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.186 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1447 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4327 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5582 | val_auc: 0.8124 | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5999 | val_auc: 0.8534 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 147
[TRAIN] Train model
Epoch [147 / 200] Step: [100 / 1130] avg_train_loss: 0.2677 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [200 / 1130] avg_train_loss: 0.2311 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [300 / 1130] avg_train_loss: 0.2316 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [400 / 1130] avg_train_loss: 0.2367 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [500 / 1130] avg_train_loss: 0.2308 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [600 / 1130] avg_train_loss: 0.2339 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [700 / 1130] avg_train_loss: 0.2481 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [800 / 1130] avg_train_loss: 0.2506 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [900 / 1130] avg_train_loss: 0.2482 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [1000 / 1130] avg_train_loss: 0.2433 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [1100 / 1130] avg_train_loss: 0.2398 | train_auc: 0.9843 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 147 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1071 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0895 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4071 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5992 | val_auc: 0.7615 | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.673 | val_auc: 0.8209 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 148
[TRAIN] Train model
Epoch [148 / 200] Step: [100 / 1130] avg_train_loss: 0.1998 | train_auc: 0.9918 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [200 / 1130] avg_train_loss: 0.1935 | train_auc: 0.993 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [300 / 1130] avg_train_loss: 0.2035 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [400 / 1130] avg_train_loss: 0.2067 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [500 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [600 / 1130] avg_train_loss: 0.2322 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [700 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [800 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [900 / 1130] avg_train_loss: 0.2452 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [1000 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [1100 / 1130] avg_train_loss: 0.238 | train_auc: 0.9862 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 148 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2328 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1679 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.459 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5665 | val_auc: 0.8031 | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5962 | val_auc: 0.844 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 149
[TRAIN] Train model
Epoch [149 / 200] Step: [100 / 1130] avg_train_loss: 0.2094 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [200 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [300 / 1130] avg_train_loss: 0.2322 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [400 / 1130] avg_train_loss: 0.2379 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [500 / 1130] avg_train_loss: 0.233 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [600 / 1130] avg_train_loss: 0.2289 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [700 / 1130] avg_train_loss: 0.2217 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [800 / 1130] avg_train_loss: 0.2358 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [900 / 1130] avg_train_loss: 0.2317 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [1000 / 1130] avg_train_loss: 0.2335 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [1100 / 1130] avg_train_loss: 0.2386 | train_auc: 0.9833 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 149 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2586 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1818 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4381 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5392 | val_auc: 0.8226 | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5891 | val_auc: 0.8512 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 150
[TRAIN] Train model
Epoch [150 / 200] Step: [100 / 1130] avg_train_loss: 0.2647 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [200 / 1130] avg_train_loss: 0.2456 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [300 / 1130] avg_train_loss: 0.251 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [400 / 1130] avg_train_loss: 0.2363 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [500 / 1130] avg_train_loss: 0.2381 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [600 / 1130] avg_train_loss: 0.2412 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [700 / 1130] avg_train_loss: 0.2407 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [800 / 1130] avg_train_loss: 0.2301 | train_auc: 0.9876 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [900 / 1130] avg_train_loss: 0.2266 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [1000 / 1130] avg_train_loss: 0.2314 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [1100 / 1130] avg_train_loss: 0.2374 | train_auc: 0.9863 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 150 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1771 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1381 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4346 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.563 | val_auc: 0.7954 | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5884 | val_auc: 0.8467 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 151
[TRAIN] Train model
Epoch [151 / 200] Step: [100 / 1130] avg_train_loss: 0.1958 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [200 / 1130] avg_train_loss: 0.248 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [300 / 1130] avg_train_loss: 0.2339 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [400 / 1130] avg_train_loss: 0.2443 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [500 / 1130] avg_train_loss: 0.2269 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [600 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [700 / 1130] avg_train_loss: 0.2232 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [800 / 1130] avg_train_loss: 0.22 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [900 / 1130] avg_train_loss: 0.2266 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [1000 / 1130] avg_train_loss: 0.227 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [1100 / 1130] avg_train_loss: 0.2236 | train_auc: 0.9869 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 151 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2869 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.196 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4613 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5488 | val_auc: 0.8056 | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5949 | val_auc: 0.8454 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 152
[TRAIN] Train model
Epoch [152 / 200] Step: [100 / 1130] avg_train_loss: 0.1819 | train_auc: 0.9995 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [200 / 1130] avg_train_loss: 0.2154 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [300 / 1130] avg_train_loss: 0.2171 | train_auc: 0.9916 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [400 / 1130] avg_train_loss: 0.2506 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [500 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [600 / 1130] avg_train_loss: 0.2253 | train_auc: 0.9895 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [700 / 1130] avg_train_loss: 0.2317 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [800 / 1130] avg_train_loss: 0.2272 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [900 / 1130] avg_train_loss: 0.2305 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [1000 / 1130] avg_train_loss: 0.2277 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [1100 / 1130] avg_train_loss: 0.2267 | train_auc: 0.9878 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 152 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2692 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1929 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.462 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5428 | val_auc: 0.8234 | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5788 | val_auc: 0.857 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 153
[TRAIN] Train model
Epoch [153 / 200] Step: [100 / 1130] avg_train_loss: 0.2275 | train_auc: 0.9911 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [200 / 1130] avg_train_loss: 0.2313 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [300 / 1130] avg_train_loss: 0.2293 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [400 / 1130] avg_train_loss: 0.2397 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [500 / 1130] avg_train_loss: 0.2397 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [600 / 1130] avg_train_loss: 0.2489 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [700 / 1130] avg_train_loss: 0.2387 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [800 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [900 / 1130] avg_train_loss: 0.248 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [1000 / 1130] avg_train_loss: 0.261 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [1100 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9806 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 153 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3485 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2478 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.509 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5752 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.577 | val_auc: 0.8587 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 154
[TRAIN] Train model
Epoch [154 / 200] Step: [100 / 1130] avg_train_loss: 0.2274 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [200 / 1130] avg_train_loss: 0.2247 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [300 / 1130] avg_train_loss: 0.2143 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [400 / 1130] avg_train_loss: 0.2151 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [500 / 1130] avg_train_loss: 0.2078 | train_auc: 0.9899 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [600 / 1130] avg_train_loss: 0.2107 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [700 / 1130] avg_train_loss: 0.2161 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [800 / 1130] avg_train_loss: 0.2176 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [900 / 1130] avg_train_loss: 0.2166 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [1000 / 1130] avg_train_loss: 0.216 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [1100 / 1130] avg_train_loss: 0.2193 | train_auc: 0.9876 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 154 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.154 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1177 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4405 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5917 | val_auc: 0.7988 | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6389 | val_auc: 0.8338 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 155
[TRAIN] Train model
Epoch [155 / 200] Step: [100 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9633 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [200 / 1130] avg_train_loss: 0.2965 | train_auc: 0.9658 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [300 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [400 / 1130] avg_train_loss: 0.2584 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [500 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [600 / 1130] avg_train_loss: 0.2476 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [700 / 1130] avg_train_loss: 0.2559 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [800 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [900 / 1130] avg_train_loss: 0.25 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [1000 / 1130] avg_train_loss: 0.2533 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [1100 / 1130] avg_train_loss: 0.2566 | train_auc: 0.982 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 155 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1688 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1318 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4334 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5689 | val_auc: 0.7801 | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6116 | val_auc: 0.8329 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 156
[TRAIN] Train model
Epoch [156 / 200] Step: [100 / 1130] avg_train_loss: 0.2296 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [200 / 1130] avg_train_loss: 0.2421 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [300 / 1130] avg_train_loss: 0.2701 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [400 / 1130] avg_train_loss: 0.2396 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [500 / 1130] avg_train_loss: 0.2449 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [600 / 1130] avg_train_loss: 0.2439 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [700 / 1130] avg_train_loss: 0.2355 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [800 / 1130] avg_train_loss: 0.2372 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [900 / 1130] avg_train_loss: 0.2345 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [1000 / 1130] avg_train_loss: 0.2351 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [1100 / 1130] avg_train_loss: 0.2425 | train_auc: 0.9831 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 156 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2293 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.166 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4289 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5257 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5727 | val_auc: 0.8463 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 157
[TRAIN] Train model
Epoch [157 / 200] Step: [100 / 1130] avg_train_loss: 0.2292 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [200 / 1130] avg_train_loss: 0.2295 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [300 / 1130] avg_train_loss: 0.2265 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [400 / 1130] avg_train_loss: 0.2322 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [500 / 1130] avg_train_loss: 0.228 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [600 / 1130] avg_train_loss: 0.2413 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [700 / 1130] avg_train_loss: 0.238 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [800 / 1130] avg_train_loss: 0.2324 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [900 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [1000 / 1130] avg_train_loss: 0.2356 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [1100 / 1130] avg_train_loss: 0.243 | train_auc: 0.9845 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 157 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.243 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1719 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4504 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5571 | val_auc: 0.8132 | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.599 | val_auc: 0.8471 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 158
[TRAIN] Train model
Epoch [158 / 200] Step: [100 / 1130] avg_train_loss: 0.2896 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [200 / 1130] avg_train_loss: 0.2751 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [300 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [400 / 1130] avg_train_loss: 0.2546 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [500 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [600 / 1130] avg_train_loss: 0.2628 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [700 / 1130] avg_train_loss: 0.256 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [800 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [900 / 1130] avg_train_loss: 0.2567 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [1000 / 1130] avg_train_loss: 0.2425 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [1100 / 1130] avg_train_loss: 0.2372 | train_auc: 0.9842 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 158 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1324 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1016 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4363 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6077 | val_auc: 0.7699 | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6604 | val_auc: 0.8266 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 159
[TRAIN] Train model
Epoch [159 / 200] Step: [100 / 1130] avg_train_loss: 0.2386 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [200 / 1130] avg_train_loss: 0.2463 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [300 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [400 / 1130] avg_train_loss: 0.2347 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [500 / 1130] avg_train_loss: 0.2428 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [600 / 1130] avg_train_loss: 0.2431 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [700 / 1130] avg_train_loss: 0.2494 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [800 / 1130] avg_train_loss: 0.242 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [900 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [1000 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [1100 / 1130] avg_train_loss: 0.2394 | train_auc: 0.9839 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 159 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2396 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1707 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.46 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5699 | val_auc: 0.8132 | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.587 | val_auc: 0.8534 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 160
[TRAIN] Train model
Epoch [160 / 200] Step: [100 / 1130] avg_train_loss: 0.1772 | train_auc: 0.9982 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [200 / 1130] avg_train_loss: 0.2479 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [300 / 1130] avg_train_loss: 0.2529 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [400 / 1130] avg_train_loss: 0.2415 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [500 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [600 / 1130] avg_train_loss: 0.2388 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [700 / 1130] avg_train_loss: 0.2255 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [800 / 1130] avg_train_loss: 0.2228 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [900 / 1130] avg_train_loss: 0.2256 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [1000 / 1130] avg_train_loss: 0.2209 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [1100 / 1130] avg_train_loss: 0.2207 | train_auc: 0.9892 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 160 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1899 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1365 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4312 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5587 | val_auc: 0.8039 | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5993 | val_auc: 0.8454 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 161
[TRAIN] Train model
Epoch [161 / 200] Step: [100 / 1130] avg_train_loss: 0.3761 | train_auc: 0.9591 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [200 / 1130] avg_train_loss: 0.3235 | train_auc: 0.966 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [300 / 1130] avg_train_loss: 0.2884 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [400 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [500 / 1130] avg_train_loss: 0.2634 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [600 / 1130] avg_train_loss: 0.257 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [700 / 1130] avg_train_loss: 0.2514 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [800 / 1130] avg_train_loss: 0.2535 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [900 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [1000 / 1130] avg_train_loss: 0.2404 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [1100 / 1130] avg_train_loss: 0.2447 | train_auc: 0.9823 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 161 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1962 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1454 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4328 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5619 | val_auc: 0.8115 | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6078 | val_auc: 0.8489 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 162
[TRAIN] Train model
Epoch [162 / 200] Step: [100 / 1130] avg_train_loss: 0.3304 | train_auc: 0.971 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [200 / 1130] avg_train_loss: 0.2961 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [300 / 1130] avg_train_loss: 0.254 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [400 / 1130] avg_train_loss: 0.2557 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [500 / 1130] avg_train_loss: 0.2522 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [600 / 1130] avg_train_loss: 0.2566 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [700 / 1130] avg_train_loss: 0.2567 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [800 / 1130] avg_train_loss: 0.2568 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [900 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [1000 / 1130] avg_train_loss: 0.2548 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [1100 / 1130] avg_train_loss: 0.2472 | train_auc: 0.9819 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 162 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1595 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1249 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4126 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5474 | val_auc: 0.8065 | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5889 | val_auc: 0.852 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 163
[TRAIN] Train model
Epoch [163 / 200] Step: [100 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [200 / 1130] avg_train_loss: 0.2274 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [300 / 1130] avg_train_loss: 0.2383 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [400 / 1130] avg_train_loss: 0.2246 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [500 / 1130] avg_train_loss: 0.2234 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [600 / 1130] avg_train_loss: 0.2195 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [700 / 1130] avg_train_loss: 0.2339 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [800 / 1130] avg_train_loss: 0.2358 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [900 / 1130] avg_train_loss: 0.2417 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [1000 / 1130] avg_train_loss: 0.248 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [1100 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9836 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 163 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1069 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.091 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4211 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6039 | val_auc: 0.7742 | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6668 | val_auc: 0.8382 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 164
[TRAIN] Train model
Epoch [164 / 200] Step: [100 / 1130] avg_train_loss: 0.2792 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [200 / 1130] avg_train_loss: 0.236 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [300 / 1130] avg_train_loss: 0.2279 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [400 / 1130] avg_train_loss: 0.252 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [500 / 1130] avg_train_loss: 0.2442 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [600 / 1130] avg_train_loss: 0.2407 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [700 / 1130] avg_train_loss: 0.2373 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [800 / 1130] avg_train_loss: 0.241 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [900 / 1130] avg_train_loss: 0.2594 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [1000 / 1130] avg_train_loss: 0.2548 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [1100 / 1130] avg_train_loss: 0.2511 | train_auc: 0.9835 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 164 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1231 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.103 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4109 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.575 | val_auc: 0.7784 | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6399 | val_auc: 0.8293 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 165
[TRAIN] Train model
Epoch [165 / 200] Step: [100 / 1130] avg_train_loss: 0.3182 | train_auc: 0.9585 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [200 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [300 / 1130] avg_train_loss: 0.2307 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [400 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [500 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [600 / 1130] avg_train_loss: 0.2233 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [700 / 1130] avg_train_loss: 0.2288 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [800 / 1130] avg_train_loss: 0.2463 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [900 / 1130] avg_train_loss: 0.2496 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [1000 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [1100 / 1130] avg_train_loss: 0.2434 | train_auc: 0.9807 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 165 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1576 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1273 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4072 | val_auc: 0.6429 | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5336 | val_auc: 0.7869 | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5782 | val_auc: 0.8458 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 166
[TRAIN] Train model
Epoch [166 / 200] Step: [100 / 1130] avg_train_loss: 0.1775 | train_auc: 0.9943 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [200 / 1130] avg_train_loss: 0.2313 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [300 / 1130] avg_train_loss: 0.2248 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [400 / 1130] avg_train_loss: 0.2312 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [500 / 1130] avg_train_loss: 0.2497 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [600 / 1130] avg_train_loss: 0.2539 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [700 / 1130] avg_train_loss: 0.2578 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [800 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [900 / 1130] avg_train_loss: 0.2591 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [1000 / 1130] avg_train_loss: 0.2588 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [1100 / 1130] avg_train_loss: 0.2571 | train_auc: 0.9803 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 166 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2104 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1646 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4256 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5326 | val_auc: 0.7946 | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5567 | val_auc: 0.8431 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 167
[TRAIN] Train model
Epoch [167 / 200] Step: [100 / 1130] avg_train_loss: 0.2203 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [200 / 1130] avg_train_loss: 0.174 | train_auc: 0.9939 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [300 / 1130] avg_train_loss: 0.1732 | train_auc: 0.9952 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [400 / 1130] avg_train_loss: 0.2045 | train_auc: 0.9897 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [500 / 1130] avg_train_loss: 0.2067 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [600 / 1130] avg_train_loss: 0.2058 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [700 / 1130] avg_train_loss: 0.2151 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [800 / 1130] avg_train_loss: 0.2237 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [900 / 1130] avg_train_loss: 0.2216 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [1000 / 1130] avg_train_loss: 0.2259 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [1100 / 1130] avg_train_loss: 0.2348 | train_auc: 0.9856 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 167 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1621 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1256 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4166 | val_auc: 0.6376 | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5866 | val_auc: 0.7606 | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6478 | val_auc: 0.8133 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 168
[TRAIN] Train model
Epoch [168 / 200] Step: [100 / 1130] avg_train_loss: 0.159 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [200 / 1130] avg_train_loss: 0.1952 | train_auc: 0.9909 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [300 / 1130] avg_train_loss: 0.2192 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [400 / 1130] avg_train_loss: 0.2074 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [500 / 1130] avg_train_loss: 0.2205 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [600 / 1130] avg_train_loss: 0.2136 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [700 / 1130] avg_train_loss: 0.2131 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [800 / 1130] avg_train_loss: 0.2171 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [900 / 1130] avg_train_loss: 0.2239 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [1000 / 1130] avg_train_loss: 0.2273 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [1100 / 1130] avg_train_loss: 0.2245 | train_auc: 0.9884 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 168 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1093 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0944 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4027 | val_auc: 0.664 | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5978 | val_auc: 0.7606 | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6734 | val_auc: 0.8115 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 169
[TRAIN] Train model
Epoch [169 / 200] Step: [100 / 1130] avg_train_loss: 0.2334 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [200 / 1130] avg_train_loss: 0.2935 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [300 / 1130] avg_train_loss: 0.3118 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [400 / 1130] avg_train_loss: 0.3088 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [500 / 1130] avg_train_loss: 0.2856 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [600 / 1130] avg_train_loss: 0.274 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [700 / 1130] avg_train_loss: 0.2775 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [800 / 1130] avg_train_loss: 0.2701 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [900 / 1130] avg_train_loss: 0.2787 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [1000 / 1130] avg_train_loss: 0.2789 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [1100 / 1130] avg_train_loss: 0.271 | train_auc: 0.9775 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 169 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2799 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1987 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4706 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5506 | val_auc: 0.8132 | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.582 | val_auc: 0.8485 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 170
[TRAIN] Train model
Epoch [170 / 200] Step: [100 / 1130] avg_train_loss: 0.2046 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [200 / 1130] avg_train_loss: 0.2611 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [300 / 1130] avg_train_loss: 0.2253 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [400 / 1130] avg_train_loss: 0.2582 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [500 / 1130] avg_train_loss: 0.251 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [600 / 1130] avg_train_loss: 0.2565 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [700 / 1130] avg_train_loss: 0.2568 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [800 / 1130] avg_train_loss: 0.2469 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [900 / 1130] avg_train_loss: 0.2471 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [1000 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [1100 / 1130] avg_train_loss: 0.2363 | train_auc: 0.9832 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 170 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3239 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2302 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.483 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5578 | val_auc: 0.82 | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5702 | val_auc: 0.8556 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 171
[TRAIN] Train model
Epoch [171 / 200] Step: [100 / 1130] avg_train_loss: 0.2596 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [200 / 1130] avg_train_loss: 0.2086 | train_auc: 0.9926 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [300 / 1130] avg_train_loss: 0.2116 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [400 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [500 / 1130] avg_train_loss: 0.225 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [600 / 1130] avg_train_loss: 0.2401 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [700 / 1130] avg_train_loss: 0.2421 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [800 / 1130] avg_train_loss: 0.244 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [900 / 1130] avg_train_loss: 0.2362 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [1000 / 1130] avg_train_loss: 0.2353 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [1100 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9844 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 171 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1316 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1055 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4083 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5671 | val_auc: 0.8031 | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6205 | val_auc: 0.8489 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 172
[TRAIN] Train model
Epoch [172 / 200] Step: [100 / 1130] avg_train_loss: 0.196 | train_auc: 0.9934 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [200 / 1130] avg_train_loss: 0.2214 | train_auc: 0.9908 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [300 / 1130] avg_train_loss: 0.2552 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [400 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [500 / 1130] avg_train_loss: 0.2395 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [600 / 1130] avg_train_loss: 0.2488 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [700 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [800 / 1130] avg_train_loss: 0.2498 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [900 / 1130] avg_train_loss: 0.2511 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [1000 / 1130] avg_train_loss: 0.2484 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [1100 / 1130] avg_train_loss: 0.245 | train_auc: 0.9817 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 172 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2553 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1894 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4532 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5447 | val_auc: 0.8098 | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.568 | val_auc: 0.8525 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 173
[TRAIN] Train model
Epoch [173 / 200] Step: [100 / 1130] avg_train_loss: 0.2585 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [200 / 1130] avg_train_loss: 0.2477 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [300 / 1130] avg_train_loss: 0.2661 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [400 / 1130] avg_train_loss: 0.2582 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [500 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [600 / 1130] avg_train_loss: 0.255 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [700 / 1130] avg_train_loss: 0.2548 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [800 / 1130] avg_train_loss: 0.2568 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [900 / 1130] avg_train_loss: 0.2524 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [1000 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [1100 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9806 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 173 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1641 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1204 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4438 | val_auc: 0.619 | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5992 | val_auc: 0.7708 | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6569 | val_auc: 0.8253 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 174
[TRAIN] Train model
Epoch [174 / 200] Step: [100 / 1130] avg_train_loss: 0.2426 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [200 / 1130] avg_train_loss: 0.2333 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [300 / 1130] avg_train_loss: 0.2352 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [400 / 1130] avg_train_loss: 0.2267 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [500 / 1130] avg_train_loss: 0.2257 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [600 / 1130] avg_train_loss: 0.225 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [700 / 1130] avg_train_loss: 0.2346 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [800 / 1130] avg_train_loss: 0.2314 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [900 / 1130] avg_train_loss: 0.2327 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [1000 / 1130] avg_train_loss: 0.2419 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [1100 / 1130] avg_train_loss: 0.2425 | train_auc: 0.9842 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 174 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3904 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.273 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5137 | val_auc: 0.7804 | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5949 | val_auc: 0.8277 | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5917 | val_auc: 0.8632 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 175
[TRAIN] Train model
Epoch [175 / 200] Step: [100 / 1130] avg_train_loss: 0.2651 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [200 / 1130] avg_train_loss: 0.2373 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [300 / 1130] avg_train_loss: 0.2598 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [400 / 1130] avg_train_loss: 0.2595 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [500 / 1130] avg_train_loss: 0.2399 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [600 / 1130] avg_train_loss: 0.2429 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [700 / 1130] avg_train_loss: 0.2558 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [800 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [900 / 1130] avg_train_loss: 0.2452 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [1000 / 1130] avg_train_loss: 0.2394 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [1100 / 1130] avg_train_loss: 0.2397 | train_auc: 0.9845 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 175 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1596 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1184 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4414 | val_auc: 0.619 | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6051 | val_auc: 0.7623 | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6593 | val_auc: 0.816 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 176
[TRAIN] Train model
Epoch [176 / 200] Step: [100 / 1130] avg_train_loss: 0.2691 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [200 / 1130] avg_train_loss: 0.2264 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [300 / 1130] avg_train_loss: 0.26 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [400 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [500 / 1130] avg_train_loss: 0.2388 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [600 / 1130] avg_train_loss: 0.2437 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [700 / 1130] avg_train_loss: 0.241 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [800 / 1130] avg_train_loss: 0.2419 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [900 / 1130] avg_train_loss: 0.2353 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [1000 / 1130] avg_train_loss: 0.2371 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [1100 / 1130] avg_train_loss: 0.2379 | train_auc: 0.9844 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 176 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3058 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2241 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4793 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.548 | val_auc: 0.8149 | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5627 | val_auc: 0.8512 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 177
[TRAIN] Train model
Epoch [177 / 200] Step: [100 / 1130] avg_train_loss: 0.3244 | train_auc: 0.9617 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [200 / 1130] avg_train_loss: 0.2493 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [300 / 1130] avg_train_loss: 0.2448 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [400 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [500 / 1130] avg_train_loss: 0.2537 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [600 / 1130] avg_train_loss: 0.2499 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [700 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [800 / 1130] avg_train_loss: 0.242 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [900 / 1130] avg_train_loss: 0.2365 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [1000 / 1130] avg_train_loss: 0.2321 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [1100 / 1130] avg_train_loss: 0.2364 | train_auc: 0.985 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 177 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1858 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1436 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4287 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5592 | val_auc: 0.8031 | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.589 | val_auc: 0.8431 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 178
[TRAIN] Train model
Epoch [178 / 200] Step: [100 / 1130] avg_train_loss: 0.1536 | train_auc: 0.9978 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [200 / 1130] avg_train_loss: 0.1929 | train_auc: 0.9942 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [300 / 1130] avg_train_loss: 0.2111 | train_auc: 0.9919 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [400 / 1130] avg_train_loss: 0.2048 | train_auc: 0.9927 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [500 / 1130] avg_train_loss: 0.2175 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [600 / 1130] avg_train_loss: 0.2093 | train_auc: 0.9893 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [700 / 1130] avg_train_loss: 0.2048 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [800 / 1130] avg_train_loss: 0.2151 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [900 / 1130] avg_train_loss: 0.207 | train_auc: 0.9897 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [1000 / 1130] avg_train_loss: 0.2094 | train_auc: 0.9897 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [1100 / 1130] avg_train_loss: 0.2189 | train_auc: 0.9881 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 178 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1611 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1218 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4162 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.561 | val_auc: 0.8141 | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6165 | val_auc: 0.8574 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 179
[TRAIN] Train model
Epoch [179 / 200] Step: [100 / 1130] avg_train_loss: 0.2283 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [200 / 1130] avg_train_loss: 0.2118 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [300 / 1130] avg_train_loss: 0.2192 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [400 / 1130] avg_train_loss: 0.2124 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [500 / 1130] avg_train_loss: 0.2141 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [600 / 1130] avg_train_loss: 0.216 | train_auc: 0.9877 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [700 / 1130] avg_train_loss: 0.23 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [800 / 1130] avg_train_loss: 0.2251 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [900 / 1130] avg_train_loss: 0.2391 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [1000 / 1130] avg_train_loss: 0.2346 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [1100 / 1130] avg_train_loss: 0.2294 | train_auc: 0.9866 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 179 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2081 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1484 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4482 | val_auc: 0.6376 | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5749 | val_auc: 0.7835 | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6014 | val_auc: 0.8422 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 180
[TRAIN] Train model
Epoch [180 / 200] Step: [100 / 1130] avg_train_loss: 0.2411 | train_auc: 0.9876 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [200 / 1130] avg_train_loss: 0.2002 | train_auc: 0.993 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [300 / 1130] avg_train_loss: 0.2067 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [400 / 1130] avg_train_loss: 0.2288 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [500 / 1130] avg_train_loss: 0.2286 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [600 / 1130] avg_train_loss: 0.2324 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [700 / 1130] avg_train_loss: 0.224 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [800 / 1130] avg_train_loss: 0.2259 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [900 / 1130] avg_train_loss: 0.2284 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [1000 / 1130] avg_train_loss: 0.2218 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [1100 / 1130] avg_train_loss: 0.2208 | train_auc: 0.9883 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 180 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2652 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1777 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4566 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5802 | val_auc: 0.7954 | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6231 | val_auc: 0.8382 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 181
[TRAIN] Train model
Epoch [181 / 200] Step: [100 / 1130] avg_train_loss: 0.2029 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [200 / 1130] avg_train_loss: 0.2061 | train_auc: 0.9914 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [300 / 1130] avg_train_loss: 0.2001 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [400 / 1130] avg_train_loss: 0.2204 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [500 / 1130] avg_train_loss: 0.2176 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [600 / 1130] avg_train_loss: 0.2281 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [700 / 1130] avg_train_loss: 0.2285 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [800 / 1130] avg_train_loss: 0.2293 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [900 / 1130] avg_train_loss: 0.2332 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [1000 / 1130] avg_train_loss: 0.2331 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [1100 / 1130] avg_train_loss: 0.2308 | train_auc: 0.9856 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 181 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1691 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1294 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4399 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5707 | val_auc: 0.7963 | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6005 | val_auc: 0.8445 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 182
[TRAIN] Train model
Epoch [182 / 200] Step: [100 / 1130] avg_train_loss: 0.3249 | train_auc: 0.9553 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [200 / 1130] avg_train_loss: 0.3056 | train_auc: 0.9671 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [300 / 1130] avg_train_loss: 0.286 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [400 / 1130] avg_train_loss: 0.2617 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [500 / 1130] avg_train_loss: 0.256 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [600 / 1130] avg_train_loss: 0.2506 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [700 / 1130] avg_train_loss: 0.2553 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [800 / 1130] avg_train_loss: 0.255 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [900 / 1130] avg_train_loss: 0.2435 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [1000 / 1130] avg_train_loss: 0.2418 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [1100 / 1130] avg_train_loss: 0.2456 | train_auc: 0.9811 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 182 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1918 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1467 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4156 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5511 | val_auc: 0.8073 | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5844 | val_auc: 0.8494 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 183
[TRAIN] Train model
Epoch [183 / 200] Step: [100 / 1130] avg_train_loss: 0.228 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [200 / 1130] avg_train_loss: 0.247 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [300 / 1130] avg_train_loss: 0.276 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [400 / 1130] avg_train_loss: 0.2899 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [500 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [600 / 1130] avg_train_loss: 0.2825 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [700 / 1130] avg_train_loss: 0.2754 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [800 / 1130] avg_train_loss: 0.2815 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [900 / 1130] avg_train_loss: 0.2775 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [1000 / 1130] avg_train_loss: 0.2769 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [1100 / 1130] avg_train_loss: 0.2685 | train_auc: 0.9789 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 183 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.166 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1289 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4372 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5941 | val_auc: 0.7547 | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6331 | val_auc: 0.8226 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 184
[TRAIN] Train model
Epoch [184 / 200] Step: [100 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9677 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [200 / 1130] avg_train_loss: 0.2086 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [300 / 1130] avg_train_loss: 0.2022 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [400 / 1130] avg_train_loss: 0.2154 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [500 / 1130] avg_train_loss: 0.2348 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [600 / 1130] avg_train_loss: 0.23 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [700 / 1130] avg_train_loss: 0.241 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [800 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [900 / 1130] avg_train_loss: 0.2324 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [1000 / 1130] avg_train_loss: 0.2334 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [1100 / 1130] avg_train_loss: 0.2347 | train_auc: 0.9857 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 184 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1574 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1177 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4227 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5799 | val_auc: 0.775 | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6562 | val_auc: 0.816 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 185
[TRAIN] Train model
Epoch [185 / 200] Step: [100 / 1130] avg_train_loss: 0.2907 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [200 / 1130] avg_train_loss: 0.2333 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [300 / 1130] avg_train_loss: 0.2327 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [400 / 1130] avg_train_loss: 0.2477 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [500 / 1130] avg_train_loss: 0.2264 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [600 / 1130] avg_train_loss: 0.2297 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [700 / 1130] avg_train_loss: 0.2311 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [800 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [900 / 1130] avg_train_loss: 0.2377 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [1000 / 1130] avg_train_loss: 0.2442 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [1100 / 1130] avg_train_loss: 0.2492 | train_auc: 0.9826 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 185 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2008 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1552 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4284 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5543 | val_auc: 0.8014 | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5907 | val_auc: 0.8418 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 186
[TRAIN] Train model
Epoch [186 / 200] Step: [100 / 1130] avg_train_loss: 0.3951 | train_auc: 0.9545 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [200 / 1130] avg_train_loss: 0.3255 | train_auc: 0.9689 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [300 / 1130] avg_train_loss: 0.3422 | train_auc: 0.9641 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [400 / 1130] avg_train_loss: 0.3104 | train_auc: 0.9694 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [500 / 1130] avg_train_loss: 0.2925 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [600 / 1130] avg_train_loss: 0.2872 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [700 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [800 / 1130] avg_train_loss: 0.278 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [900 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [1000 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [1100 / 1130] avg_train_loss: 0.2682 | train_auc: 0.9794 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 186 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2266 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1607 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4422 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.546 | val_auc: 0.8209 | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5811 | val_auc: 0.8587 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 187
[TRAIN] Train model
Epoch [187 / 200] Step: [100 / 1130] avg_train_loss: 0.2777 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [200 / 1130] avg_train_loss: 0.1924 | train_auc: 0.9913 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [300 / 1130] avg_train_loss: 0.1972 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [400 / 1130] avg_train_loss: 0.2054 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [500 / 1130] avg_train_loss: 0.2246 | train_auc: 0.9862 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [600 / 1130] avg_train_loss: 0.2295 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [700 / 1130] avg_train_loss: 0.2367 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [800 / 1130] avg_train_loss: 0.2473 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [900 / 1130] avg_train_loss: 0.2451 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [1000 / 1130] avg_train_loss: 0.2405 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [1100 / 1130] avg_train_loss: 0.2346 | train_auc: 0.9848 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 187 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2845 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2032 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4928 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5749 | val_auc: 0.8183 | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5944 | val_auc: 0.8538 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 188
[TRAIN] Train model
Epoch [188 / 200] Step: [100 / 1130] avg_train_loss: 0.3106 | train_auc: 0.9713 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [200 / 1130] avg_train_loss: 0.3025 | train_auc: 0.9717 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [300 / 1130] avg_train_loss: 0.2679 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [400 / 1130] avg_train_loss: 0.2578 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [500 / 1130] avg_train_loss: 0.2428 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [600 / 1130] avg_train_loss: 0.2438 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [700 / 1130] avg_train_loss: 0.2446 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [800 / 1130] avg_train_loss: 0.242 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [900 / 1130] avg_train_loss: 0.253 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [1000 / 1130] avg_train_loss: 0.2535 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [1100 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9801 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 188 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2273 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1607 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4683 | val_auc: 0.664 | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5951 | val_auc: 0.7818 | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6235 | val_auc: 0.8275 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 189
[TRAIN] Train model
Epoch [189 / 200] Step: [100 / 1130] avg_train_loss: 0.2439 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [200 / 1130] avg_train_loss: 0.2328 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [300 / 1130] avg_train_loss: 0.2078 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [400 / 1130] avg_train_loss: 0.2273 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [500 / 1130] avg_train_loss: 0.2172 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [600 / 1130] avg_train_loss: 0.2229 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [700 / 1130] avg_train_loss: 0.2359 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [800 / 1130] avg_train_loss: 0.2416 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [900 / 1130] avg_train_loss: 0.244 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [1000 / 1130] avg_train_loss: 0.2473 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [1100 / 1130] avg_train_loss: 0.254 | train_auc: 0.9815 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 189 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1891 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1428 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4351 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5604 | val_auc: 0.8081 | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5959 | val_auc: 0.8494 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 190
[TRAIN] Train model
Epoch [190 / 200] Step: [100 / 1130] avg_train_loss: 0.2179 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [200 / 1130] avg_train_loss: 0.2281 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [300 / 1130] avg_train_loss: 0.2474 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [400 / 1130] avg_train_loss: 0.2507 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [500 / 1130] avg_train_loss: 0.2529 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [600 / 1130] avg_train_loss: 0.2552 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [700 / 1130] avg_train_loss: 0.2601 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [800 / 1130] avg_train_loss: 0.2598 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [900 / 1130] avg_train_loss: 0.266 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [1000 / 1130] avg_train_loss: 0.262 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [1100 / 1130] avg_train_loss: 0.2584 | train_auc: 0.9814 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 190 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1986 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1487 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4172 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5329 | val_auc: 0.8158 | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5842 | val_auc: 0.8418 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 191
[TRAIN] Train model
Epoch [191 / 200] Step: [100 / 1130] avg_train_loss: 0.2316 | train_auc: 0.9876 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [200 / 1130] avg_train_loss: 0.2173 | train_auc: 0.9901 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [300 / 1130] avg_train_loss: 0.2043 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [400 / 1130] avg_train_loss: 0.206 | train_auc: 0.9917 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [500 / 1130] avg_train_loss: 0.2107 | train_auc: 0.9901 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [600 / 1130] avg_train_loss: 0.2082 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [700 / 1130] avg_train_loss: 0.2086 | train_auc: 0.99 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [800 / 1130] avg_train_loss: 0.2076 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [900 / 1130] avg_train_loss: 0.2083 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [1000 / 1130] avg_train_loss: 0.2149 | train_auc: 0.9895 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [1100 / 1130] avg_train_loss: 0.2164 | train_auc: 0.9888 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 191 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2418 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1772 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4304 | val_auc: 0.7434 | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5237 | val_auc: 0.826 | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5563 | val_auc: 0.8578 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 192
[TRAIN] Train model
Epoch [192 / 200] Step: [100 / 1130] avg_train_loss: 0.3453 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [200 / 1130] avg_train_loss: 0.2564 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [300 / 1130] avg_train_loss: 0.2467 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [400 / 1130] avg_train_loss: 0.2452 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [500 / 1130] avg_train_loss: 0.2284 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [600 / 1130] avg_train_loss: 0.225 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [700 / 1130] avg_train_loss: 0.2236 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [800 / 1130] avg_train_loss: 0.2245 | train_auc: 0.9893 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [900 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [1000 / 1130] avg_train_loss: 0.2305 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [1100 / 1130] avg_train_loss: 0.2393 | train_auc: 0.985 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 192 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3261 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2295 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4874 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5646 | val_auc: 0.8115 | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5856 | val_auc: 0.8498 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 193
[TRAIN] Train model
Epoch [193 / 200] Step: [100 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9903 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [200 / 1130] avg_train_loss: 0.2017 | train_auc: 0.9944 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [300 / 1130] avg_train_loss: 0.2004 | train_auc: 0.9944 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [400 / 1130] avg_train_loss: 0.1967 | train_auc: 0.9946 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [500 / 1130] avg_train_loss: 0.2176 | train_auc: 0.9918 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [600 / 1130] avg_train_loss: 0.2227 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [700 / 1130] avg_train_loss: 0.2173 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [800 / 1130] avg_train_loss: 0.2177 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [900 / 1130] avg_train_loss: 0.2105 | train_auc: 0.9898 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [1000 / 1130] avg_train_loss: 0.2111 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [1100 / 1130] avg_train_loss: 0.2138 | train_auc: 0.9887 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 193 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.334 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2348 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4792 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5579 | val_auc: 0.8217 | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.579 | val_auc: 0.8574 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 194
[TRAIN] Train model
Epoch [194 / 200] Step: [100 / 1130] avg_train_loss: 0.2428 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [200 / 1130] avg_train_loss: 0.1945 | train_auc: 0.991 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [300 / 1130] avg_train_loss: 0.2 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [400 / 1130] avg_train_loss: 0.189 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [500 / 1130] avg_train_loss: 0.2033 | train_auc: 0.9888 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [600 / 1130] avg_train_loss: 0.2015 | train_auc: 0.9898 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [700 / 1130] avg_train_loss: 0.2081 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [800 / 1130] avg_train_loss: 0.2209 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [900 / 1130] avg_train_loss: 0.2251 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [1000 / 1130] avg_train_loss: 0.2309 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [1100 / 1130] avg_train_loss: 0.238 | train_auc: 0.9847 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 194 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1179 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0976 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4203 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5907 | val_auc: 0.7699 | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6441 | val_auc: 0.8253 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 195
[TRAIN] Train model
Epoch [195 / 200] Step: [100 / 1130] avg_train_loss: 0.1606 | train_auc: 0.9962 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [200 / 1130] avg_train_loss: 0.1719 | train_auc: 0.9949 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [300 / 1130] avg_train_loss: 0.1745 | train_auc: 0.9951 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [400 / 1130] avg_train_loss: 0.1877 | train_auc: 0.9927 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [500 / 1130] avg_train_loss: 0.1907 | train_auc: 0.993 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [600 / 1130] avg_train_loss: 0.1926 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [700 / 1130] avg_train_loss: 0.2099 | train_auc: 0.9898 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [800 / 1130] avg_train_loss: 0.2183 | train_auc: 0.9889 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [900 / 1130] avg_train_loss: 0.2227 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [1000 / 1130] avg_train_loss: 0.2283 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [1100 / 1130] avg_train_loss: 0.2237 | train_auc: 0.9883 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 195 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1919 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1509 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4437 | val_auc: 0.7275 | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5635 | val_auc: 0.8031 | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5915 | val_auc: 0.8409 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 196
[TRAIN] Train model
Epoch [196 / 200] Step: [100 / 1130] avg_train_loss: 0.2412 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [200 / 1130] avg_train_loss: 0.223 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [300 / 1130] avg_train_loss: 0.215 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [400 / 1130] avg_train_loss: 0.2462 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [500 / 1130] avg_train_loss: 0.2355 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [600 / 1130] avg_train_loss: 0.232 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [700 / 1130] avg_train_loss: 0.2368 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [800 / 1130] avg_train_loss: 0.2396 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [900 / 1130] avg_train_loss: 0.2334 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [1000 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [1100 / 1130] avg_train_loss: 0.2346 | train_auc: 0.9848 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 196 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2502 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1827 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4679 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5815 | val_auc: 0.798 | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5929 | val_auc: 0.8436 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 197
[TRAIN] Train model
Epoch [197 / 200] Step: [100 / 1130] avg_train_loss: 0.1994 | train_auc: 0.994 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [200 / 1130] avg_train_loss: 0.2706 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [300 / 1130] avg_train_loss: 0.2919 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [400 / 1130] avg_train_loss: 0.2797 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [500 / 1130] avg_train_loss: 0.2757 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [600 / 1130] avg_train_loss: 0.2661 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [700 / 1130] avg_train_loss: 0.2657 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [800 / 1130] avg_train_loss: 0.253 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [900 / 1130] avg_train_loss: 0.2562 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [1000 / 1130] avg_train_loss: 0.2577 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [1100 / 1130] avg_train_loss: 0.2525 | train_auc: 0.9817 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 197 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.217 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1657 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4513 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5579 | val_auc: 0.8183 | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5839 | val_auc: 0.8538 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 198
[TRAIN] Train model
Epoch [198 / 200] Step: [100 / 1130] avg_train_loss: 0.2933 | train_auc: 0.9666 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [200 / 1130] avg_train_loss: 0.2292 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [300 / 1130] avg_train_loss: 0.2294 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [400 / 1130] avg_train_loss: 0.2589 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [500 / 1130] avg_train_loss: 0.2585 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [600 / 1130] avg_train_loss: 0.2673 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [700 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [800 / 1130] avg_train_loss: 0.2675 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [900 / 1130] avg_train_loss: 0.267 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [1000 / 1130] avg_train_loss: 0.2555 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [1100 / 1130] avg_train_loss: 0.2508 | train_auc: 0.9822 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 198 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2207 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1599 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.448 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5608 | val_auc: 0.8124 | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6162 | val_auc: 0.8391 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 199
[TRAIN] Train model
Epoch [199 / 200] Step: [100 / 1130] avg_train_loss: 0.2478 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [200 / 1130] avg_train_loss: 0.2369 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [300 / 1130] avg_train_loss: 0.24 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [400 / 1130] avg_train_loss: 0.2641 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [500 / 1130] avg_train_loss: 0.2708 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [600 / 1130] avg_train_loss: 0.262 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [700 / 1130] avg_train_loss: 0.2698 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [800 / 1130] avg_train_loss: 0.2629 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [900 / 1130] avg_train_loss: 0.2652 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [1000 / 1130] avg_train_loss: 0.2631 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [1100 / 1130] avg_train_loss: 0.2582 | train_auc: 0.9813 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 199 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1558 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1177 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4161 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.568 | val_auc: 0.8022 | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6152 | val_auc: 0.8503 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 200
[TRAIN] Train model
Epoch [200 / 200] Step: [100 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [200 / 1130] avg_train_loss: 0.2171 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [300 / 1130] avg_train_loss: 0.259 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [400 / 1130] avg_train_loss: 0.2886 | train_auc: 0.9711 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [500 / 1130] avg_train_loss: 0.2618 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [600 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [700 / 1130] avg_train_loss: 0.2646 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [800 / 1130] avg_train_loss: 0.2538 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [900 / 1130] avg_train_loss: 0.2486 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [1000 / 1130] avg_train_loss: 0.2476 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [1100 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9819 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 200 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.298 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2183 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4748 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5558 | val_auc: 0.8149 | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5874 | val_auc: 0.852 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[INFO] Execution duration: 360.00 minutes 43.20 seconds
Completed Meniscus Axial Training
---------------------------------
Starting Meniscus Coronal Training...
[SEED] Setting seeds for reproducibility...
src/models-to-submit/pretrained
[TRAIN] Creating logs folder: "./logs/20250311-051226_meniscus_coronal"
[TRAIN] Loading Data Loaders
[DATALOADER] __init__ task: meniscus, plane: coronal, train: train
[DATALOADER] __init__ weights: [1, 1.8463476070528968]
[DATALOADER] __init__ task: meniscus, plane: coronal, train: valid
[DATALOADER] __init__ weights: [1, 1.3076923076923077]
[TRAIN] Instantiate Model
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[TRAIN] Defining Optimizer
[TRAIN] Starting Training!
[TRAIN] Epochs = 200
[TRAIN] EPOCH # 1
[TRAIN] Train model
Epoch [1 / 200] Step: [100 / 1130] avg_train_loss: 0.9745 | train_auc: 0.4938 | lr : 1e-05
Epoch [1 / 200] Step: [200 / 1130] avg_train_loss: 0.9506 | train_auc: 0.5402 | lr : 1e-05
Epoch [1 / 200] Step: [300 / 1130] avg_train_loss: 0.9456 | train_auc: 0.5193 | lr : 1e-05
Epoch [1 / 200] Step: [400 / 1130] avg_train_loss: 0.9351 | train_auc: 0.5349 | lr : 1e-05
Epoch [1 / 200] Step: [500 / 1130] avg_train_loss: 0.9355 | train_auc: 0.518 | lr : 1e-05
Epoch [1 / 200] Step: [600 / 1130] avg_train_loss: 0.9313 | train_auc: 0.5223 | lr : 1e-05
Epoch [1 / 200] Step: [700 / 1130] avg_train_loss: 0.9249 | train_auc: 0.533 | lr : 1e-05
Epoch [1 / 200] Step: [800 / 1130] avg_train_loss: 0.9219 | train_auc: 0.5327 | lr : 1e-05
Epoch [1 / 200] Step: [900 / 1130] avg_train_loss: 0.9195 | train_auc: 0.5282 | lr : 1e-05
Epoch [1 / 200] Step: [1000 / 1130] avg_train_loss: 0.9171 | train_auc: 0.5326 | lr : 1e-05
Epoch [1 / 200] Step: [1100 / 1130] avg_train_loss: 0.9157 | train_auc: 0.5404 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 1 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.606 | val_auc: nan | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.6365 | val_auc: nan | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6772 | val_auc: 0.5026 | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.7183 | val_auc: 0.5153 | lr: 1e-05
[Epoch: 1 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7362 | val_auc: 0.5896 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_coronal_train_auc_0.5448_val_auc_0.6049_train_loss_0.9137_val_loss_0.7657_epoch_1_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 2
[TRAIN] Train model
Epoch [2 / 200] Step: [100 / 1130] avg_train_loss: 0.878 | train_auc: 0.5883 | lr : 1e-05
Epoch [2 / 200] Step: [200 / 1130] avg_train_loss: 0.8664 | train_auc: 0.6122 | lr : 1e-05
Epoch [2 / 200] Step: [300 / 1130] avg_train_loss: 0.8805 | train_auc: 0.6082 | lr : 1e-05
Epoch [2 / 200] Step: [400 / 1130] avg_train_loss: 0.8688 | train_auc: 0.63 | lr : 1e-05
Epoch [2 / 200] Step: [500 / 1130] avg_train_loss: 0.8688 | train_auc: 0.6369 | lr : 1e-05
Epoch [2 / 200] Step: [600 / 1130] avg_train_loss: 0.8661 | train_auc: 0.6489 | lr : 1e-05
Epoch [2 / 200] Step: [700 / 1130] avg_train_loss: 0.8726 | train_auc: 0.6439 | lr : 1e-05
Epoch [2 / 200] Step: [800 / 1130] avg_train_loss: 0.8705 | train_auc: 0.6485 | lr : 1e-05
Epoch [2 / 200] Step: [900 / 1130] avg_train_loss: 0.8637 | train_auc: 0.6564 | lr : 1e-05
Epoch [2 / 200] Step: [1000 / 1130] avg_train_loss: 0.8654 | train_auc: 0.6501 | lr : 1e-05
Epoch [2 / 200] Step: [1100 / 1130] avg_train_loss: 0.8608 | train_auc: 0.656 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 2 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.5187 | val_auc: nan | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.5277 | val_auc: nan | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6061 | val_auc: 0.6561 | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6602 | val_auc: 0.6621 | lr: 1e-05
[Epoch: 2 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6932 | val_auc: 0.6858 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_coronal_train_auc_0.6588_val_auc_0.7031_train_loss_0.8590_val_loss_0.7331_epoch_2_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 3
[TRAIN] Train model
Epoch [3 / 200] Step: [100 / 1130] avg_train_loss: 0.8046 | train_auc: 0.7598 | lr : 1e-05
Epoch [3 / 200] Step: [200 / 1130] avg_train_loss: 0.8329 | train_auc: 0.7321 | lr : 1e-05
Epoch [3 / 200] Step: [300 / 1130] avg_train_loss: 0.8289 | train_auc: 0.733 | lr : 1e-05
Epoch [3 / 200] Step: [400 / 1130] avg_train_loss: 0.8233 | train_auc: 0.7346 | lr : 1e-05
Epoch [3 / 200] Step: [500 / 1130] avg_train_loss: 0.8261 | train_auc: 0.7271 | lr : 1e-05
Epoch [3 / 200] Step: [600 / 1130] avg_train_loss: 0.8148 | train_auc: 0.744 | lr : 1e-05
Epoch [3 / 200] Step: [700 / 1130] avg_train_loss: 0.8254 | train_auc: 0.7232 | lr : 1e-05
Epoch [3 / 200] Step: [800 / 1130] avg_train_loss: 0.8275 | train_auc: 0.7184 | lr : 1e-05
Epoch [3 / 200] Step: [900 / 1130] avg_train_loss: 0.8276 | train_auc: 0.709 | lr : 1e-05
Epoch [3 / 200] Step: [1000 / 1130] avg_train_loss: 0.8236 | train_auc: 0.7053 | lr : 1e-05
Epoch [3 / 200] Step: [1100 / 1130] avg_train_loss: 0.8259 | train_auc: 0.6973 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 3 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.4942 | val_auc: nan | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.5382 | val_auc: nan | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5792 | val_auc: 0.8519 | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6331 | val_auc: 0.7818 | lr: 1e-05
[Epoch: 3 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6497 | val_auc: 0.8053 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_coronal_train_auc_0.6983_val_auc_0.7458_train_loss_0.8262_val_loss_0.7021_epoch_3_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 4
[TRAIN] Train model
Epoch [4 / 200] Step: [100 / 1130] avg_train_loss: 0.7791 | train_auc: 0.6979 | lr : 1e-05
Epoch [4 / 200] Step: [200 / 1130] avg_train_loss: 0.7838 | train_auc: 0.7028 | lr : 1e-05
Epoch [4 / 200] Step: [300 / 1130] avg_train_loss: 0.7718 | train_auc: 0.725 | lr : 1e-05
Epoch [4 / 200] Step: [400 / 1130] avg_train_loss: 0.7643 | train_auc: 0.7458 | lr : 1e-05
Epoch [4 / 200] Step: [500 / 1130] avg_train_loss: 0.768 | train_auc: 0.7503 | lr : 1e-05
Epoch [4 / 200] Step: [600 / 1130] avg_train_loss: 0.7852 | train_auc: 0.7431 | lr : 1e-05
Epoch [4 / 200] Step: [700 / 1130] avg_train_loss: 0.7901 | train_auc: 0.7419 | lr : 1e-05
Epoch [4 / 200] Step: [800 / 1130] avg_train_loss: 0.7886 | train_auc: 0.7386 | lr : 1e-05
Epoch [4 / 200] Step: [900 / 1130] avg_train_loss: 0.7978 | train_auc: 0.7295 | lr : 1e-05
Epoch [4 / 200] Step: [1000 / 1130] avg_train_loss: 0.8036 | train_auc: 0.7256 | lr : 1e-05
Epoch [4 / 200] Step: [1100 / 1130] avg_train_loss: 0.8023 | train_auc: 0.7299 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 4 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.5402 | val_auc: nan | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.6138 | val_auc: nan | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6409 | val_auc: 0.8704 | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6817 | val_auc: 0.7538 | lr: 1e-05
[Epoch: 4 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6523 | val_auc: 0.8209 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_coronal_train_auc_0.7300_val_auc_0.7489_train_loss_0.8020_val_loss_0.6848_epoch_4_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 5
[TRAIN] Train model
Epoch [5 / 200] Step: [100 / 1130] avg_train_loss: 0.8335 | train_auc: 0.6833 | lr : 1e-05
Epoch [5 / 200] Step: [200 / 1130] avg_train_loss: 0.7365 | train_auc: 0.7981 | lr : 1e-05
Epoch [5 / 200] Step: [300 / 1130] avg_train_loss: 0.7323 | train_auc: 0.8 | lr : 1e-05
Epoch [5 / 200] Step: [400 / 1130] avg_train_loss: 0.768 | train_auc: 0.7559 | lr : 1e-05
Epoch [5 / 200] Step: [500 / 1130] avg_train_loss: 0.7635 | train_auc: 0.7636 | lr : 1e-05
Epoch [5 / 200] Step: [600 / 1130] avg_train_loss: 0.7665 | train_auc: 0.7572 | lr : 1e-05
Epoch [5 / 200] Step: [700 / 1130] avg_train_loss: 0.7569 | train_auc: 0.7621 | lr : 1e-05
Epoch [5 / 200] Step: [800 / 1130] avg_train_loss: 0.7459 | train_auc: 0.7767 | lr : 1e-05
Epoch [5 / 200] Step: [900 / 1130] avg_train_loss: 0.7393 | train_auc: 0.7834 | lr : 1e-05
Epoch [5 / 200] Step: [1000 / 1130] avg_train_loss: 0.7422 | train_auc: 0.7838 | lr : 1e-05
Epoch [5 / 200] Step: [1100 / 1130] avg_train_loss: 0.7492 | train_auc: 0.7746 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 5 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3859 | val_auc: nan | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.4673 | val_auc: nan | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5223 | val_auc: 0.8915 | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6012 | val_auc: 0.809 | lr: 1e-05
[Epoch: 5 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5958 | val_auc: 0.8293 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_coronal_train_auc_0.7771_val_auc_0.7958_train_loss_0.7466_val_loss_0.6415_epoch_5_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 6
[TRAIN] Train model
Epoch [6 / 200] Step: [100 / 1130] avg_train_loss: 0.7095 | train_auc: 0.8297 | lr : 1e-05
Epoch [6 / 200] Step: [200 / 1130] avg_train_loss: 0.7343 | train_auc: 0.7997 | lr : 1e-05
Epoch [6 / 200] Step: [300 / 1130] avg_train_loss: 0.7269 | train_auc: 0.8037 | lr : 1e-05
Epoch [6 / 200] Step: [400 / 1130] avg_train_loss: 0.7074 | train_auc: 0.8122 | lr : 1e-05
Epoch [6 / 200] Step: [500 / 1130] avg_train_loss: 0.6985 | train_auc: 0.8195 | lr : 1e-05
Epoch [6 / 200] Step: [600 / 1130] avg_train_loss: 0.6985 | train_auc: 0.8151 | lr : 1e-05
Epoch [6 / 200] Step: [700 / 1130] avg_train_loss: 0.7035 | train_auc: 0.8125 | lr : 1e-05
Epoch [6 / 200] Step: [800 / 1130] avg_train_loss: 0.7091 | train_auc: 0.8083 | lr : 1e-05
Epoch [6 / 200] Step: [900 / 1130] avg_train_loss: 0.7264 | train_auc: 0.7961 | lr : 1e-05
Epoch [6 / 200] Step: [1000 / 1130] avg_train_loss: 0.7261 | train_auc: 0.795 | lr : 1e-05
Epoch [6 / 200] Step: [1100 / 1130] avg_train_loss: 0.7191 | train_auc: 0.7991 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 6 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3391 | val_auc: nan | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.4394 | val_auc: nan | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.5205 | val_auc: 0.9259 | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6021 | val_auc: 0.8022 | lr: 1e-05
[Epoch: 6 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5886 | val_auc: 0.8351 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_coronal_train_auc_0.8001_val_auc_0.7969_train_loss_0.7178_val_loss_0.6362_epoch_6_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth"
[TRAIN] EPOCH # 7
[TRAIN] Train model
Epoch [7 / 200] Step: [100 / 1130] avg_train_loss: 0.7108 | train_auc: 0.8091 | lr : 1e-05
Epoch [7 / 200] Step: [200 / 1130] avg_train_loss: 0.7012 | train_auc: 0.8168 | lr : 1e-05
Epoch [7 / 200] Step: [300 / 1130] avg_train_loss: 0.6794 | train_auc: 0.8316 | lr : 1e-05
Epoch [7 / 200] Step: [400 / 1130] avg_train_loss: 0.6713 | train_auc: 0.8369 | lr : 1e-05
Epoch [7 / 200] Step: [500 / 1130] avg_train_loss: 0.6614 | train_auc: 0.8452 | lr : 1e-05
Epoch [7 / 200] Step: [600 / 1130] avg_train_loss: 0.6496 | train_auc: 0.8526 | lr : 1e-05
Epoch [7 / 200] Step: [700 / 1130] avg_train_loss: 0.6665 | train_auc: 0.8356 | lr : 1e-05
Epoch [7 / 200] Step: [800 / 1130] avg_train_loss: 0.6599 | train_auc: 0.8387 | lr : 1e-05
Epoch [7 / 200] Step: [900 / 1130] avg_train_loss: 0.6672 | train_auc: 0.829 | lr : 1e-05
Epoch [7 / 200] Step: [1000 / 1130] avg_train_loss: 0.6705 | train_auc: 0.8244 | lr : 1e-05
Epoch [7 / 200] Step: [1100 / 1130] avg_train_loss: 0.6682 | train_auc: 0.8269 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 7 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2632 | val_auc: nan | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.3526 | val_auc: nan | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4097 | val_auc: 0.9233 | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5343 | val_auc: 0.7929 | lr: 1e-05
[Epoch: 7 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5765 | val_auc: 0.8128 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 8
[TRAIN] Train model
Epoch [8 / 200] Step: [100 / 1130] avg_train_loss: 0.5568 | train_auc: 0.9054 | lr : 1e-05
Epoch [8 / 200] Step: [200 / 1130] avg_train_loss: 0.5997 | train_auc: 0.8845 | lr : 1e-05
Epoch [8 / 200] Step: [300 / 1130] avg_train_loss: 0.6072 | train_auc: 0.8742 | lr : 1e-05
Epoch [8 / 200] Step: [400 / 1130] avg_train_loss: 0.6368 | train_auc: 0.8579 | lr : 1e-05
Epoch [8 / 200] Step: [500 / 1130] avg_train_loss: 0.6254 | train_auc: 0.8612 | lr : 1e-05
Epoch [8 / 200] Step: [600 / 1130] avg_train_loss: 0.6491 | train_auc: 0.8457 | lr : 1e-05
Epoch [8 / 200] Step: [700 / 1130] avg_train_loss: 0.6427 | train_auc: 0.8521 | lr : 1e-05
Epoch [8 / 200] Step: [800 / 1130] avg_train_loss: 0.6362 | train_auc: 0.8556 | lr : 1e-05
Epoch [8 / 200] Step: [900 / 1130] avg_train_loss: 0.6508 | train_auc: 0.8443 | lr : 1e-05
Epoch [8 / 200] Step: [1000 / 1130] avg_train_loss: 0.6518 | train_auc: 0.8426 | lr : 1e-05
Epoch [8 / 200] Step: [1100 / 1130] avg_train_loss: 0.6506 | train_auc: 0.8422 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 8 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2577 | val_auc: nan | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2991 | val_auc: nan | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4044 | val_auc: 0.8889 | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5398 | val_auc: 0.7818 | lr: 1e-05
[Epoch: 8 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5832 | val_auc: 0.8066 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 9
[TRAIN] Train model
Epoch [9 / 200] Step: [100 / 1130] avg_train_loss: 0.6009 | train_auc: 0.8498 | lr : 1e-05
Epoch [9 / 200] Step: [200 / 1130] avg_train_loss: 0.624 | train_auc: 0.8435 | lr : 1e-05
Epoch [9 / 200] Step: [300 / 1130] avg_train_loss: 0.6336 | train_auc: 0.8314 | lr : 1e-05
Epoch [9 / 200] Step: [400 / 1130] avg_train_loss: 0.6248 | train_auc: 0.8428 | lr : 1e-05
Epoch [9 / 200] Step: [500 / 1130] avg_train_loss: 0.635 | train_auc: 0.8359 | lr : 1e-05
Epoch [9 / 200] Step: [600 / 1130] avg_train_loss: 0.6282 | train_auc: 0.8451 | lr : 1e-05
Epoch [9 / 200] Step: [700 / 1130] avg_train_loss: 0.6181 | train_auc: 0.853 | lr : 1e-05
Epoch [9 / 200] Step: [800 / 1130] avg_train_loss: 0.601 | train_auc: 0.8639 | lr : 1e-05
Epoch [9 / 200] Step: [900 / 1130] avg_train_loss: 0.6097 | train_auc: 0.8572 | lr : 1e-05
Epoch [9 / 200] Step: [1000 / 1130] avg_train_loss: 0.6136 | train_auc: 0.8555 | lr : 1e-05
Epoch [9 / 200] Step: [1100 / 1130] avg_train_loss: 0.6197 | train_auc: 0.8525 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 9 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.4555 | val_auc: nan | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.5286 | val_auc: nan | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.6303 | val_auc: 0.8386 | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6903 | val_auc: 0.7649 | lr: 1e-05
[Epoch: 9 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.642 | val_auc: 0.8155 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 10
[TRAIN] Train model
Epoch [10 / 200] Step: [100 / 1130] avg_train_loss: 0.5778 | train_auc: 0.8897 | lr : 1e-05
Epoch [10 / 200] Step: [200 / 1130] avg_train_loss: 0.5594 | train_auc: 0.8965 | lr : 1e-05
Epoch [10 / 200] Step: [300 / 1130] avg_train_loss: 0.5739 | train_auc: 0.8811 | lr : 1e-05
Epoch [10 / 200] Step: [400 / 1130] avg_train_loss: 0.554 | train_auc: 0.8906 | lr : 1e-05
Epoch [10 / 200] Step: [500 / 1130] avg_train_loss: 0.5491 | train_auc: 0.8939 | lr : 1e-05
Epoch [10 / 200] Step: [600 / 1130] avg_train_loss: 0.5371 | train_auc: 0.8988 | lr : 1e-05
Epoch [10 / 200] Step: [700 / 1130] avg_train_loss: 0.5342 | train_auc: 0.8995 | lr : 1e-05
Epoch [10 / 200] Step: [800 / 1130] avg_train_loss: 0.5527 | train_auc: 0.891 | lr : 1e-05
Epoch [10 / 200] Step: [900 / 1130] avg_train_loss: 0.5535 | train_auc: 0.8902 | lr : 1e-05
Epoch [10 / 200] Step: [1000 / 1130] avg_train_loss: 0.5625 | train_auc: 0.8878 | lr : 1e-05
Epoch [10 / 200] Step: [1100 / 1130] avg_train_loss: 0.5732 | train_auc: 0.8804 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 10 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2231 | val_auc: nan | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2457 | val_auc: nan | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4149 | val_auc: 0.8492 | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5814 | val_auc: 0.7411 | lr: 1e-05
[Epoch: 10 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6419 | val_auc: 0.7678 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 11
[TRAIN] Train model
Epoch [11 / 200] Step: [100 / 1130] avg_train_loss: 0.54 | train_auc: 0.8991 | lr : 3e-06
Epoch [11 / 200] Step: [200 / 1130] avg_train_loss: 0.5678 | train_auc: 0.8845 | lr : 3e-06
Epoch [11 / 200] Step: [300 / 1130] avg_train_loss: 0.4988 | train_auc: 0.9162 | lr : 3e-06
Epoch [11 / 200] Step: [400 / 1130] avg_train_loss: 0.5081 | train_auc: 0.9107 | lr : 3e-06
Epoch [11 / 200] Step: [500 / 1130] avg_train_loss: 0.4905 | train_auc: 0.9168 | lr : 3e-06
Epoch [11 / 200] Step: [600 / 1130] avg_train_loss: 0.4919 | train_auc: 0.9137 | lr : 3e-06
Epoch [11 / 200] Step: [700 / 1130] avg_train_loss: 0.4943 | train_auc: 0.9162 | lr : 3e-06
Epoch [11 / 200] Step: [800 / 1130] avg_train_loss: 0.48 | train_auc: 0.9226 | lr : 3e-06
Epoch [11 / 200] Step: [900 / 1130] avg_train_loss: 0.4846 | train_auc: 0.9218 | lr : 3e-06
Epoch [11 / 200] Step: [1000 / 1130] avg_train_loss: 0.4936 | train_auc: 0.9177 | lr : 3e-06
Epoch [11 / 200] Step: [1100 / 1130] avg_train_loss: 0.488 | train_auc: 0.9207 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 11 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1393 | val_auc: nan | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1593 | val_auc: nan | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3798 | val_auc: 0.7487 | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6018 | val_auc: 0.7156 | lr: 3e-06
[Epoch: 11 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7152 | val_auc: 0.754 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 12
[TRAIN] Train model
Epoch [12 / 200] Step: [100 / 1130] avg_train_loss: 0.4025 | train_auc: 0.9388 | lr : 3e-06
Epoch [12 / 200] Step: [200 / 1130] avg_train_loss: 0.382 | train_auc: 0.9489 | lr : 3e-06
Epoch [12 / 200] Step: [300 / 1130] avg_train_loss: 0.388 | train_auc: 0.95 | lr : 3e-06
Epoch [12 / 200] Step: [400 / 1130] avg_train_loss: 0.3873 | train_auc: 0.9539 | lr : 3e-06
Epoch [12 / 200] Step: [500 / 1130] avg_train_loss: 0.3953 | train_auc: 0.9499 | lr : 3e-06
Epoch [12 / 200] Step: [600 / 1130] avg_train_loss: 0.4086 | train_auc: 0.9422 | lr : 3e-06
Epoch [12 / 200] Step: [700 / 1130] avg_train_loss: 0.4301 | train_auc: 0.9351 | lr : 3e-06
Epoch [12 / 200] Step: [800 / 1130] avg_train_loss: 0.4359 | train_auc: 0.9346 | lr : 3e-06
Epoch [12 / 200] Step: [900 / 1130] avg_train_loss: 0.4368 | train_auc: 0.9345 | lr : 3e-06
Epoch [12 / 200] Step: [1000 / 1130] avg_train_loss: 0.4427 | train_auc: 0.9325 | lr : 3e-06
Epoch [12 / 200] Step: [1100 / 1130] avg_train_loss: 0.4509 | train_auc: 0.9308 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 12 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2514 | val_auc: nan | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.297 | val_auc: nan | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4759 | val_auc: 0.7275 | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5842 | val_auc: 0.7402 | lr: 3e-06
[Epoch: 12 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.5959 | val_auc: 0.7883 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 13
[TRAIN] Train model
Epoch [13 / 200] Step: [100 / 1130] avg_train_loss: 0.3963 | train_auc: 0.9493 | lr : 3e-06
Epoch [13 / 200] Step: [200 / 1130] avg_train_loss: 0.3664 | train_auc: 0.9584 | lr : 3e-06
Epoch [13 / 200] Step: [300 / 1130] avg_train_loss: 0.3693 | train_auc: 0.9575 | lr : 3e-06
Epoch [13 / 200] Step: [400 / 1130] avg_train_loss: 0.4065 | train_auc: 0.9433 | lr : 3e-06
Epoch [13 / 200] Step: [500 / 1130] avg_train_loss: 0.3965 | train_auc: 0.9495 | lr : 3e-06
Epoch [13 / 200] Step: [600 / 1130] avg_train_loss: 0.4009 | train_auc: 0.9471 | lr : 3e-06
Epoch [13 / 200] Step: [700 / 1130] avg_train_loss: 0.3892 | train_auc: 0.9519 | lr : 3e-06
Epoch [13 / 200] Step: [800 / 1130] avg_train_loss: 0.39 | train_auc: 0.9524 | lr : 3e-06
Epoch [13 / 200] Step: [900 / 1130] avg_train_loss: 0.3978 | train_auc: 0.9498 | lr : 3e-06
Epoch [13 / 200] Step: [1000 / 1130] avg_train_loss: 0.4031 | train_auc: 0.9483 | lr : 3e-06
Epoch [13 / 200] Step: [1100 / 1130] avg_train_loss: 0.3977 | train_auc: 0.9492 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 13 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2532 | val_auc: nan | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2836 | val_auc: nan | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4423 | val_auc: 0.7407 | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5949 | val_auc: 0.7114 | lr: 3e-06
[Epoch: 13 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6323 | val_auc: 0.7634 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 14
[TRAIN] Train model
Epoch [14 / 200] Step: [100 / 1130] avg_train_loss: 0.4983 | train_auc: 0.9226 | lr : 3e-06
Epoch [14 / 200] Step: [200 / 1130] avg_train_loss: 0.4317 | train_auc: 0.9395 | lr : 3e-06
Epoch [14 / 200] Step: [300 / 1130] avg_train_loss: 0.4349 | train_auc: 0.9347 | lr : 3e-06
Epoch [14 / 200] Step: [400 / 1130] avg_train_loss: 0.4222 | train_auc: 0.939 | lr : 3e-06
Epoch [14 / 200] Step: [500 / 1130] avg_train_loss: 0.4163 | train_auc: 0.9408 | lr : 3e-06
Epoch [14 / 200] Step: [600 / 1130] avg_train_loss: 0.3954 | train_auc: 0.949 | lr : 3e-06
Epoch [14 / 200] Step: [700 / 1130] avg_train_loss: 0.3873 | train_auc: 0.9507 | lr : 3e-06
Epoch [14 / 200] Step: [800 / 1130] avg_train_loss: 0.3853 | train_auc: 0.9519 | lr : 3e-06
Epoch [14 / 200] Step: [900 / 1130] avg_train_loss: 0.3844 | train_auc: 0.9519 | lr : 3e-06
Epoch [14 / 200] Step: [1000 / 1130] avg_train_loss: 0.3814 | train_auc: 0.9526 | lr : 3e-06
Epoch [14 / 200] Step: [1100 / 1130] avg_train_loss: 0.3834 | train_auc: 0.9521 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 14 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1491 | val_auc: nan | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.164 | val_auc: nan | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4145 | val_auc: 0.6402 | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.5983 | val_auc: 0.6969 | lr: 3e-06
[Epoch: 14 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6632 | val_auc: 0.7464 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 15
[TRAIN] Train model
Epoch [15 / 200] Step: [100 / 1130] avg_train_loss: 0.4351 | train_auc: 0.9394 | lr : 9e-07
Epoch [15 / 200] Step: [200 / 1130] avg_train_loss: 0.3653 | train_auc: 0.9607 | lr : 9e-07
Epoch [15 / 200] Step: [300 / 1130] avg_train_loss: 0.3355 | train_auc: 0.9684 | lr : 9e-07
Epoch [15 / 200] Step: [400 / 1130] avg_train_loss: 0.3295 | train_auc: 0.9709 | lr : 9e-07
Epoch [15 / 200] Step: [500 / 1130] avg_train_loss: 0.3215 | train_auc: 0.9723 | lr : 9e-07
Epoch [15 / 200] Step: [600 / 1130] avg_train_loss: 0.3263 | train_auc: 0.971 | lr : 9e-07
Epoch [15 / 200] Step: [700 / 1130] avg_train_loss: 0.3316 | train_auc: 0.9702 | lr : 9e-07
Epoch [15 / 200] Step: [800 / 1130] avg_train_loss: 0.3391 | train_auc: 0.9673 | lr : 9e-07
Epoch [15 / 200] Step: [900 / 1130] avg_train_loss: 0.3455 | train_auc: 0.9654 | lr : 9e-07
Epoch [15 / 200] Step: [1000 / 1130] avg_train_loss: 0.3477 | train_auc: 0.9654 | lr : 9e-07
Epoch [15 / 200] Step: [1100 / 1130] avg_train_loss: 0.345 | train_auc: 0.965 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 15 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1521 | val_auc: nan | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1544 | val_auc: nan | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3986 | val_auc: 0.7249 | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6283 | val_auc: 0.7122 | lr: 9e-07
[Epoch: 15 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7314 | val_auc: 0.7491 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 16
[TRAIN] Train model
Epoch [16 / 200] Step: [100 / 1130] avg_train_loss: 0.3066 | train_auc: 0.9692 | lr : 9e-07
Epoch [16 / 200] Step: [200 / 1130] avg_train_loss: 0.3248 | train_auc: 0.9727 | lr : 9e-07
Epoch [16 / 200] Step: [300 / 1130] avg_train_loss: 0.3408 | train_auc: 0.9588 | lr : 9e-07
Epoch [16 / 200] Step: [400 / 1130] avg_train_loss: 0.35 | train_auc: 0.9576 | lr : 9e-07
Epoch [16 / 200] Step: [500 / 1130] avg_train_loss: 0.3497 | train_auc: 0.9603 | lr : 9e-07
Epoch [16 / 200] Step: [600 / 1130] avg_train_loss: 0.3401 | train_auc: 0.9642 | lr : 9e-07
Epoch [16 / 200] Step: [700 / 1130] avg_train_loss: 0.3494 | train_auc: 0.9608 | lr : 9e-07
Epoch [16 / 200] Step: [800 / 1130] avg_train_loss: 0.3523 | train_auc: 0.9622 | lr : 9e-07
Epoch [16 / 200] Step: [900 / 1130] avg_train_loss: 0.3537 | train_auc: 0.9617 | lr : 9e-07
Epoch [16 / 200] Step: [1000 / 1130] avg_train_loss: 0.3529 | train_auc: 0.9619 | lr : 9e-07
Epoch [16 / 200] Step: [1100 / 1130] avg_train_loss: 0.3512 | train_auc: 0.9622 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 16 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1631 | val_auc: nan | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1926 | val_auc: nan | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.437 | val_auc: 0.7143 | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6215 | val_auc: 0.708 | lr: 9e-07
[Epoch: 16 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6855 | val_auc: 0.7527 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 17
[TRAIN] Train model
Epoch [17 / 200] Step: [100 / 1130] avg_train_loss: 0.3608 | train_auc: 0.9434 | lr : 9e-07
Epoch [17 / 200] Step: [200 / 1130] avg_train_loss: 0.3575 | train_auc: 0.9576 | lr : 9e-07
Epoch [17 / 200] Step: [300 / 1130] avg_train_loss: 0.3333 | train_auc: 0.9656 | lr : 9e-07
Epoch [17 / 200] Step: [400 / 1130] avg_train_loss: 0.3393 | train_auc: 0.9666 | lr : 9e-07
Epoch [17 / 200] Step: [500 / 1130] avg_train_loss: 0.3265 | train_auc: 0.9708 | lr : 9e-07
Epoch [17 / 200] Step: [600 / 1130] avg_train_loss: 0.3257 | train_auc: 0.9712 | lr : 9e-07
Epoch [17 / 200] Step: [700 / 1130] avg_train_loss: 0.3172 | train_auc: 0.9734 | lr : 9e-07
Epoch [17 / 200] Step: [800 / 1130] avg_train_loss: 0.3146 | train_auc: 0.9739 | lr : 9e-07
Epoch [17 / 200] Step: [900 / 1130] avg_train_loss: 0.3279 | train_auc: 0.9686 | lr : 9e-07
Epoch [17 / 200] Step: [1000 / 1130] avg_train_loss: 0.3249 | train_auc: 0.9696 | lr : 9e-07
Epoch [17 / 200] Step: [1100 / 1130] avg_train_loss: 0.3302 | train_auc: 0.9679 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 17 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1587 | val_auc: nan | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1605 | val_auc: nan | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4191 | val_auc: 0.6534 | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6483 | val_auc: 0.68 | lr: 9e-07
[Epoch: 17 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7628 | val_auc: 0.7228 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 18
[TRAIN] Train model
Epoch [18 / 200] Step: [100 / 1130] avg_train_loss: 0.3331 | train_auc: 0.9514 | lr : 9e-07
Epoch [18 / 200] Step: [200 / 1130] avg_train_loss: 0.3093 | train_auc: 0.9683 | lr : 9e-07
Epoch [18 / 200] Step: [300 / 1130] avg_train_loss: 0.3176 | train_auc: 0.9617 | lr : 9e-07
Epoch [18 / 200] Step: [400 / 1130] avg_train_loss: 0.3184 | train_auc: 0.9639 | lr : 9e-07
Epoch [18 / 200] Step: [500 / 1130] avg_train_loss: 0.3174 | train_auc: 0.9647 | lr : 9e-07
Epoch [18 / 200] Step: [600 / 1130] avg_train_loss: 0.2966 | train_auc: 0.9705 | lr : 9e-07
Epoch [18 / 200] Step: [700 / 1130] avg_train_loss: 0.2996 | train_auc: 0.9713 | lr : 9e-07
Epoch [18 / 200] Step: [800 / 1130] avg_train_loss: 0.2955 | train_auc: 0.973 | lr : 9e-07
Epoch [18 / 200] Step: [900 / 1130] avg_train_loss: 0.3038 | train_auc: 0.9716 | lr : 9e-07
Epoch [18 / 200] Step: [1000 / 1130] avg_train_loss: 0.301 | train_auc: 0.9722 | lr : 9e-07
Epoch [18 / 200] Step: [1100 / 1130] avg_train_loss: 0.3026 | train_auc: 0.9716 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 18 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1939 | val_auc: nan | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1979 | val_auc: nan | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4204 | val_auc: 0.7275 | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6179 | val_auc: 0.7003 | lr: 9e-07
[Epoch: 18 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.683 | val_auc: 0.7447 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 19
[TRAIN] Train model
Epoch [19 / 200] Step: [100 / 1130] avg_train_loss: 0.2989 | train_auc: 0.9779 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [200 / 1130] avg_train_loss: 0.292 | train_auc: 0.9748 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [300 / 1130] avg_train_loss: 0.2884 | train_auc: 0.9752 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [400 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9769 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [500 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9778 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [600 / 1130] avg_train_loss: 0.2927 | train_auc: 0.9764 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [700 / 1130] avg_train_loss: 0.3027 | train_auc: 0.9739 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [800 / 1130] avg_train_loss: 0.3033 | train_auc: 0.9737 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [900 / 1130] avg_train_loss: 0.3087 | train_auc: 0.9725 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [1000 / 1130] avg_train_loss: 0.2974 | train_auc: 0.9755 | lr : 2.6999999999999996e-07
Epoch [19 / 200] Step: [1100 / 1130] avg_train_loss: 0.3014 | train_auc: 0.9751 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 19 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1681 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1779 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.409 | val_auc: 0.7143 | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6073 | val_auc: 0.7037 | lr: 2.6999999999999996e-07
[Epoch: 19 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6709 | val_auc: 0.7598 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 20
[TRAIN] Train model
Epoch [20 / 200] Step: [100 / 1130] avg_train_loss: 0.3194 | train_auc: 0.9737 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [200 / 1130] avg_train_loss: 0.2676 | train_auc: 0.9861 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [300 / 1130] avg_train_loss: 0.289 | train_auc: 0.9795 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [400 / 1130] avg_train_loss: 0.2893 | train_auc: 0.9783 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [500 / 1130] avg_train_loss: 0.286 | train_auc: 0.9788 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [600 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9787 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [700 / 1130] avg_train_loss: 0.2944 | train_auc: 0.9765 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [800 / 1130] avg_train_loss: 0.2987 | train_auc: 0.9756 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [900 / 1130] avg_train_loss: 0.2936 | train_auc: 0.9773 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [1000 / 1130] avg_train_loss: 0.3073 | train_auc: 0.9727 | lr : 2.6999999999999996e-07
Epoch [20 / 200] Step: [1100 / 1130] avg_train_loss: 0.3183 | train_auc: 0.9698 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 20 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1995 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1876 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4215 | val_auc: 0.7169 | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6424 | val_auc: 0.6842 | lr: 2.6999999999999996e-07
[Epoch: 20 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7168 | val_auc: 0.7406 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 21
[TRAIN] Train model
Epoch [21 / 200] Step: [100 / 1130] avg_train_loss: 0.3355 | train_auc: 0.9675 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [200 / 1130] avg_train_loss: 0.3381 | train_auc: 0.9648 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [300 / 1130] avg_train_loss: 0.3417 | train_auc: 0.9634 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [400 / 1130] avg_train_loss: 0.3317 | train_auc: 0.9665 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [500 / 1130] avg_train_loss: 0.324 | train_auc: 0.9682 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [600 / 1130] avg_train_loss: 0.3354 | train_auc: 0.964 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [700 / 1130] avg_train_loss: 0.3387 | train_auc: 0.9625 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [800 / 1130] avg_train_loss: 0.339 | train_auc: 0.9634 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [900 / 1130] avg_train_loss: 0.3335 | train_auc: 0.9648 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [1000 / 1130] avg_train_loss: 0.3247 | train_auc: 0.967 | lr : 2.6999999999999996e-07
Epoch [21 / 200] Step: [1100 / 1130] avg_train_loss: 0.3213 | train_auc: 0.9683 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 21 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1845 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1842 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4279 | val_auc: 0.6825 | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6518 | val_auc: 0.6715 | lr: 2.6999999999999996e-07
[Epoch: 21 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7228 | val_auc: 0.7348 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 22
[TRAIN] Train model
Epoch [22 / 200] Step: [100 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9886 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [200 / 1130] avg_train_loss: 0.2744 | train_auc: 0.9832 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [300 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9818 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [400 / 1130] avg_train_loss: 0.2901 | train_auc: 0.9764 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [500 / 1130] avg_train_loss: 0.2832 | train_auc: 0.9781 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [600 / 1130] avg_train_loss: 0.2863 | train_auc: 0.9764 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [700 / 1130] avg_train_loss: 0.279 | train_auc: 0.9781 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [800 / 1130] avg_train_loss: 0.2723 | train_auc: 0.98 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [900 / 1130] avg_train_loss: 0.2696 | train_auc: 0.9806 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [1000 / 1130] avg_train_loss: 0.2733 | train_auc: 0.9804 | lr : 2.6999999999999996e-07
Epoch [22 / 200] Step: [1100 / 1130] avg_train_loss: 0.2747 | train_auc: 0.9803 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 22 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2288 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2213 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4384 | val_auc: 0.7011 | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6406 | val_auc: 0.6689 | lr: 2.6999999999999996e-07
[Epoch: 22 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6984 | val_auc: 0.7268 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 23
[TRAIN] Train model
Epoch [23 / 200] Step: [100 / 1130] avg_train_loss: 0.3389 | train_auc: 0.9635 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [200 / 1130] avg_train_loss: 0.2949 | train_auc: 0.9769 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [300 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9832 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [400 / 1130] avg_train_loss: 0.2958 | train_auc: 0.9751 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [500 / 1130] avg_train_loss: 0.2786 | train_auc: 0.9793 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [600 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9786 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [700 / 1130] avg_train_loss: 0.279 | train_auc: 0.9789 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [800 / 1130] avg_train_loss: 0.278 | train_auc: 0.9786 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [900 / 1130] avg_train_loss: 0.284 | train_auc: 0.9771 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [1000 / 1130] avg_train_loss: 0.279 | train_auc: 0.9783 | lr : 8.099999999999998e-08
Epoch [23 / 200] Step: [1100 / 1130] avg_train_loss: 0.2808 | train_auc: 0.9775 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 23 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1832 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1803 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4162 | val_auc: 0.6852 | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6445 | val_auc: 0.6553 | lr: 8.099999999999998e-08
[Epoch: 23 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7176 | val_auc: 0.7215 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 24
[TRAIN] Train model
Epoch [24 / 200] Step: [100 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9889 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [200 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9799 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [300 / 1130] avg_train_loss: 0.277 | train_auc: 0.9811 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [400 / 1130] avg_train_loss: 0.2838 | train_auc: 0.9747 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [500 / 1130] avg_train_loss: 0.2672 | train_auc: 0.9788 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [600 / 1130] avg_train_loss: 0.2629 | train_auc: 0.9809 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [700 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9814 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [800 / 1130] avg_train_loss: 0.261 | train_auc: 0.9811 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [900 / 1130] avg_train_loss: 0.2749 | train_auc: 0.9781 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [1000 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9779 | lr : 8.099999999999998e-08
Epoch [24 / 200] Step: [1100 / 1130] avg_train_loss: 0.2724 | train_auc: 0.9788 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 24 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1941 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.187 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4181 | val_auc: 0.7143 | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6512 | val_auc: 0.6749 | lr: 8.099999999999998e-08
[Epoch: 24 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7289 | val_auc: 0.7299 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 25
[TRAIN] Train model
Epoch [25 / 200] Step: [100 / 1130] avg_train_loss: 0.3603 | train_auc: 0.9632 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [200 / 1130] avg_train_loss: 0.3233 | train_auc: 0.9698 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [300 / 1130] avg_train_loss: 0.3318 | train_auc: 0.9643 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [400 / 1130] avg_train_loss: 0.315 | train_auc: 0.9695 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [500 / 1130] avg_train_loss: 0.3369 | train_auc: 0.9637 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [600 / 1130] avg_train_loss: 0.3299 | train_auc: 0.9665 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [700 / 1130] avg_train_loss: 0.3244 | train_auc: 0.9677 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [800 / 1130] avg_train_loss: 0.3199 | train_auc: 0.9686 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [900 / 1130] avg_train_loss: 0.3101 | train_auc: 0.9711 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [1000 / 1130] avg_train_loss: 0.3156 | train_auc: 0.97 | lr : 8.099999999999998e-08
Epoch [25 / 200] Step: [1100 / 1130] avg_train_loss: 0.3107 | train_auc: 0.9714 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 25 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1605 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1637 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.423 | val_auc: 0.6905 | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6578 | val_auc: 0.68 | lr: 8.099999999999998e-08
[Epoch: 25 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7498 | val_auc: 0.7255 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 26
[TRAIN] Train model
Epoch [26 / 200] Step: [100 / 1130] avg_train_loss: 0.2066 | train_auc: 0.9953 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [200 / 1130] avg_train_loss: 0.2456 | train_auc: 0.9868 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [300 / 1130] avg_train_loss: 0.2636 | train_auc: 0.9824 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [400 / 1130] avg_train_loss: 0.2793 | train_auc: 0.9794 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [500 / 1130] avg_train_loss: 0.2895 | train_auc: 0.9787 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [600 / 1130] avg_train_loss: 0.2898 | train_auc: 0.9781 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [700 / 1130] avg_train_loss: 0.2894 | train_auc: 0.9791 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [800 / 1130] avg_train_loss: 0.2908 | train_auc: 0.9787 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [900 / 1130] avg_train_loss: 0.2912 | train_auc: 0.9781 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [1000 / 1130] avg_train_loss: 0.2916 | train_auc: 0.9782 | lr : 8.099999999999998e-08
Epoch [26 / 200] Step: [1100 / 1130] avg_train_loss: 0.29 | train_auc: 0.9782 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 26 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1288 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1324 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3903 | val_auc: 0.7513 | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6592 | val_auc: 0.7054 | lr: 8.099999999999998e-08
[Epoch: 26 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7754 | val_auc: 0.7447 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 27
[TRAIN] Train model
Epoch [27 / 200] Step: [100 / 1130] avg_train_loss: 0.3267 | train_auc: 0.9684 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [200 / 1130] avg_train_loss: 0.2899 | train_auc: 0.9759 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [300 / 1130] avg_train_loss: 0.2937 | train_auc: 0.9751 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [400 / 1130] avg_train_loss: 0.2691 | train_auc: 0.9807 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [500 / 1130] avg_train_loss: 0.2603 | train_auc: 0.9827 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [600 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9838 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [700 / 1130] avg_train_loss: 0.2742 | train_auc: 0.9803 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [800 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9815 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [900 / 1130] avg_train_loss: 0.2728 | train_auc: 0.9806 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [1000 / 1130] avg_train_loss: 0.2698 | train_auc: 0.9816 | lr : 2.4299999999999996e-08
Epoch [27 / 200] Step: [1100 / 1130] avg_train_loss: 0.2714 | train_auc: 0.9813 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 27 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1777 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1868 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.404 | val_auc: 0.7275 | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6249 | val_auc: 0.6817 | lr: 2.4299999999999996e-08
[Epoch: 27 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7071 | val_auc: 0.7384 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 28
[TRAIN] Train model
Epoch [28 / 200] Step: [100 / 1130] avg_train_loss: 0.3793 | train_auc: 0.9528 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [200 / 1130] avg_train_loss: 0.319 | train_auc: 0.9701 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [300 / 1130] avg_train_loss: 0.3078 | train_auc: 0.9694 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [400 / 1130] avg_train_loss: 0.3232 | train_auc: 0.9638 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [500 / 1130] avg_train_loss: 0.3235 | train_auc: 0.9627 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [600 / 1130] avg_train_loss: 0.3225 | train_auc: 0.9628 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [700 / 1130] avg_train_loss: 0.3272 | train_auc: 0.9616 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [800 / 1130] avg_train_loss: 0.322 | train_auc: 0.9639 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [900 / 1130] avg_train_loss: 0.314 | train_auc: 0.966 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [1000 / 1130] avg_train_loss: 0.3068 | train_auc: 0.9684 | lr : 2.4299999999999996e-08
Epoch [28 / 200] Step: [1100 / 1130] avg_train_loss: 0.3049 | train_auc: 0.9695 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 28 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1695 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1867 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4233 | val_auc: 0.6878 | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6386 | val_auc: 0.6723 | lr: 2.4299999999999996e-08
[Epoch: 28 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7249 | val_auc: 0.7228 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 29
[TRAIN] Train model
Epoch [29 / 200] Step: [100 / 1130] avg_train_loss: 0.2155 | train_auc: 0.9965 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [200 / 1130] avg_train_loss: 0.2752 | train_auc: 0.98 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [300 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9747 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [400 / 1130] avg_train_loss: 0.2782 | train_auc: 0.9774 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [500 / 1130] avg_train_loss: 0.2718 | train_auc: 0.9807 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [600 / 1130] avg_train_loss: 0.2749 | train_auc: 0.9805 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [700 / 1130] avg_train_loss: 0.2835 | train_auc: 0.9783 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [800 / 1130] avg_train_loss: 0.276 | train_auc: 0.9802 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [900 / 1130] avg_train_loss: 0.2816 | train_auc: 0.9792 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [1000 / 1130] avg_train_loss: 0.282 | train_auc: 0.9789 | lr : 2.4299999999999996e-08
Epoch [29 / 200] Step: [1100 / 1130] avg_train_loss: 0.2807 | train_auc: 0.9793 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 29 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2538 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2484 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4728 | val_auc: 0.6905 | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6572 | val_auc: 0.6732 | lr: 2.4299999999999996e-08
[Epoch: 29 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6912 | val_auc: 0.7362 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 30
[TRAIN] Train model
Epoch [30 / 200] Step: [100 / 1130] avg_train_loss: 0.2314 | train_auc: 0.9889 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [200 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9857 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [300 / 1130] avg_train_loss: 0.2559 | train_auc: 0.9848 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [400 / 1130] avg_train_loss: 0.2557 | train_auc: 0.985 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [500 / 1130] avg_train_loss: 0.2723 | train_auc: 0.9792 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [600 / 1130] avg_train_loss: 0.26 | train_auc: 0.9823 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [700 / 1130] avg_train_loss: 0.2643 | train_auc: 0.981 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [800 / 1130] avg_train_loss: 0.2691 | train_auc: 0.9798 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [900 / 1130] avg_train_loss: 0.2667 | train_auc: 0.98 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [1000 / 1130] avg_train_loss: 0.2685 | train_auc: 0.9795 | lr : 2.4299999999999996e-08
Epoch [30 / 200] Step: [1100 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9801 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 30 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1786 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.187 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4517 | val_auc: 0.664 | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6602 | val_auc: 0.6834 | lr: 2.4299999999999996e-08
[Epoch: 30 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.741 | val_auc: 0.7331 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 31
[TRAIN] Train model
Epoch [31 / 200] Step: [100 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9696 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [200 / 1130] avg_train_loss: 0.2841 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [300 / 1130] avg_train_loss: 0.2859 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [400 / 1130] avg_train_loss: 0.2717 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [500 / 1130] avg_train_loss: 0.2755 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [600 / 1130] avg_train_loss: 0.2903 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [700 / 1130] avg_train_loss: 0.2876 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [800 / 1130] avg_train_loss: 0.2838 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [900 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [1000 / 1130] avg_train_loss: 0.2846 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [31 / 200] Step: [1100 / 1130] avg_train_loss: 0.2795 | train_auc: 0.9771 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 31 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2014 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1803 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4153 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6465 | val_auc: 0.6927 | lr: 7.289999999999999e-09
[Epoch: 31 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7474 | val_auc: 0.7304 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 32
[TRAIN] Train model
Epoch [32 / 200] Step: [100 / 1130] avg_train_loss: 0.2903 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [200 / 1130] avg_train_loss: 0.293 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [300 / 1130] avg_train_loss: 0.2656 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [400 / 1130] avg_train_loss: 0.2634 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [500 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [600 / 1130] avg_train_loss: 0.277 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [700 / 1130] avg_train_loss: 0.2728 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [800 / 1130] avg_train_loss: 0.2724 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [900 / 1130] avg_train_loss: 0.2811 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [1000 / 1130] avg_train_loss: 0.2806 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [32 / 200] Step: [1100 / 1130] avg_train_loss: 0.2833 | train_auc: 0.9762 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 32 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1584 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1537 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4057 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.646 | val_auc: 0.6986 | lr: 7.289999999999999e-09
[Epoch: 32 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7364 | val_auc: 0.7469 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 33
[TRAIN] Train model
Epoch [33 / 200] Step: [100 / 1130] avg_train_loss: 0.2172 | train_auc: 0.9922 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [200 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [300 / 1130] avg_train_loss: 0.2964 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [400 / 1130] avg_train_loss: 0.2978 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [500 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [600 / 1130] avg_train_loss: 0.2919 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [700 / 1130] avg_train_loss: 0.2865 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [800 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [900 / 1130] avg_train_loss: 0.2815 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [1000 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [33 / 200] Step: [1100 / 1130] avg_train_loss: 0.2821 | train_auc: 0.9791 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 33 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.25 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2427 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4476 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6314 | val_auc: 0.6868 | lr: 7.289999999999999e-09
[Epoch: 33 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6973 | val_auc: 0.7331 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 34
[TRAIN] Train model
Epoch [34 / 200] Step: [100 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [200 / 1130] avg_train_loss: 0.2553 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [300 / 1130] avg_train_loss: 0.2914 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [400 / 1130] avg_train_loss: 0.2867 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [500 / 1130] avg_train_loss: 0.2841 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [600 / 1130] avg_train_loss: 0.2812 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [700 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [800 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [900 / 1130] avg_train_loss: 0.2751 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [1000 / 1130] avg_train_loss: 0.2703 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [34 / 200] Step: [1100 / 1130] avg_train_loss: 0.2715 | train_auc: 0.9821 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 34 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1793 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1854 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4215 | val_auc: 0.7275 | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6377 | val_auc: 0.7029 | lr: 7.289999999999999e-09
[Epoch: 34 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7007 | val_auc: 0.7509 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 35
[TRAIN] Train model
Epoch [35 / 200] Step: [100 / 1130] avg_train_loss: 0.3548 | train_auc: 0.9611 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [200 / 1130] avg_train_loss: 0.2992 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [300 / 1130] avg_train_loss: 0.3085 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [400 / 1130] avg_train_loss: 0.2987 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [500 / 1130] avg_train_loss: 0.2901 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [600 / 1130] avg_train_loss: 0.2886 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [700 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [800 / 1130] avg_train_loss: 0.2705 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [900 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [1000 / 1130] avg_train_loss: 0.28 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [35 / 200] Step: [1100 / 1130] avg_train_loss: 0.2915 | train_auc: 0.9737 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 35 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1257 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1355 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3779 | val_auc: 0.7937 | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6311 | val_auc: 0.7428 | lr: 7.289999999999999e-09
[Epoch: 35 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7613 | val_auc: 0.7665 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 36
[TRAIN] Train model
Epoch [36 / 200] Step: [100 / 1130] avg_train_loss: 0.3628 | train_auc: 0.9623 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [200 / 1130] avg_train_loss: 0.2978 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [300 / 1130] avg_train_loss: 0.2921 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [400 / 1130] avg_train_loss: 0.296 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [500 / 1130] avg_train_loss: 0.2942 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [600 / 1130] avg_train_loss: 0.3135 | train_auc: 0.9706 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [700 / 1130] avg_train_loss: 0.3045 | train_auc: 0.9726 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [800 / 1130] avg_train_loss: 0.3058 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [900 / 1130] avg_train_loss: 0.3027 | train_auc: 0.973 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [1000 / 1130] avg_train_loss: 0.2956 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [36 / 200] Step: [1100 / 1130] avg_train_loss: 0.3038 | train_auc: 0.9726 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 36 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1446 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.147 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4196 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6641 | val_auc: 0.6876 | lr: 7.289999999999999e-09
[Epoch: 36 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7725 | val_auc: 0.7322 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 37
[TRAIN] Train model
Epoch [37 / 200] Step: [100 / 1130] avg_train_loss: 0.2344 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [200 / 1130] avg_train_loss: 0.2364 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [300 / 1130] avg_train_loss: 0.2945 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [400 / 1130] avg_train_loss: 0.2949 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [500 / 1130] avg_train_loss: 0.3218 | train_auc: 0.9701 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [600 / 1130] avg_train_loss: 0.3158 | train_auc: 0.9706 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [700 / 1130] avg_train_loss: 0.3074 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [800 / 1130] avg_train_loss: 0.3059 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [900 / 1130] avg_train_loss: 0.304 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [1000 / 1130] avg_train_loss: 0.3052 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [37 / 200] Step: [1100 / 1130] avg_train_loss: 0.2991 | train_auc: 0.9757 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 37 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1673 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1759 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4193 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6311 | val_auc: 0.6986 | lr: 7.289999999999999e-09
[Epoch: 37 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.716 | val_auc: 0.7366 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 38
[TRAIN] Train model
Epoch [38 / 200] Step: [100 / 1130] avg_train_loss: 0.2609 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [200 / 1130] avg_train_loss: 0.2764 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [300 / 1130] avg_train_loss: 0.2852 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [400 / 1130] avg_train_loss: 0.2807 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [500 / 1130] avg_train_loss: 0.2652 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [600 / 1130] avg_train_loss: 0.2764 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [700 / 1130] avg_train_loss: 0.2787 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [800 / 1130] avg_train_loss: 0.2923 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [900 / 1130] avg_train_loss: 0.2847 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [1000 / 1130] avg_train_loss: 0.2893 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [38 / 200] Step: [1100 / 1130] avg_train_loss: 0.2944 | train_auc: 0.9746 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 38 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1603 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1619 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4127 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.643 | val_auc: 0.6851 | lr: 7.289999999999999e-09
[Epoch: 38 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7244 | val_auc: 0.7348 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 39
[TRAIN] Train model
Epoch [39 / 200] Step: [100 / 1130] avg_train_loss: 0.2969 | train_auc: 0.968 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [200 / 1130] avg_train_loss: 0.3088 | train_auc: 0.9725 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [300 / 1130] avg_train_loss: 0.2862 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [400 / 1130] avg_train_loss: 0.2799 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [500 / 1130] avg_train_loss: 0.311 | train_auc: 0.9702 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [600 / 1130] avg_train_loss: 0.2956 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [700 / 1130] avg_train_loss: 0.3021 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [800 / 1130] avg_train_loss: 0.3001 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [900 / 1130] avg_train_loss: 0.2945 | train_auc: 0.9726 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [1000 / 1130] avg_train_loss: 0.2979 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [39 / 200] Step: [1100 / 1130] avg_train_loss: 0.3042 | train_auc: 0.971 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 39 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1488 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1464 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4041 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6607 | val_auc: 0.6638 | lr: 7.289999999999999e-09
[Epoch: 39 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7659 | val_auc: 0.7206 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 40
[TRAIN] Train model
Epoch [40 / 200] Step: [100 / 1130] avg_train_loss: 0.2691 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [200 / 1130] avg_train_loss: 0.3005 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [300 / 1130] avg_train_loss: 0.2737 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [400 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [500 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [600 / 1130] avg_train_loss: 0.2631 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [700 / 1130] avg_train_loss: 0.2579 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [800 / 1130] avg_train_loss: 0.2605 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [900 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [1000 / 1130] avg_train_loss: 0.2618 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [40 / 200] Step: [1100 / 1130] avg_train_loss: 0.2691 | train_auc: 0.9831 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 40 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1827 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1607 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4242 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6928 | val_auc: 0.6553 | lr: 7.289999999999999e-09
[Epoch: 40 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8214 | val_auc: 0.7001 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 41
[TRAIN] Train model
Epoch [41 / 200] Step: [100 / 1130] avg_train_loss: 0.3366 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [200 / 1130] avg_train_loss: 0.3117 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [300 / 1130] avg_train_loss: 0.301 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [400 / 1130] avg_train_loss: 0.2937 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [500 / 1130] avg_train_loss: 0.2806 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [600 / 1130] avg_train_loss: 0.2808 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [700 / 1130] avg_train_loss: 0.2727 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [800 / 1130] avg_train_loss: 0.2712 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [900 / 1130] avg_train_loss: 0.2698 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [1000 / 1130] avg_train_loss: 0.2729 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [41 / 200] Step: [1100 / 1130] avg_train_loss: 0.276 | train_auc: 0.9777 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 41 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1727 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1691 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4044 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6486 | val_auc: 0.6749 | lr: 7.289999999999999e-09
[Epoch: 41 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7557 | val_auc: 0.7282 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 42
[TRAIN] Train model
Epoch [42 / 200] Step: [100 / 1130] avg_train_loss: 0.2975 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [200 / 1130] avg_train_loss: 0.2806 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [300 / 1130] avg_train_loss: 0.2923 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [400 / 1130] avg_train_loss: 0.291 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [500 / 1130] avg_train_loss: 0.2901 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [600 / 1130] avg_train_loss: 0.2934 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [700 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [800 / 1130] avg_train_loss: 0.2908 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [900 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [1000 / 1130] avg_train_loss: 0.2839 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [42 / 200] Step: [1100 / 1130] avg_train_loss: 0.2845 | train_auc: 0.9747 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 42 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1933 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1901 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4138 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6561 | val_auc: 0.6384 | lr: 7.289999999999999e-09
[Epoch: 42 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7484 | val_auc: 0.7063 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 43
[TRAIN] Train model
Epoch [43 / 200] Step: [100 / 1130] avg_train_loss: 0.2715 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [200 / 1130] avg_train_loss: 0.265 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [300 / 1130] avg_train_loss: 0.2697 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [400 / 1130] avg_train_loss: 0.2934 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [500 / 1130] avg_train_loss: 0.2875 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [600 / 1130] avg_train_loss: 0.283 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [700 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [800 / 1130] avg_train_loss: 0.2705 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [900 / 1130] avg_train_loss: 0.261 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [1000 / 1130] avg_train_loss: 0.2708 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [43 / 200] Step: [1100 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9782 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 43 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1972 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1928 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.422 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6511 | val_auc: 0.6579 | lr: 7.289999999999999e-09
[Epoch: 43 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7299 | val_auc: 0.7201 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 44
[TRAIN] Train model
Epoch [44 / 200] Step: [100 / 1130] avg_train_loss: 0.2577 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [200 / 1130] avg_train_loss: 0.2431 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [300 / 1130] avg_train_loss: 0.2497 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [400 / 1130] avg_train_loss: 0.2571 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [500 / 1130] avg_train_loss: 0.2687 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [600 / 1130] avg_train_loss: 0.2647 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [700 / 1130] avg_train_loss: 0.2756 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [800 / 1130] avg_train_loss: 0.2746 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [900 / 1130] avg_train_loss: 0.2647 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [1000 / 1130] avg_train_loss: 0.2665 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [44 / 200] Step: [1100 / 1130] avg_train_loss: 0.2732 | train_auc: 0.9786 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 44 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.14 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1369 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4055 | val_auc: 0.7116 | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6672 | val_auc: 0.6842 | lr: 7.289999999999999e-09
[Epoch: 44 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.779 | val_auc: 0.7304 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 45
[TRAIN] Train model
Epoch [45 / 200] Step: [100 / 1130] avg_train_loss: 0.3308 | train_auc: 0.9737 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [200 / 1130] avg_train_loss: 0.3019 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [300 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [400 / 1130] avg_train_loss: 0.2728 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [500 / 1130] avg_train_loss: 0.269 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [600 / 1130] avg_train_loss: 0.2777 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [700 / 1130] avg_train_loss: 0.2893 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [800 / 1130] avg_train_loss: 0.2917 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [900 / 1130] avg_train_loss: 0.2977 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [1000 / 1130] avg_train_loss: 0.2975 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [45 / 200] Step: [1100 / 1130] avg_train_loss: 0.2935 | train_auc: 0.9764 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 45 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1466 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1453 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3906 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6448 | val_auc: 0.7003 | lr: 7.289999999999999e-09
[Epoch: 45 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7648 | val_auc: 0.7406 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 46
[TRAIN] Train model
Epoch [46 / 200] Step: [100 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9939 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [200 / 1130] avg_train_loss: 0.24 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [300 / 1130] avg_train_loss: 0.2407 | train_auc: 0.989 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [400 / 1130] avg_train_loss: 0.2669 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [500 / 1130] avg_train_loss: 0.2517 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [600 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [700 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [800 / 1130] avg_train_loss: 0.274 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [900 / 1130] avg_train_loss: 0.2729 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [1000 / 1130] avg_train_loss: 0.2712 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [46 / 200] Step: [1100 / 1130] avg_train_loss: 0.2704 | train_auc: 0.9788 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 46 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1411 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1391 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3906 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6327 | val_auc: 0.7216 | lr: 7.289999999999999e-09
[Epoch: 46 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7548 | val_auc: 0.7527 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 47
[TRAIN] Train model
Epoch [47 / 200] Step: [100 / 1130] avg_train_loss: 0.1633 | train_auc: 0.999 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [200 / 1130] avg_train_loss: 0.2327 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [300 / 1130] avg_train_loss: 0.2478 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [400 / 1130] avg_train_loss: 0.2718 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [500 / 1130] avg_train_loss: 0.276 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [600 / 1130] avg_train_loss: 0.2873 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [700 / 1130] avg_train_loss: 0.2857 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [800 / 1130] avg_train_loss: 0.2846 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [900 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [1000 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [47 / 200] Step: [1100 / 1130] avg_train_loss: 0.2898 | train_auc: 0.9755 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 47 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.13 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1363 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3882 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6346 | val_auc: 0.7122 | lr: 7.289999999999999e-09
[Epoch: 47 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7474 | val_auc: 0.758 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 48
[TRAIN] Train model
Epoch [48 / 200] Step: [100 / 1130] avg_train_loss: 0.277 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [200 / 1130] avg_train_loss: 0.2964 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [300 / 1130] avg_train_loss: 0.2886 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [400 / 1130] avg_train_loss: 0.2849 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [500 / 1130] avg_train_loss: 0.2863 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [600 / 1130] avg_train_loss: 0.28 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [700 / 1130] avg_train_loss: 0.2912 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [800 / 1130] avg_train_loss: 0.2927 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [900 / 1130] avg_train_loss: 0.2967 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [1000 / 1130] avg_train_loss: 0.2897 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [48 / 200] Step: [1100 / 1130] avg_train_loss: 0.2832 | train_auc: 0.9784 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 48 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1314 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.128 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4092 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6979 | val_auc: 0.6638 | lr: 7.289999999999999e-09
[Epoch: 48 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8391 | val_auc: 0.7059 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 49
[TRAIN] Train model
Epoch [49 / 200] Step: [100 / 1130] avg_train_loss: 0.2342 | train_auc: 0.9936 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [200 / 1130] avg_train_loss: 0.2628 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [300 / 1130] avg_train_loss: 0.2673 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [400 / 1130] avg_train_loss: 0.28 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [500 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [600 / 1130] avg_train_loss: 0.2878 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [700 / 1130] avg_train_loss: 0.2852 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [800 / 1130] avg_train_loss: 0.2793 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [900 / 1130] avg_train_loss: 0.2722 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [1000 / 1130] avg_train_loss: 0.2741 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [49 / 200] Step: [1100 / 1130] avg_train_loss: 0.2767 | train_auc: 0.9771 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 49 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1745 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1666 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4051 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6235 | val_auc: 0.7046 | lr: 7.289999999999999e-09
[Epoch: 49 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7059 | val_auc: 0.7589 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 50
[TRAIN] Train model
Epoch [50 / 200] Step: [100 / 1130] avg_train_loss: 0.211 | train_auc: 0.9939 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [200 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [300 / 1130] avg_train_loss: 0.2786 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [400 / 1130] avg_train_loss: 0.3172 | train_auc: 0.9701 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [500 / 1130] avg_train_loss: 0.3061 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [600 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [700 / 1130] avg_train_loss: 0.2914 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [800 / 1130] avg_train_loss: 0.2843 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [900 / 1130] avg_train_loss: 0.2807 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [1000 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [50 / 200] Step: [1100 / 1130] avg_train_loss: 0.276 | train_auc: 0.9786 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 50 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.221 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2197 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4409 | val_auc: 0.672 | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6351 | val_auc: 0.6689 | lr: 7.289999999999999e-09
[Epoch: 50 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6901 | val_auc: 0.7371 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 51
[TRAIN] Train model
Epoch [51 / 200] Step: [100 / 1130] avg_train_loss: 0.3097 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [200 / 1130] avg_train_loss: 0.3407 | train_auc: 0.965 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [300 / 1130] avg_train_loss: 0.3223 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [400 / 1130] avg_train_loss: 0.3054 | train_auc: 0.974 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [500 / 1130] avg_train_loss: 0.3052 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [600 / 1130] avg_train_loss: 0.3069 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [700 / 1130] avg_train_loss: 0.302 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [800 / 1130] avg_train_loss: 0.2971 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [900 / 1130] avg_train_loss: 0.2951 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [1000 / 1130] avg_train_loss: 0.2994 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [51 / 200] Step: [1100 / 1130] avg_train_loss: 0.2944 | train_auc: 0.9754 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 51 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1631 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1586 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3975 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6424 | val_auc: 0.6893 | lr: 7.289999999999999e-09
[Epoch: 51 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7528 | val_auc: 0.7286 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 52
[TRAIN] Train model
Epoch [52 / 200] Step: [100 / 1130] avg_train_loss: 0.2738 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [200 / 1130] avg_train_loss: 0.2392 | train_auc: 0.9924 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [300 / 1130] avg_train_loss: 0.2366 | train_auc: 0.9911 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [400 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [500 / 1130] avg_train_loss: 0.2684 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [600 / 1130] avg_train_loss: 0.2581 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [700 / 1130] avg_train_loss: 0.255 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [800 / 1130] avg_train_loss: 0.2622 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [900 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [1000 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [52 / 200] Step: [1100 / 1130] avg_train_loss: 0.278 | train_auc: 0.9808 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 52 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.17 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1668 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4176 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6512 | val_auc: 0.6783 | lr: 7.289999999999999e-09
[Epoch: 52 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7251 | val_auc: 0.7384 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 53
[TRAIN] Train model
Epoch [53 / 200] Step: [100 / 1130] avg_train_loss: 0.205 | train_auc: 0.9953 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [200 / 1130] avg_train_loss: 0.2897 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [300 / 1130] avg_train_loss: 0.3191 | train_auc: 0.9695 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [400 / 1130] avg_train_loss: 0.3021 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [500 / 1130] avg_train_loss: 0.2971 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [600 / 1130] avg_train_loss: 0.3004 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [700 / 1130] avg_train_loss: 0.301 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [800 / 1130] avg_train_loss: 0.2877 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [900 / 1130] avg_train_loss: 0.2802 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [1000 / 1130] avg_train_loss: 0.2913 | train_auc: 0.973 | lr : 7.289999999999999e-09
Epoch [53 / 200] Step: [1100 / 1130] avg_train_loss: 0.2833 | train_auc: 0.975 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 53 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2426 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2374 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4683 | val_auc: 0.664 | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6507 | val_auc: 0.6706 | lr: 7.289999999999999e-09
[Epoch: 53 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6929 | val_auc: 0.7348 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 54
[TRAIN] Train model
Epoch [54 / 200] Step: [100 / 1130] avg_train_loss: 0.2658 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [200 / 1130] avg_train_loss: 0.3112 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [300 / 1130] avg_train_loss: 0.2837 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [400 / 1130] avg_train_loss: 0.2876 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [500 / 1130] avg_train_loss: 0.2772 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [600 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [700 / 1130] avg_train_loss: 0.2676 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [800 / 1130] avg_train_loss: 0.272 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [900 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [1000 / 1130] avg_train_loss: 0.2807 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [54 / 200] Step: [1100 / 1130] avg_train_loss: 0.2806 | train_auc: 0.9799 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 54 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1831 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1853 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4139 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6219 | val_auc: 0.6706 | lr: 7.289999999999999e-09
[Epoch: 54 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7197 | val_auc: 0.717 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 55
[TRAIN] Train model
Epoch [55 / 200] Step: [100 / 1130] avg_train_loss: 0.3052 | train_auc: 0.9581 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [200 / 1130] avg_train_loss: 0.3081 | train_auc: 0.9611 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [300 / 1130] avg_train_loss: 0.2961 | train_auc: 0.9677 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [400 / 1130] avg_train_loss: 0.2844 | train_auc: 0.9712 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [500 / 1130] avg_train_loss: 0.2716 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [600 / 1130] avg_train_loss: 0.2799 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [700 / 1130] avg_train_loss: 0.2806 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [800 / 1130] avg_train_loss: 0.2759 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [900 / 1130] avg_train_loss: 0.2798 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [1000 / 1130] avg_train_loss: 0.2822 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [55 / 200] Step: [1100 / 1130] avg_train_loss: 0.2904 | train_auc: 0.9754 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 55 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3011 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2715 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4824 | val_auc: 0.6164 | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6754 | val_auc: 0.6324 | lr: 7.289999999999999e-09
[Epoch: 55 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7237 | val_auc: 0.7019 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 56
[TRAIN] Train model
Epoch [56 / 200] Step: [100 / 1130] avg_train_loss: 0.3173 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [200 / 1130] avg_train_loss: 0.3109 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [300 / 1130] avg_train_loss: 0.2889 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [400 / 1130] avg_train_loss: 0.3092 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [500 / 1130] avg_train_loss: 0.3036 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [600 / 1130] avg_train_loss: 0.2915 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [700 / 1130] avg_train_loss: 0.3036 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [800 / 1130] avg_train_loss: 0.2969 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [900 / 1130] avg_train_loss: 0.2892 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [1000 / 1130] avg_train_loss: 0.2868 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [56 / 200] Step: [1100 / 1130] avg_train_loss: 0.2835 | train_auc: 0.9789 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 56 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1821 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1697 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3992 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6446 | val_auc: 0.691 | lr: 7.289999999999999e-09
[Epoch: 56 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7618 | val_auc: 0.7242 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 57
[TRAIN] Train model
Epoch [57 / 200] Step: [100 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [200 / 1130] avg_train_loss: 0.2475 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [300 / 1130] avg_train_loss: 0.24 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [400 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [500 / 1130] avg_train_loss: 0.2676 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [600 / 1130] avg_train_loss: 0.267 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [700 / 1130] avg_train_loss: 0.2627 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [800 / 1130] avg_train_loss: 0.2622 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [900 / 1130] avg_train_loss: 0.2592 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [1000 / 1130] avg_train_loss: 0.2746 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [57 / 200] Step: [1100 / 1130] avg_train_loss: 0.2773 | train_auc: 0.978 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 57 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1912 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.186 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.413 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6412 | val_auc: 0.6817 | lr: 7.289999999999999e-09
[Epoch: 57 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7401 | val_auc: 0.7246 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 58
[TRAIN] Train model
Epoch [58 / 200] Step: [100 / 1130] avg_train_loss: 0.1688 | train_auc: 0.998 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [200 / 1130] avg_train_loss: 0.202 | train_auc: 0.9953 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [300 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [400 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [500 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [600 / 1130] avg_train_loss: 0.2849 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [700 / 1130] avg_train_loss: 0.2972 | train_auc: 0.974 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [800 / 1130] avg_train_loss: 0.297 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [900 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [1000 / 1130] avg_train_loss: 0.2865 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [58 / 200] Step: [1100 / 1130] avg_train_loss: 0.287 | train_auc: 0.9767 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 58 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2211 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2172 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4286 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6312 | val_auc: 0.6638 | lr: 7.289999999999999e-09
[Epoch: 58 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6891 | val_auc: 0.7295 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 59
[TRAIN] Train model
Epoch [59 / 200] Step: [100 / 1130] avg_train_loss: 0.2405 | train_auc: 0.9907 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [200 / 1130] avg_train_loss: 0.2531 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [300 / 1130] avg_train_loss: 0.2744 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [400 / 1130] avg_train_loss: 0.278 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [500 / 1130] avg_train_loss: 0.2772 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [600 / 1130] avg_train_loss: 0.2663 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [700 / 1130] avg_train_loss: 0.2838 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [800 / 1130] avg_train_loss: 0.2849 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [900 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [1000 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [59 / 200] Step: [1100 / 1130] avg_train_loss: 0.2793 | train_auc: 0.98 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 59 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2011 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1916 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4369 | val_auc: 0.6481 | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6521 | val_auc: 0.6503 | lr: 7.289999999999999e-09
[Epoch: 59 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.716 | val_auc: 0.7166 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 60
[TRAIN] Train model
Epoch [60 / 200] Step: [100 / 1130] avg_train_loss: 0.3955 | train_auc: 0.9473 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [200 / 1130] avg_train_loss: 0.3661 | train_auc: 0.9564 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [300 / 1130] avg_train_loss: 0.3314 | train_auc: 0.9663 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [400 / 1130] avg_train_loss: 0.3456 | train_auc: 0.9588 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [500 / 1130] avg_train_loss: 0.3254 | train_auc: 0.9645 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [600 / 1130] avg_train_loss: 0.3319 | train_auc: 0.9622 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [700 / 1130] avg_train_loss: 0.3345 | train_auc: 0.9623 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [800 / 1130] avg_train_loss: 0.3384 | train_auc: 0.9609 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [900 / 1130] avg_train_loss: 0.3363 | train_auc: 0.962 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [1000 / 1130] avg_train_loss: 0.3354 | train_auc: 0.9614 | lr : 7.289999999999999e-09
Epoch [60 / 200] Step: [1100 / 1130] avg_train_loss: 0.3268 | train_auc: 0.9635 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 60 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2087 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1955 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4229 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6485 | val_auc: 0.6528 | lr: 7.289999999999999e-09
[Epoch: 60 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7488 | val_auc: 0.7068 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 61
[TRAIN] Train model
Epoch [61 / 200] Step: [100 / 1130] avg_train_loss: 0.2074 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [200 / 1130] avg_train_loss: 0.2948 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [300 / 1130] avg_train_loss: 0.2943 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [400 / 1130] avg_train_loss: 0.2877 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [500 / 1130] avg_train_loss: 0.2987 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [600 / 1130] avg_train_loss: 0.2948 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [700 / 1130] avg_train_loss: 0.301 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [800 / 1130] avg_train_loss: 0.3053 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [900 / 1130] avg_train_loss: 0.2976 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [1000 / 1130] avg_train_loss: 0.2969 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [61 / 200] Step: [1100 / 1130] avg_train_loss: 0.2985 | train_auc: 0.9745 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 61 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1868 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1845 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4266 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6556 | val_auc: 0.6562 | lr: 7.289999999999999e-09
[Epoch: 61 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7403 | val_auc: 0.7179 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 62
[TRAIN] Train model
Epoch [62 / 200] Step: [100 / 1130] avg_train_loss: 0.361 | train_auc: 0.9603 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [200 / 1130] avg_train_loss: 0.33 | train_auc: 0.9709 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [300 / 1130] avg_train_loss: 0.2913 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [400 / 1130] avg_train_loss: 0.2846 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [500 / 1130] avg_train_loss: 0.2881 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [600 / 1130] avg_train_loss: 0.2811 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [700 / 1130] avg_train_loss: 0.2708 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [800 / 1130] avg_train_loss: 0.2635 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [900 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [1000 / 1130] avg_train_loss: 0.2713 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [62 / 200] Step: [1100 / 1130] avg_train_loss: 0.278 | train_auc: 0.9782 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 62 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2467 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2287 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4239 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6314 | val_auc: 0.6698 | lr: 7.289999999999999e-09
[Epoch: 62 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7197 | val_auc: 0.7054 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 63
[TRAIN] Train model
Epoch [63 / 200] Step: [100 / 1130] avg_train_loss: 0.205 | train_auc: 0.9924 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [200 / 1130] avg_train_loss: 0.2497 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [300 / 1130] avg_train_loss: 0.2881 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [400 / 1130] avg_train_loss: 0.2978 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [500 / 1130] avg_train_loss: 0.2872 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [600 / 1130] avg_train_loss: 0.2696 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [700 / 1130] avg_train_loss: 0.2699 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [800 / 1130] avg_train_loss: 0.2746 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [900 / 1130] avg_train_loss: 0.2755 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [1000 / 1130] avg_train_loss: 0.2792 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [63 / 200] Step: [1100 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9772 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 63 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1808 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1788 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4222 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6404 | val_auc: 0.691 | lr: 7.289999999999999e-09
[Epoch: 63 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7267 | val_auc: 0.7357 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 64
[TRAIN] Train model
Epoch [64 / 200] Step: [100 / 1130] avg_train_loss: 0.2345 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [200 / 1130] avg_train_loss: 0.3089 | train_auc: 0.9678 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [300 / 1130] avg_train_loss: 0.2984 | train_auc: 0.974 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [400 / 1130] avg_train_loss: 0.2937 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [500 / 1130] avg_train_loss: 0.2783 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [600 / 1130] avg_train_loss: 0.2957 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [700 / 1130] avg_train_loss: 0.2946 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [800 / 1130] avg_train_loss: 0.292 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [900 / 1130] avg_train_loss: 0.2928 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [1000 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [64 / 200] Step: [1100 / 1130] avg_train_loss: 0.28 | train_auc: 0.9777 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 64 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2107 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1928 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.43 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6394 | val_auc: 0.6859 | lr: 7.289999999999999e-09
[Epoch: 64 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.719 | val_auc: 0.7331 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 65
[TRAIN] Train model
Epoch [65 / 200] Step: [100 / 1130] avg_train_loss: 0.2958 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [200 / 1130] avg_train_loss: 0.3288 | train_auc: 0.9697 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [300 / 1130] avg_train_loss: 0.3232 | train_auc: 0.9697 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [400 / 1130] avg_train_loss: 0.306 | train_auc: 0.9727 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [500 / 1130] avg_train_loss: 0.3271 | train_auc: 0.9662 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [600 / 1130] avg_train_loss: 0.3111 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [700 / 1130] avg_train_loss: 0.3087 | train_auc: 0.971 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [800 / 1130] avg_train_loss: 0.3201 | train_auc: 0.9685 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [900 / 1130] avg_train_loss: 0.3033 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [1000 / 1130] avg_train_loss: 0.2997 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [65 / 200] Step: [1100 / 1130] avg_train_loss: 0.2958 | train_auc: 0.9745 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 65 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1515 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1467 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4057 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.651 | val_auc: 0.6995 | lr: 7.289999999999999e-09
[Epoch: 65 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7537 | val_auc: 0.7567 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 66
[TRAIN] Train model
Epoch [66 / 200] Step: [100 / 1130] avg_train_loss: 0.2979 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [200 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [300 / 1130] avg_train_loss: 0.3136 | train_auc: 0.9713 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [400 / 1130] avg_train_loss: 0.3263 | train_auc: 0.968 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [500 / 1130] avg_train_loss: 0.3036 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [600 / 1130] avg_train_loss: 0.3047 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [700 / 1130] avg_train_loss: 0.3022 | train_auc: 0.9726 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [800 / 1130] avg_train_loss: 0.3085 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [900 / 1130] avg_train_loss: 0.3076 | train_auc: 0.9725 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [1000 / 1130] avg_train_loss: 0.3138 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [66 / 200] Step: [1100 / 1130] avg_train_loss: 0.3033 | train_auc: 0.9725 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 66 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2458 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2344 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4476 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6444 | val_auc: 0.6613 | lr: 7.289999999999999e-09
[Epoch: 66 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7127 | val_auc: 0.7188 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 67
[TRAIN] Train model
Epoch [67 / 200] Step: [100 / 1130] avg_train_loss: 0.3181 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [200 / 1130] avg_train_loss: 0.2918 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [300 / 1130] avg_train_loss: 0.296 | train_auc: 0.974 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [400 / 1130] avg_train_loss: 0.3002 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [500 / 1130] avg_train_loss: 0.3022 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [600 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [700 / 1130] avg_train_loss: 0.2783 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [800 / 1130] avg_train_loss: 0.2733 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [900 / 1130] avg_train_loss: 0.2812 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [1000 / 1130] avg_train_loss: 0.2746 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [67 / 200] Step: [1100 / 1130] avg_train_loss: 0.2684 | train_auc: 0.9796 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 67 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1465 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1497 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4105 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6443 | val_auc: 0.6885 | lr: 7.289999999999999e-09
[Epoch: 67 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7332 | val_auc: 0.7438 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 68
[TRAIN] Train model
Epoch [68 / 200] Step: [100 / 1130] avg_train_loss: 0.2526 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [200 / 1130] avg_train_loss: 0.2752 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [300 / 1130] avg_train_loss: 0.2727 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [400 / 1130] avg_train_loss: 0.2584 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [500 / 1130] avg_train_loss: 0.2749 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [600 / 1130] avg_train_loss: 0.2752 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [700 / 1130] avg_train_loss: 0.281 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [800 / 1130] avg_train_loss: 0.2868 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [900 / 1130] avg_train_loss: 0.2935 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [1000 / 1130] avg_train_loss: 0.2865 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [68 / 200] Step: [1100 / 1130] avg_train_loss: 0.296 | train_auc: 0.9738 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 68 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1827 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1831 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4259 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6408 | val_auc: 0.6766 | lr: 7.289999999999999e-09
[Epoch: 68 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6967 | val_auc: 0.7447 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 69
[TRAIN] Train model
Epoch [69 / 200] Step: [100 / 1130] avg_train_loss: 0.2236 | train_auc: 0.9939 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [200 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [300 / 1130] avg_train_loss: 0.292 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [400 / 1130] avg_train_loss: 0.2982 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [500 / 1130] avg_train_loss: 0.2782 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [600 / 1130] avg_train_loss: 0.2956 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [700 / 1130] avg_train_loss: 0.2873 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [800 / 1130] avg_train_loss: 0.308 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [900 / 1130] avg_train_loss: 0.2982 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [1000 / 1130] avg_train_loss: 0.299 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [69 / 200] Step: [1100 / 1130] avg_train_loss: 0.2955 | train_auc: 0.9772 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 69 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2274 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2162 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4338 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6391 | val_auc: 0.6715 | lr: 7.289999999999999e-09
[Epoch: 69 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.706 | val_auc: 0.7268 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 70
[TRAIN] Train model
Epoch [70 / 200] Step: [100 / 1130] avg_train_loss: 0.2431 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [200 / 1130] avg_train_loss: 0.2495 | train_auc: 0.9896 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [300 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [400 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [500 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [600 / 1130] avg_train_loss: 0.2787 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [700 / 1130] avg_train_loss: 0.2733 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [800 / 1130] avg_train_loss: 0.2849 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [900 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [1000 / 1130] avg_train_loss: 0.2805 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [70 / 200] Step: [1100 / 1130] avg_train_loss: 0.2909 | train_auc: 0.978 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 70 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1833 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1818 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4365 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.654 | val_auc: 0.6749 | lr: 7.289999999999999e-09
[Epoch: 70 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7109 | val_auc: 0.7362 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 71
[TRAIN] Train model
Epoch [71 / 200] Step: [100 / 1130] avg_train_loss: 0.2677 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [200 / 1130] avg_train_loss: 0.3038 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [300 / 1130] avg_train_loss: 0.2652 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [400 / 1130] avg_train_loss: 0.257 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [500 / 1130] avg_train_loss: 0.2767 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [600 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [700 / 1130] avg_train_loss: 0.2886 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [800 / 1130] avg_train_loss: 0.299 | train_auc: 0.9711 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [900 / 1130] avg_train_loss: 0.2967 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [1000 / 1130] avg_train_loss: 0.2987 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [71 / 200] Step: [1100 / 1130] avg_train_loss: 0.3045 | train_auc: 0.9711 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 71 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1988 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1834 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4254 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6639 | val_auc: 0.6562 | lr: 7.289999999999999e-09
[Epoch: 71 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7531 | val_auc: 0.7086 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 72
[TRAIN] Train model
Epoch [72 / 200] Step: [100 / 1130] avg_train_loss: 0.3261 | train_auc: 0.9665 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [200 / 1130] avg_train_loss: 0.3151 | train_auc: 0.9701 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [300 / 1130] avg_train_loss: 0.2918 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [400 / 1130] avg_train_loss: 0.2905 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [500 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [600 / 1130] avg_train_loss: 0.3039 | train_auc: 0.9711 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [700 / 1130] avg_train_loss: 0.2976 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [800 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9727 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [900 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [1000 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [72 / 200] Step: [1100 / 1130] avg_train_loss: 0.2834 | train_auc: 0.9756 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 72 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1689 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1604 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4066 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6433 | val_auc: 0.7012 | lr: 7.289999999999999e-09
[Epoch: 72 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.748 | val_auc: 0.7402 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 73
[TRAIN] Train model
Epoch [73 / 200] Step: [100 / 1130] avg_train_loss: 0.2292 | train_auc: 0.9915 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [200 / 1130] avg_train_loss: 0.2657 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [300 / 1130] avg_train_loss: 0.2401 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [400 / 1130] avg_train_loss: 0.2579 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [500 / 1130] avg_train_loss: 0.2672 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [600 / 1130] avg_train_loss: 0.2559 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [700 / 1130] avg_train_loss: 0.2509 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [800 / 1130] avg_train_loss: 0.2655 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [900 / 1130] avg_train_loss: 0.2757 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [1000 / 1130] avg_train_loss: 0.269 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [73 / 200] Step: [1100 / 1130] avg_train_loss: 0.2691 | train_auc: 0.9795 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 73 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1552 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1511 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4091 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6761 | val_auc: 0.6469 | lr: 7.289999999999999e-09
[Epoch: 73 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7711 | val_auc: 0.7072 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 74
[TRAIN] Train model
Epoch [74 / 200] Step: [100 / 1130] avg_train_loss: 0.2772 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [200 / 1130] avg_train_loss: 0.2301 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [300 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [400 / 1130] avg_train_loss: 0.2791 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [500 / 1130] avg_train_loss: 0.2857 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [600 / 1130] avg_train_loss: 0.3002 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [700 / 1130] avg_train_loss: 0.3068 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [800 / 1130] avg_train_loss: 0.296 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [900 / 1130] avg_train_loss: 0.2876 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [1000 / 1130] avg_train_loss: 0.2881 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [74 / 200] Step: [1100 / 1130] avg_train_loss: 0.285 | train_auc: 0.9786 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 74 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1245 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1292 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3883 | val_auc: 0.7222 | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6444 | val_auc: 0.6834 | lr: 7.289999999999999e-09
[Epoch: 74 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7663 | val_auc: 0.7389 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 75
[TRAIN] Train model
Epoch [75 / 200] Step: [100 / 1130] avg_train_loss: 0.3167 | train_auc: 0.9666 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [200 / 1130] avg_train_loss: 0.2907 | train_auc: 0.9705 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [300 / 1130] avg_train_loss: 0.2579 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [400 / 1130] avg_train_loss: 0.2434 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [500 / 1130] avg_train_loss: 0.2484 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [600 / 1130] avg_train_loss: 0.2645 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [700 / 1130] avg_train_loss: 0.2743 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [800 / 1130] avg_train_loss: 0.2884 | train_auc: 0.9715 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [900 / 1130] avg_train_loss: 0.2949 | train_auc: 0.969 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [1000 / 1130] avg_train_loss: 0.2908 | train_auc: 0.9706 | lr : 7.289999999999999e-09
Epoch [75 / 200] Step: [1100 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9724 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 75 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1604 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1605 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4247 | val_auc: 0.6481 | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.679 | val_auc: 0.6401 | lr: 7.289999999999999e-09
[Epoch: 75 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.782 | val_auc: 0.697 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 76
[TRAIN] Train model
Epoch [76 / 200] Step: [100 / 1130] avg_train_loss: 0.3484 | train_auc: 0.9593 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [200 / 1130] avg_train_loss: 0.3209 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [300 / 1130] avg_train_loss: 0.3382 | train_auc: 0.9635 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [400 / 1130] avg_train_loss: 0.3267 | train_auc: 0.9674 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [500 / 1130] avg_train_loss: 0.3275 | train_auc: 0.9655 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [600 / 1130] avg_train_loss: 0.3327 | train_auc: 0.9656 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [700 / 1130] avg_train_loss: 0.3163 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [800 / 1130] avg_train_loss: 0.3179 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [900 / 1130] avg_train_loss: 0.3057 | train_auc: 0.973 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [1000 / 1130] avg_train_loss: 0.3007 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [76 / 200] Step: [1100 / 1130] avg_train_loss: 0.2993 | train_auc: 0.9745 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 76 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2066 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2022 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.427 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6418 | val_auc: 0.6664 | lr: 7.289999999999999e-09
[Epoch: 76 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7041 | val_auc: 0.7299 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 77
[TRAIN] Train model
Epoch [77 / 200] Step: [100 / 1130] avg_train_loss: 0.2963 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [200 / 1130] avg_train_loss: 0.2879 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [300 / 1130] avg_train_loss: 0.3075 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [400 / 1130] avg_train_loss: 0.2836 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [500 / 1130] avg_train_loss: 0.2753 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [600 / 1130] avg_train_loss: 0.265 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [700 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [800 / 1130] avg_train_loss: 0.2767 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [900 / 1130] avg_train_loss: 0.2803 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [1000 / 1130] avg_train_loss: 0.2738 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [77 / 200] Step: [1100 / 1130] avg_train_loss: 0.2782 | train_auc: 0.979 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 77 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1096 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1105 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3933 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6802 | val_auc: 0.7071 | lr: 7.289999999999999e-09
[Epoch: 77 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8197 | val_auc: 0.7487 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 78
[TRAIN] Train model
Epoch [78 / 200] Step: [100 / 1130] avg_train_loss: 0.243 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [200 / 1130] avg_train_loss: 0.2604 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [300 / 1130] avg_train_loss: 0.2706 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [400 / 1130] avg_train_loss: 0.2734 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [500 / 1130] avg_train_loss: 0.2589 | train_auc: 0.9831 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [600 / 1130] avg_train_loss: 0.2642 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [700 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [800 / 1130] avg_train_loss: 0.2636 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [900 / 1130] avg_train_loss: 0.2551 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [1000 / 1130] avg_train_loss: 0.2522 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [78 / 200] Step: [1100 / 1130] avg_train_loss: 0.2516 | train_auc: 0.9849 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 78 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2024 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1937 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4216 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6471 | val_auc: 0.6613 | lr: 7.289999999999999e-09
[Epoch: 78 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7261 | val_auc: 0.7175 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 79
[TRAIN] Train model
Epoch [79 / 200] Step: [100 / 1130] avg_train_loss: 0.252 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [200 / 1130] avg_train_loss: 0.2579 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [300 / 1130] avg_train_loss: 0.2616 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [400 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [500 / 1130] avg_train_loss: 0.2785 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [600 / 1130] avg_train_loss: 0.274 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [700 / 1130] avg_train_loss: 0.2599 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [800 / 1130] avg_train_loss: 0.2604 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [900 / 1130] avg_train_loss: 0.2679 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [1000 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [79 / 200] Step: [1100 / 1130] avg_train_loss: 0.2681 | train_auc: 0.9811 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 79 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1673 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1561 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4013 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6443 | val_auc: 0.6842 | lr: 7.289999999999999e-09
[Epoch: 79 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7439 | val_auc: 0.7384 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 80
[TRAIN] Train model
Epoch [80 / 200] Step: [100 / 1130] avg_train_loss: 0.2972 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [200 / 1130] avg_train_loss: 0.2833 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [300 / 1130] avg_train_loss: 0.3121 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [400 / 1130] avg_train_loss: 0.3051 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [500 / 1130] avg_train_loss: 0.3211 | train_auc: 0.9675 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [600 / 1130] avg_train_loss: 0.3295 | train_auc: 0.9649 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [700 / 1130] avg_train_loss: 0.316 | train_auc: 0.9681 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [800 / 1130] avg_train_loss: 0.3151 | train_auc: 0.9688 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [900 / 1130] avg_train_loss: 0.3109 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [1000 / 1130] avg_train_loss: 0.3112 | train_auc: 0.9693 | lr : 7.289999999999999e-09
Epoch [80 / 200] Step: [1100 / 1130] avg_train_loss: 0.3061 | train_auc: 0.9711 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 80 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1345 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1358 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4009 | val_auc: 0.7487 | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6474 | val_auc: 0.7207 | lr: 7.289999999999999e-09
[Epoch: 80 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7595 | val_auc: 0.7549 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 81
[TRAIN] Train model
Epoch [81 / 200] Step: [100 / 1130] avg_train_loss: 0.2671 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [200 / 1130] avg_train_loss: 0.238 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [300 / 1130] avg_train_loss: 0.3409 | train_auc: 0.968 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [400 / 1130] avg_train_loss: 0.3233 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [500 / 1130] avg_train_loss: 0.3232 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [600 / 1130] avg_train_loss: 0.3223 | train_auc: 0.9702 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [700 / 1130] avg_train_loss: 0.3111 | train_auc: 0.9727 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [800 / 1130] avg_train_loss: 0.2982 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [900 / 1130] avg_train_loss: 0.292 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [1000 / 1130] avg_train_loss: 0.2869 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [81 / 200] Step: [1100 / 1130] avg_train_loss: 0.2821 | train_auc: 0.9789 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 81 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2339 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.22 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4372 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.639 | val_auc: 0.6604 | lr: 7.289999999999999e-09
[Epoch: 81 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6945 | val_auc: 0.7295 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 82
[TRAIN] Train model
Epoch [82 / 200] Step: [100 / 1130] avg_train_loss: 0.2424 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [200 / 1130] avg_train_loss: 0.313 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [300 / 1130] avg_train_loss: 0.3323 | train_auc: 0.9701 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [400 / 1130] avg_train_loss: 0.3124 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [500 / 1130] avg_train_loss: 0.3028 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [600 / 1130] avg_train_loss: 0.2914 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [700 / 1130] avg_train_loss: 0.2818 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [800 / 1130] avg_train_loss: 0.2742 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [900 / 1130] avg_train_loss: 0.2688 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [1000 / 1130] avg_train_loss: 0.2693 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [82 / 200] Step: [1100 / 1130] avg_train_loss: 0.2654 | train_auc: 0.9828 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 82 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2643 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2636 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4857 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6652 | val_auc: 0.6672 | lr: 7.289999999999999e-09
[Epoch: 82 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6963 | val_auc: 0.7295 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 83
[TRAIN] Train model
Epoch [83 / 200] Step: [100 / 1130] avg_train_loss: 0.2639 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [200 / 1130] avg_train_loss: 0.2588 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [300 / 1130] avg_train_loss: 0.2811 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [400 / 1130] avg_train_loss: 0.2988 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [500 / 1130] avg_train_loss: 0.2864 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [600 / 1130] avg_train_loss: 0.3025 | train_auc: 0.974 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [700 / 1130] avg_train_loss: 0.3006 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [800 / 1130] avg_train_loss: 0.304 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [900 / 1130] avg_train_loss: 0.2991 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [1000 / 1130] avg_train_loss: 0.2939 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [83 / 200] Step: [1100 / 1130] avg_train_loss: 0.2951 | train_auc: 0.9761 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 83 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1501 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.152 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4122 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6527 | val_auc: 0.702 | lr: 7.289999999999999e-09
[Epoch: 83 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7416 | val_auc: 0.7469 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 84
[TRAIN] Train model
Epoch [84 / 200] Step: [100 / 1130] avg_train_loss: 0.251 | train_auc: 0.9928 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [200 / 1130] avg_train_loss: 0.27 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [300 / 1130] avg_train_loss: 0.2546 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [400 / 1130] avg_train_loss: 0.2575 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [500 / 1130] avg_train_loss: 0.2603 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [600 / 1130] avg_train_loss: 0.2717 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [700 / 1130] avg_train_loss: 0.2751 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [800 / 1130] avg_train_loss: 0.2745 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [900 / 1130] avg_train_loss: 0.2737 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [1000 / 1130] avg_train_loss: 0.2797 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [84 / 200] Step: [1100 / 1130] avg_train_loss: 0.2825 | train_auc: 0.9765 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 84 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3095 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2928 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4924 | val_auc: 0.6164 | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6775 | val_auc: 0.6205 | lr: 7.289999999999999e-09
[Epoch: 84 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7324 | val_auc: 0.684 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 85
[TRAIN] Train model
Epoch [85 / 200] Step: [100 / 1130] avg_train_loss: 0.3203 | train_auc: 0.9672 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [200 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [300 / 1130] avg_train_loss: 0.2754 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [400 / 1130] avg_train_loss: 0.3073 | train_auc: 0.971 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [500 / 1130] avg_train_loss: 0.3019 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [600 / 1130] avg_train_loss: 0.2948 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [700 / 1130] avg_train_loss: 0.2952 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [800 / 1130] avg_train_loss: 0.2939 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [900 / 1130] avg_train_loss: 0.2981 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [1000 / 1130] avg_train_loss: 0.2938 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [85 / 200] Step: [1100 / 1130] avg_train_loss: 0.2855 | train_auc: 0.9767 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 85 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1408 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1439 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3937 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6564 | val_auc: 0.6834 | lr: 7.289999999999999e-09
[Epoch: 85 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7665 | val_auc: 0.7331 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 86
[TRAIN] Train model
Epoch [86 / 200] Step: [100 / 1130] avg_train_loss: 0.3727 | train_auc: 0.9563 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [200 / 1130] avg_train_loss: 0.3165 | train_auc: 0.9717 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [300 / 1130] avg_train_loss: 0.3031 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [400 / 1130] avg_train_loss: 0.2946 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [500 / 1130] avg_train_loss: 0.2925 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [600 / 1130] avg_train_loss: 0.3046 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [700 / 1130] avg_train_loss: 0.3068 | train_auc: 0.9712 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [800 / 1130] avg_train_loss: 0.3029 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [900 / 1130] avg_train_loss: 0.2977 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [1000 / 1130] avg_train_loss: 0.2973 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [86 / 200] Step: [1100 / 1130] avg_train_loss: 0.3073 | train_auc: 0.9703 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 86 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2174 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2101 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4333 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6423 | val_auc: 0.6689 | lr: 7.289999999999999e-09
[Epoch: 86 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7274 | val_auc: 0.7233 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 87
[TRAIN] Train model
Epoch [87 / 200] Step: [100 / 1130] avg_train_loss: 0.2325 | train_auc: 0.9918 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [200 / 1130] avg_train_loss: 0.2842 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [300 / 1130] avg_train_loss: 0.2621 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [400 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [500 / 1130] avg_train_loss: 0.26 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [600 / 1130] avg_train_loss: 0.2513 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [700 / 1130] avg_train_loss: 0.2566 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [800 / 1130] avg_train_loss: 0.2541 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [900 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [1000 / 1130] avg_train_loss: 0.2686 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [87 / 200] Step: [1100 / 1130] avg_train_loss: 0.2674 | train_auc: 0.98 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 87 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2098 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1935 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4225 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6373 | val_auc: 0.6842 | lr: 7.289999999999999e-09
[Epoch: 87 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7134 | val_auc: 0.7344 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 88
[TRAIN] Train model
Epoch [88 / 200] Step: [100 / 1130] avg_train_loss: 0.393 | train_auc: 0.9432 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [200 / 1130] avg_train_loss: 0.3188 | train_auc: 0.9653 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [300 / 1130] avg_train_loss: 0.2857 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [400 / 1130] avg_train_loss: 0.266 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [500 / 1130] avg_train_loss: 0.2686 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [600 / 1130] avg_train_loss: 0.2787 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [700 / 1130] avg_train_loss: 0.2723 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [800 / 1130] avg_train_loss: 0.2871 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [900 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [1000 / 1130] avg_train_loss: 0.2865 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [88 / 200] Step: [1100 / 1130] avg_train_loss: 0.2878 | train_auc: 0.9762 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 88 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.204 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2001 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4313 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6445 | val_auc: 0.6553 | lr: 7.289999999999999e-09
[Epoch: 88 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7168 | val_auc: 0.7188 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 89
[TRAIN] Train model
Epoch [89 / 200] Step: [100 / 1130] avg_train_loss: 0.3657 | train_auc: 0.9549 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [200 / 1130] avg_train_loss: 0.3132 | train_auc: 0.9674 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [300 / 1130] avg_train_loss: 0.3144 | train_auc: 0.966 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [400 / 1130] avg_train_loss: 0.3049 | train_auc: 0.9693 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [500 / 1130] avg_train_loss: 0.2984 | train_auc: 0.971 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [600 / 1130] avg_train_loss: 0.3119 | train_auc: 0.9682 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [700 / 1130] avg_train_loss: 0.3015 | train_auc: 0.9709 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [800 / 1130] avg_train_loss: 0.2969 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [900 / 1130] avg_train_loss: 0.3012 | train_auc: 0.9713 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [1000 / 1130] avg_train_loss: 0.3051 | train_auc: 0.9709 | lr : 7.289999999999999e-09
Epoch [89 / 200] Step: [1100 / 1130] avg_train_loss: 0.2982 | train_auc: 0.9728 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 89 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2266 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.221 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4268 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6272 | val_auc: 0.6723 | lr: 7.289999999999999e-09
[Epoch: 89 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6801 | val_auc: 0.7411 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 90
[TRAIN] Train model
Epoch [90 / 200] Step: [100 / 1130] avg_train_loss: 0.2431 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [200 / 1130] avg_train_loss: 0.2395 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [300 / 1130] avg_train_loss: 0.2431 | train_auc: 0.9884 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [400 / 1130] avg_train_loss: 0.2721 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [500 / 1130] avg_train_loss: 0.2835 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [600 / 1130] avg_train_loss: 0.2777 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [700 / 1130] avg_train_loss: 0.2759 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [800 / 1130] avg_train_loss: 0.2832 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [900 / 1130] avg_train_loss: 0.2814 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [1000 / 1130] avg_train_loss: 0.2815 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [90 / 200] Step: [1100 / 1130] avg_train_loss: 0.2822 | train_auc: 0.9777 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 90 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2075 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2008 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4217 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6354 | val_auc: 0.6842 | lr: 7.289999999999999e-09
[Epoch: 90 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7145 | val_auc: 0.7366 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 91
[TRAIN] Train model
Epoch [91 / 200] Step: [100 / 1130] avg_train_loss: 0.227 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [200 / 1130] avg_train_loss: 0.2418 | train_auc: 0.9882 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [300 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [400 / 1130] avg_train_loss: 0.267 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [500 / 1130] avg_train_loss: 0.2829 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [600 / 1130] avg_train_loss: 0.296 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [700 / 1130] avg_train_loss: 0.2941 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [800 / 1130] avg_train_loss: 0.2918 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [900 / 1130] avg_train_loss: 0.2849 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [1000 / 1130] avg_train_loss: 0.2837 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [91 / 200] Step: [1100 / 1130] avg_train_loss: 0.2841 | train_auc: 0.9783 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 91 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1442 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.142 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4022 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6666 | val_auc: 0.6808 | lr: 7.289999999999999e-09
[Epoch: 91 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7682 | val_auc: 0.7353 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 92
[TRAIN] Train model
Epoch [92 / 200] Step: [100 / 1130] avg_train_loss: 0.3412 | train_auc: 0.9574 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [200 / 1130] avg_train_loss: 0.2771 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [300 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [400 / 1130] avg_train_loss: 0.2635 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [500 / 1130] avg_train_loss: 0.2662 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [600 / 1130] avg_train_loss: 0.277 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [700 / 1130] avg_train_loss: 0.2761 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [800 / 1130] avg_train_loss: 0.2731 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [900 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [1000 / 1130] avg_train_loss: 0.2778 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [92 / 200] Step: [1100 / 1130] avg_train_loss: 0.2795 | train_auc: 0.9784 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 92 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1687 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1684 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4193 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6295 | val_auc: 0.6952 | lr: 7.289999999999999e-09
[Epoch: 92 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.709 | val_auc: 0.7496 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 93
[TRAIN] Train model
Epoch [93 / 200] Step: [100 / 1130] avg_train_loss: 0.3251 | train_auc: 0.9657 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [200 / 1130] avg_train_loss: 0.3032 | train_auc: 0.9713 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [300 / 1130] avg_train_loss: 0.2985 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [400 / 1130] avg_train_loss: 0.2862 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [500 / 1130] avg_train_loss: 0.2986 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [600 / 1130] avg_train_loss: 0.2875 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [700 / 1130] avg_train_loss: 0.2825 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [800 / 1130] avg_train_loss: 0.283 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [900 / 1130] avg_train_loss: 0.2861 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [1000 / 1130] avg_train_loss: 0.2823 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [93 / 200] Step: [1100 / 1130] avg_train_loss: 0.2872 | train_auc: 0.9773 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 93 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2135 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2018 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4216 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6538 | val_auc: 0.6469 | lr: 7.289999999999999e-09
[Epoch: 93 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7554 | val_auc: 0.6988 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 94
[TRAIN] Train model
Epoch [94 / 200] Step: [100 / 1130] avg_train_loss: 0.2949 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [200 / 1130] avg_train_loss: 0.3054 | train_auc: 0.9671 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [300 / 1130] avg_train_loss: 0.2968 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [400 / 1130] avg_train_loss: 0.2837 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [500 / 1130] avg_train_loss: 0.27 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [600 / 1130] avg_train_loss: 0.2886 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [700 / 1130] avg_train_loss: 0.2856 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [800 / 1130] avg_train_loss: 0.2992 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [900 / 1130] avg_train_loss: 0.2997 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [1000 / 1130] avg_train_loss: 0.3 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [94 / 200] Step: [1100 / 1130] avg_train_loss: 0.313 | train_auc: 0.9686 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 94 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1947 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1775 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4332 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6741 | val_auc: 0.6511 | lr: 7.289999999999999e-09
[Epoch: 94 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7646 | val_auc: 0.7086 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 95
[TRAIN] Train model
Epoch [95 / 200] Step: [100 / 1130] avg_train_loss: 0.2467 | train_auc: 0.9718 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [200 / 1130] avg_train_loss: 0.2546 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [300 / 1130] avg_train_loss: 0.293 | train_auc: 0.9705 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [400 / 1130] avg_train_loss: 0.3015 | train_auc: 0.9694 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [500 / 1130] avg_train_loss: 0.3092 | train_auc: 0.9697 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [600 / 1130] avg_train_loss: 0.3041 | train_auc: 0.9715 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [700 / 1130] avg_train_loss: 0.3122 | train_auc: 0.9695 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [800 / 1130] avg_train_loss: 0.302 | train_auc: 0.973 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [900 / 1130] avg_train_loss: 0.3056 | train_auc: 0.9718 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [1000 / 1130] avg_train_loss: 0.3101 | train_auc: 0.9705 | lr : 7.289999999999999e-09
Epoch [95 / 200] Step: [1100 / 1130] avg_train_loss: 0.3096 | train_auc: 0.9705 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 95 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1461 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.142 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4124 | val_auc: 0.7487 | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6476 | val_auc: 0.7292 | lr: 7.289999999999999e-09
[Epoch: 95 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7547 | val_auc: 0.7643 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 96
[TRAIN] Train model
Epoch [96 / 200] Step: [100 / 1130] avg_train_loss: 0.2327 | train_auc: 0.9887 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [200 / 1130] avg_train_loss: 0.2664 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [300 / 1130] avg_train_loss: 0.2523 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [400 / 1130] avg_train_loss: 0.2616 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [500 / 1130] avg_train_loss: 0.2484 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [600 / 1130] avg_train_loss: 0.2535 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [700 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9861 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [800 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [900 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [1000 / 1130] avg_train_loss: 0.2646 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [96 / 200] Step: [1100 / 1130] avg_train_loss: 0.2614 | train_auc: 0.9842 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 96 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1479 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.143 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4126 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6653 | val_auc: 0.6952 | lr: 7.289999999999999e-09
[Epoch: 96 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7788 | val_auc: 0.7313 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 97
[TRAIN] Train model
Epoch [97 / 200] Step: [100 / 1130] avg_train_loss: 0.2684 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [200 / 1130] avg_train_loss: 0.2447 | train_auc: 0.9879 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [300 / 1130] avg_train_loss: 0.2468 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [400 / 1130] avg_train_loss: 0.2504 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [500 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [600 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [700 / 1130] avg_train_loss: 0.2482 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [800 / 1130] avg_train_loss: 0.2553 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [900 / 1130] avg_train_loss: 0.2622 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [1000 / 1130] avg_train_loss: 0.2679 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [97 / 200] Step: [1100 / 1130] avg_train_loss: 0.2671 | train_auc: 0.9826 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 97 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1337 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1306 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3974 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6656 | val_auc: 0.6935 | lr: 7.289999999999999e-09
[Epoch: 97 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7869 | val_auc: 0.7402 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 98
[TRAIN] Train model
Epoch [98 / 200] Step: [100 / 1130] avg_train_loss: 0.3788 | train_auc: 0.9552 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [200 / 1130] avg_train_loss: 0.3013 | train_auc: 0.9674 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [300 / 1130] avg_train_loss: 0.2796 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [400 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [500 / 1130] avg_train_loss: 0.2824 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [600 / 1130] avg_train_loss: 0.2853 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [700 / 1130] avg_train_loss: 0.2824 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [800 / 1130] avg_train_loss: 0.283 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [900 / 1130] avg_train_loss: 0.2797 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [1000 / 1130] avg_train_loss: 0.28 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [98 / 200] Step: [1100 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9769 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 98 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2097 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2003 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4407 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6609 | val_auc: 0.6596 | lr: 7.289999999999999e-09
[Epoch: 98 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7208 | val_auc: 0.7228 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 99
[TRAIN] Train model
Epoch [99 / 200] Step: [100 / 1130] avg_train_loss: 0.2736 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [200 / 1130] avg_train_loss: 0.2405 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [300 / 1130] avg_train_loss: 0.274 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [400 / 1130] avg_train_loss: 0.3018 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [500 / 1130] avg_train_loss: 0.2825 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [600 / 1130] avg_train_loss: 0.2822 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [700 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [800 / 1130] avg_train_loss: 0.2919 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [900 / 1130] avg_train_loss: 0.2924 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [1000 / 1130] avg_train_loss: 0.292 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [99 / 200] Step: [1100 / 1130] avg_train_loss: 0.283 | train_auc: 0.9778 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 99 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.146 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.143 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4101 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6739 | val_auc: 0.6579 | lr: 7.289999999999999e-09
[Epoch: 99 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7794 | val_auc: 0.7121 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 100
[TRAIN] Train model
Epoch [100 / 200] Step: [100 / 1130] avg_train_loss: 0.3283 | train_auc: 0.9616 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [200 / 1130] avg_train_loss: 0.3065 | train_auc: 0.9682 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [300 / 1130] avg_train_loss: 0.2886 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [400 / 1130] avg_train_loss: 0.2897 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [500 / 1130] avg_train_loss: 0.2765 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [600 / 1130] avg_train_loss: 0.2668 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [700 / 1130] avg_train_loss: 0.2678 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [800 / 1130] avg_train_loss: 0.2618 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [900 / 1130] avg_train_loss: 0.2714 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [1000 / 1130] avg_train_loss: 0.2768 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [100 / 200] Step: [1100 / 1130] avg_train_loss: 0.2806 | train_auc: 0.978 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 100 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1279 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1187 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4178 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6886 | val_auc: 0.6978 | lr: 7.289999999999999e-09
[Epoch: 100 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.822 | val_auc: 0.7308 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 101
[TRAIN] Train model
Epoch [101 / 200] Step: [100 / 1130] avg_train_loss: 0.3024 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [200 / 1130] avg_train_loss: 0.3029 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [300 / 1130] avg_train_loss: 0.2734 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [400 / 1130] avg_train_loss: 0.2814 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [500 / 1130] avg_train_loss: 0.2741 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [600 / 1130] avg_train_loss: 0.279 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [700 / 1130] avg_train_loss: 0.2956 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [800 / 1130] avg_train_loss: 0.2935 | train_auc: 0.9727 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [900 / 1130] avg_train_loss: 0.2841 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [1000 / 1130] avg_train_loss: 0.287 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [101 / 200] Step: [1100 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9749 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 101 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2192 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2258 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.448 | val_auc: 0.6931 | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6514 | val_auc: 0.6664 | lr: 7.289999999999999e-09
[Epoch: 101 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6994 | val_auc: 0.7295 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 102
[TRAIN] Train model
Epoch [102 / 200] Step: [100 / 1130] avg_train_loss: 0.2101 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [200 / 1130] avg_train_loss: 0.2879 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [300 / 1130] avg_train_loss: 0.3162 | train_auc: 0.9669 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [400 / 1130] avg_train_loss: 0.2962 | train_auc: 0.9724 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [500 / 1130] avg_train_loss: 0.2898 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [600 / 1130] avg_train_loss: 0.2791 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [700 / 1130] avg_train_loss: 0.275 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [800 / 1130] avg_train_loss: 0.2867 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [900 / 1130] avg_train_loss: 0.2838 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [1000 / 1130] avg_train_loss: 0.2843 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [102 / 200] Step: [1100 / 1130] avg_train_loss: 0.2829 | train_auc: 0.9775 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 102 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1423 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1454 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.399 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6389 | val_auc: 0.7122 | lr: 7.289999999999999e-09
[Epoch: 102 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7257 | val_auc: 0.7598 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 103
[TRAIN] Train model
Epoch [103 / 200] Step: [100 / 1130] avg_train_loss: 0.295 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [200 / 1130] avg_train_loss: 0.294 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [300 / 1130] avg_train_loss: 0.3131 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [400 / 1130] avg_train_loss: 0.2907 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [500 / 1130] avg_train_loss: 0.3064 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [600 / 1130] avg_train_loss: 0.3109 | train_auc: 0.9688 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [700 / 1130] avg_train_loss: 0.3123 | train_auc: 0.9689 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [800 / 1130] avg_train_loss: 0.3023 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [900 / 1130] avg_train_loss: 0.2991 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [1000 / 1130] avg_train_loss: 0.3022 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [103 / 200] Step: [1100 / 1130] avg_train_loss: 0.3023 | train_auc: 0.972 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 103 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.206 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2043 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.429 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6312 | val_auc: 0.6817 | lr: 7.289999999999999e-09
[Epoch: 103 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6868 | val_auc: 0.7398 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 104
[TRAIN] Train model
Epoch [104 / 200] Step: [100 / 1130] avg_train_loss: 0.3307 | train_auc: 0.9472 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [200 / 1130] avg_train_loss: 0.3271 | train_auc: 0.965 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [300 / 1130] avg_train_loss: 0.2849 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [400 / 1130] avg_train_loss: 0.2703 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [500 / 1130] avg_train_loss: 0.2658 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [600 / 1130] avg_train_loss: 0.258 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [700 / 1130] avg_train_loss: 0.2704 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [800 / 1130] avg_train_loss: 0.2683 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [900 / 1130] avg_train_loss: 0.2685 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [1000 / 1130] avg_train_loss: 0.2732 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [104 / 200] Step: [1100 / 1130] avg_train_loss: 0.2772 | train_auc: 0.9802 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 104 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1868 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.18 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4108 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6306 | val_auc: 0.6647 | lr: 7.289999999999999e-09
[Epoch: 104 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7254 | val_auc: 0.7188 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 105
[TRAIN] Train model
Epoch [105 / 200] Step: [100 / 1130] avg_train_loss: 0.2795 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [200 / 1130] avg_train_loss: 0.2456 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [300 / 1130] avg_train_loss: 0.2585 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [400 / 1130] avg_train_loss: 0.2767 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [500 / 1130] avg_train_loss: 0.2846 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [600 / 1130] avg_train_loss: 0.2926 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [700 / 1130] avg_train_loss: 0.2964 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [800 / 1130] avg_train_loss: 0.2882 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [900 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [1000 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [105 / 200] Step: [1100 / 1130] avg_train_loss: 0.2896 | train_auc: 0.9764 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 105 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1465 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1546 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.396 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6489 | val_auc: 0.6876 | lr: 7.289999999999999e-09
[Epoch: 105 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7426 | val_auc: 0.7429 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 106
[TRAIN] Train model
Epoch [106 / 200] Step: [100 / 1130] avg_train_loss: 0.2771 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [200 / 1130] avg_train_loss: 0.2605 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [300 / 1130] avg_train_loss: 0.262 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [400 / 1130] avg_train_loss: 0.2544 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [500 / 1130] avg_train_loss: 0.2645 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [600 / 1130] avg_train_loss: 0.271 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [700 / 1130] avg_train_loss: 0.2663 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [800 / 1130] avg_train_loss: 0.268 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [900 / 1130] avg_train_loss: 0.2639 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [1000 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [106 / 200] Step: [1100 / 1130] avg_train_loss: 0.2656 | train_auc: 0.982 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 106 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2378 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2139 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4682 | val_auc: 0.6243 | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6846 | val_auc: 0.635 | lr: 7.289999999999999e-09
[Epoch: 106 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7483 | val_auc: 0.7063 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 107
[TRAIN] Train model
Epoch [107 / 200] Step: [100 / 1130] avg_train_loss: 0.247 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [200 / 1130] avg_train_loss: 0.2909 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [300 / 1130] avg_train_loss: 0.2633 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [400 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [500 / 1130] avg_train_loss: 0.2566 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [600 / 1130] avg_train_loss: 0.2511 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [700 / 1130] avg_train_loss: 0.2663 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [800 / 1130] avg_train_loss: 0.2677 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [900 / 1130] avg_train_loss: 0.2716 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [1000 / 1130] avg_train_loss: 0.2707 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [107 / 200] Step: [1100 / 1130] avg_train_loss: 0.2797 | train_auc: 0.9768 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 107 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1575 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1509 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4178 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6635 | val_auc: 0.6902 | lr: 7.289999999999999e-09
[Epoch: 107 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7569 | val_auc: 0.7451 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 108
[TRAIN] Train model
Epoch [108 / 200] Step: [100 / 1130] avg_train_loss: 0.2861 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [200 / 1130] avg_train_loss: 0.3183 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [300 / 1130] avg_train_loss: 0.295 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [400 / 1130] avg_train_loss: 0.2993 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [500 / 1130] avg_train_loss: 0.2865 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [600 / 1130] avg_train_loss: 0.2725 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [700 / 1130] avg_train_loss: 0.2643 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [800 / 1130] avg_train_loss: 0.266 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [900 / 1130] avg_train_loss: 0.2705 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [1000 / 1130] avg_train_loss: 0.2697 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [108 / 200] Step: [1100 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9815 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 108 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1576 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1581 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4174 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6757 | val_auc: 0.6435 | lr: 7.289999999999999e-09
[Epoch: 108 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7903 | val_auc: 0.6992 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 109
[TRAIN] Train model
Epoch [109 / 200] Step: [100 / 1130] avg_train_loss: 0.3045 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [200 / 1130] avg_train_loss: 0.3029 | train_auc: 0.9711 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [300 / 1130] avg_train_loss: 0.3256 | train_auc: 0.965 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [400 / 1130] avg_train_loss: 0.312 | train_auc: 0.9666 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [500 / 1130] avg_train_loss: 0.2975 | train_auc: 0.9699 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [600 / 1130] avg_train_loss: 0.2887 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [700 / 1130] avg_train_loss: 0.3003 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [800 / 1130] avg_train_loss: 0.3063 | train_auc: 0.9706 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [900 / 1130] avg_train_loss: 0.3137 | train_auc: 0.9691 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [1000 / 1130] avg_train_loss: 0.3062 | train_auc: 0.9714 | lr : 7.289999999999999e-09
Epoch [109 / 200] Step: [1100 / 1130] avg_train_loss: 0.3005 | train_auc: 0.973 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 109 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2529 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2379 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4457 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6365 | val_auc: 0.6638 | lr: 7.289999999999999e-09
[Epoch: 109 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6963 | val_auc: 0.7206 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 110
[TRAIN] Train model
Epoch [110 / 200] Step: [100 / 1130] avg_train_loss: 0.4173 | train_auc: 0.9516 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [200 / 1130] avg_train_loss: 0.2982 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [300 / 1130] avg_train_loss: 0.3266 | train_auc: 0.9692 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [400 / 1130] avg_train_loss: 0.3287 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [500 / 1130] avg_train_loss: 0.3274 | train_auc: 0.9682 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [600 / 1130] avg_train_loss: 0.3229 | train_auc: 0.9687 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [700 / 1130] avg_train_loss: 0.3188 | train_auc: 0.969 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [800 / 1130] avg_train_loss: 0.319 | train_auc: 0.9689 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [900 / 1130] avg_train_loss: 0.3145 | train_auc: 0.9696 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [1000 / 1130] avg_train_loss: 0.3144 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [110 / 200] Step: [1100 / 1130] avg_train_loss: 0.3061 | train_auc: 0.972 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 110 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1354 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1382 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4018 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6522 | val_auc: 0.6995 | lr: 7.289999999999999e-09
[Epoch: 110 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7644 | val_auc: 0.7402 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 111
[TRAIN] Train model
Epoch [111 / 200] Step: [100 / 1130] avg_train_loss: 0.2704 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [200 / 1130] avg_train_loss: 0.2547 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [300 / 1130] avg_train_loss: 0.2766 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [400 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [500 / 1130] avg_train_loss: 0.2823 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [600 / 1130] avg_train_loss: 0.2737 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [700 / 1130] avg_train_loss: 0.2675 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [800 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [900 / 1130] avg_train_loss: 0.29 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [1000 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [111 / 200] Step: [1100 / 1130] avg_train_loss: 0.2883 | train_auc: 0.9758 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 111 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1929 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1797 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4283 | val_auc: 0.6667 | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6519 | val_auc: 0.6715 | lr: 7.289999999999999e-09
[Epoch: 111 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7088 | val_auc: 0.7451 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 112
[TRAIN] Train model
Epoch [112 / 200] Step: [100 / 1130] avg_train_loss: 0.2424 | train_auc: 0.9925 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [200 / 1130] avg_train_loss: 0.2674 | train_auc: 0.9853 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [300 / 1130] avg_train_loss: 0.2872 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [400 / 1130] avg_train_loss: 0.2933 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [500 / 1130] avg_train_loss: 0.3011 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [600 / 1130] avg_train_loss: 0.2834 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [700 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [800 / 1130] avg_train_loss: 0.2656 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [900 / 1130] avg_train_loss: 0.2618 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [1000 / 1130] avg_train_loss: 0.2636 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [112 / 200] Step: [1100 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9845 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 112 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2011 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1984 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4251 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6422 | val_auc: 0.6783 | lr: 7.289999999999999e-09
[Epoch: 112 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7279 | val_auc: 0.7166 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 113
[TRAIN] Train model
Epoch [113 / 200] Step: [100 / 1130] avg_train_loss: 0.2382 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [200 / 1130] avg_train_loss: 0.2476 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [300 / 1130] avg_train_loss: 0.266 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [400 / 1130] avg_train_loss: 0.2722 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [500 / 1130] avg_train_loss: 0.2724 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [600 / 1130] avg_train_loss: 0.2732 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [700 / 1130] avg_train_loss: 0.2841 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [800 / 1130] avg_train_loss: 0.2829 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [900 / 1130] avg_train_loss: 0.2858 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [1000 / 1130] avg_train_loss: 0.287 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [113 / 200] Step: [1100 / 1130] avg_train_loss: 0.2856 | train_auc: 0.9743 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 113 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.18 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1845 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4288 | val_auc: 0.6667 | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6502 | val_auc: 0.6613 | lr: 7.289999999999999e-09
[Epoch: 113 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7364 | val_auc: 0.7126 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 114
[TRAIN] Train model
Epoch [114 / 200] Step: [100 / 1130] avg_train_loss: 0.2919 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [200 / 1130] avg_train_loss: 0.289 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [300 / 1130] avg_train_loss: 0.2828 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [400 / 1130] avg_train_loss: 0.2951 | train_auc: 0.9712 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [500 / 1130] avg_train_loss: 0.2919 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [600 / 1130] avg_train_loss: 0.3002 | train_auc: 0.9699 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [700 / 1130] avg_train_loss: 0.2835 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [800 / 1130] avg_train_loss: 0.2845 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [900 / 1130] avg_train_loss: 0.2825 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [1000 / 1130] avg_train_loss: 0.2898 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [114 / 200] Step: [1100 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9724 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 114 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1801 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1693 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4198 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6469 | val_auc: 0.6766 | lr: 7.289999999999999e-09
[Epoch: 114 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7432 | val_auc: 0.7308 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 115
[TRAIN] Train model
Epoch [115 / 200] Step: [100 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [200 / 1130] avg_train_loss: 0.2643 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [300 / 1130] avg_train_loss: 0.2802 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [400 / 1130] avg_train_loss: 0.2738 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [500 / 1130] avg_train_loss: 0.2727 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [600 / 1130] avg_train_loss: 0.2616 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [700 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [800 / 1130] avg_train_loss: 0.2716 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [900 / 1130] avg_train_loss: 0.2712 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [1000 / 1130] avg_train_loss: 0.2771 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [115 / 200] Step: [1100 / 1130] avg_train_loss: 0.2719 | train_auc: 0.9795 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 115 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2125 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2183 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.442 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.653 | val_auc: 0.6553 | lr: 7.289999999999999e-09
[Epoch: 115 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7213 | val_auc: 0.7077 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 116
[TRAIN] Train model
Epoch [116 / 200] Step: [100 / 1130] avg_train_loss: 0.2547 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [200 / 1130] avg_train_loss: 0.2486 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [300 / 1130] avg_train_loss: 0.277 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [400 / 1130] avg_train_loss: 0.2842 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [500 / 1130] avg_train_loss: 0.2738 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [600 / 1130] avg_train_loss: 0.288 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [700 / 1130] avg_train_loss: 0.2803 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [800 / 1130] avg_train_loss: 0.2862 | train_auc: 0.9724 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [900 / 1130] avg_train_loss: 0.2942 | train_auc: 0.9709 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [1000 / 1130] avg_train_loss: 0.2949 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [116 / 200] Step: [1100 / 1130] avg_train_loss: 0.2885 | train_auc: 0.9725 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 116 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1505 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1629 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4535 | val_auc: 0.6217 | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6642 | val_auc: 0.6723 | lr: 7.289999999999999e-09
[Epoch: 116 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7461 | val_auc: 0.7242 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 117
[TRAIN] Train model
Epoch [117 / 200] Step: [100 / 1130] avg_train_loss: 0.344 | train_auc: 0.9566 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [200 / 1130] avg_train_loss: 0.3274 | train_auc: 0.9625 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [300 / 1130] avg_train_loss: 0.3199 | train_auc: 0.9642 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [400 / 1130] avg_train_loss: 0.2976 | train_auc: 0.9692 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [500 / 1130] avg_train_loss: 0.3048 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [600 / 1130] avg_train_loss: 0.31 | train_auc: 0.9672 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [700 / 1130] avg_train_loss: 0.3084 | train_auc: 0.9677 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [800 / 1130] avg_train_loss: 0.302 | train_auc: 0.9694 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [900 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9712 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [1000 / 1130] avg_train_loss: 0.28 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [117 / 200] Step: [1100 / 1130] avg_train_loss: 0.2862 | train_auc: 0.9736 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 117 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1675 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1697 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4151 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6576 | val_auc: 0.6537 | lr: 7.289999999999999e-09
[Epoch: 117 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7564 | val_auc: 0.7099 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 118
[TRAIN] Train model
Epoch [118 / 200] Step: [100 / 1130] avg_train_loss: 0.2708 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [200 / 1130] avg_train_loss: 0.296 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [300 / 1130] avg_train_loss: 0.2858 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [400 / 1130] avg_train_loss: 0.283 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [500 / 1130] avg_train_loss: 0.2978 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [600 / 1130] avg_train_loss: 0.2851 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [700 / 1130] avg_train_loss: 0.2864 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [800 / 1130] avg_train_loss: 0.2806 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [900 / 1130] avg_train_loss: 0.2808 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [1000 / 1130] avg_train_loss: 0.2757 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [118 / 200] Step: [1100 / 1130] avg_train_loss: 0.2804 | train_auc: 0.9779 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 118 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1937 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1828 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4161 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6434 | val_auc: 0.6851 | lr: 7.289999999999999e-09
[Epoch: 118 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7338 | val_auc: 0.7348 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 119
[TRAIN] Train model
Epoch [119 / 200] Step: [100 / 1130] avg_train_loss: 0.3352 | train_auc: 0.9603 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [200 / 1130] avg_train_loss: 0.261 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [300 / 1130] avg_train_loss: 0.2564 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [400 / 1130] avg_train_loss: 0.2611 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [500 / 1130] avg_train_loss: 0.2695 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [600 / 1130] avg_train_loss: 0.2634 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [700 / 1130] avg_train_loss: 0.2668 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [800 / 1130] avg_train_loss: 0.2894 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [900 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [1000 / 1130] avg_train_loss: 0.2877 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [119 / 200] Step: [1100 / 1130] avg_train_loss: 0.2876 | train_auc: 0.9752 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 119 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2685 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.244 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4622 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6559 | val_auc: 0.6528 | lr: 7.289999999999999e-09
[Epoch: 119 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7069 | val_auc: 0.7193 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 120
[TRAIN] Train model
Epoch [120 / 200] Step: [100 / 1130] avg_train_loss: 0.3769 | train_auc: 0.9557 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [200 / 1130] avg_train_loss: 0.3533 | train_auc: 0.9607 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [300 / 1130] avg_train_loss: 0.3319 | train_auc: 0.9676 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [400 / 1130] avg_train_loss: 0.3266 | train_auc: 0.9683 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [500 / 1130] avg_train_loss: 0.3182 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [600 / 1130] avg_train_loss: 0.3126 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [700 / 1130] avg_train_loss: 0.3052 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [800 / 1130] avg_train_loss: 0.2956 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [900 / 1130] avg_train_loss: 0.2948 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [1000 / 1130] avg_train_loss: 0.2902 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [120 / 200] Step: [1100 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9778 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 120 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1866 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1871 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4093 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6259 | val_auc: 0.6851 | lr: 7.289999999999999e-09
[Epoch: 120 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7009 | val_auc: 0.7393 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 121
[TRAIN] Train model
Epoch [121 / 200] Step: [100 / 1130] avg_train_loss: 0.337 | train_auc: 0.9695 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [200 / 1130] avg_train_loss: 0.2959 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [300 / 1130] avg_train_loss: 0.2852 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [400 / 1130] avg_train_loss: 0.3095 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [500 / 1130] avg_train_loss: 0.3068 | train_auc: 0.9714 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [600 / 1130] avg_train_loss: 0.29 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [700 / 1130] avg_train_loss: 0.2772 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [800 / 1130] avg_train_loss: 0.2703 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [900 / 1130] avg_train_loss: 0.2649 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [1000 / 1130] avg_train_loss: 0.2616 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [121 / 200] Step: [1100 / 1130] avg_train_loss: 0.2735 | train_auc: 0.9788 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 121 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1583 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1588 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4016 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6265 | val_auc: 0.7088 | lr: 7.289999999999999e-09
[Epoch: 121 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7044 | val_auc: 0.762 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 122
[TRAIN] Train model
Epoch [122 / 200] Step: [100 / 1130] avg_train_loss: 0.3669 | train_auc: 0.9502 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [200 / 1130] avg_train_loss: 0.3758 | train_auc: 0.9514 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [300 / 1130] avg_train_loss: 0.3355 | train_auc: 0.9648 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [400 / 1130] avg_train_loss: 0.3057 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [500 / 1130] avg_train_loss: 0.3014 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [600 / 1130] avg_train_loss: 0.3008 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [700 / 1130] avg_train_loss: 0.2954 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [800 / 1130] avg_train_loss: 0.2949 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [900 / 1130] avg_train_loss: 0.2972 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [1000 / 1130] avg_train_loss: 0.2869 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [122 / 200] Step: [1100 / 1130] avg_train_loss: 0.2816 | train_auc: 0.9775 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 122 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.282 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2618 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4893 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.7061 | val_auc: 0.6163 | lr: 7.289999999999999e-09
[Epoch: 122 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7456 | val_auc: 0.693 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 123
[TRAIN] Train model
Epoch [123 / 200] Step: [100 / 1130] avg_train_loss: 0.2568 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [200 / 1130] avg_train_loss: 0.2805 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [300 / 1130] avg_train_loss: 0.266 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [400 / 1130] avg_train_loss: 0.2614 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [500 / 1130] avg_train_loss: 0.2719 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [600 / 1130] avg_train_loss: 0.2689 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [700 / 1130] avg_train_loss: 0.267 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [800 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [900 / 1130] avg_train_loss: 0.2754 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [1000 / 1130] avg_train_loss: 0.2709 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [123 / 200] Step: [1100 / 1130] avg_train_loss: 0.2643 | train_auc: 0.9811 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 123 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3073 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2807 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4711 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.658 | val_auc: 0.6341 | lr: 7.289999999999999e-09
[Epoch: 123 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7047 | val_auc: 0.7054 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 124
[TRAIN] Train model
Epoch [124 / 200] Step: [100 / 1130] avg_train_loss: 0.2231 | train_auc: 0.9915 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [200 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [300 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [400 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [500 / 1130] avg_train_loss: 0.287 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [600 / 1130] avg_train_loss: 0.2823 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [700 / 1130] avg_train_loss: 0.2777 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [800 / 1130] avg_train_loss: 0.27 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [900 / 1130] avg_train_loss: 0.2723 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [1000 / 1130] avg_train_loss: 0.2721 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [124 / 200] Step: [1100 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9777 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 124 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1631 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1542 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4196 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6643 | val_auc: 0.6952 | lr: 7.289999999999999e-09
[Epoch: 124 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7692 | val_auc: 0.7335 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 125
[TRAIN] Train model
Epoch [125 / 200] Step: [100 / 1130] avg_train_loss: 0.2801 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [200 / 1130] avg_train_loss: 0.2673 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [300 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [400 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [500 / 1130] avg_train_loss: 0.291 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [600 / 1130] avg_train_loss: 0.2885 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [700 / 1130] avg_train_loss: 0.2958 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [800 / 1130] avg_train_loss: 0.2791 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [900 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [1000 / 1130] avg_train_loss: 0.2826 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [125 / 200] Step: [1100 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9803 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 125 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2057 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1991 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4452 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6322 | val_auc: 0.691 | lr: 7.289999999999999e-09
[Epoch: 125 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6915 | val_auc: 0.7433 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 126
[TRAIN] Train model
Epoch [126 / 200] Step: [100 / 1130] avg_train_loss: 0.1903 | train_auc: 0.9945 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [200 / 1130] avg_train_loss: 0.2959 | train_auc: 0.9737 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [300 / 1130] avg_train_loss: 0.2586 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [400 / 1130] avg_train_loss: 0.2765 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [500 / 1130] avg_train_loss: 0.3007 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [600 / 1130] avg_train_loss: 0.2979 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [700 / 1130] avg_train_loss: 0.2977 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [800 / 1130] avg_train_loss: 0.294 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [900 / 1130] avg_train_loss: 0.2877 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [1000 / 1130] avg_train_loss: 0.2824 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [126 / 200] Step: [1100 / 1130] avg_train_loss: 0.2828 | train_auc: 0.9769 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 126 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2232 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.216 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4433 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6637 | val_auc: 0.6435 | lr: 7.289999999999999e-09
[Epoch: 126 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7168 | val_auc: 0.7126 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 127
[TRAIN] Train model
Epoch [127 / 200] Step: [100 / 1130] avg_train_loss: 0.3928 | train_auc: 0.9585 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [200 / 1130] avg_train_loss: 0.3279 | train_auc: 0.9694 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [300 / 1130] avg_train_loss: 0.3292 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [400 / 1130] avg_train_loss: 0.3456 | train_auc: 0.9623 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [500 / 1130] avg_train_loss: 0.3459 | train_auc: 0.9634 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [600 / 1130] avg_train_loss: 0.3319 | train_auc: 0.9664 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [700 / 1130] avg_train_loss: 0.3372 | train_auc: 0.9634 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [800 / 1130] avg_train_loss: 0.3207 | train_auc: 0.9674 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [900 / 1130] avg_train_loss: 0.3098 | train_auc: 0.9699 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [1000 / 1130] avg_train_loss: 0.3015 | train_auc: 0.9724 | lr : 7.289999999999999e-09
Epoch [127 / 200] Step: [1100 / 1130] avg_train_loss: 0.3031 | train_auc: 0.9717 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 127 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2153 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2195 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4366 | val_auc: 0.6455 | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6347 | val_auc: 0.646 | lr: 7.289999999999999e-09
[Epoch: 127 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.697 | val_auc: 0.7077 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 128
[TRAIN] Train model
Epoch [128 / 200] Step: [100 / 1130] avg_train_loss: 0.2863 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [200 / 1130] avg_train_loss: 0.3211 | train_auc: 0.9683 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [300 / 1130] avg_train_loss: 0.3038 | train_auc: 0.9724 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [400 / 1130] avg_train_loss: 0.2995 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [500 / 1130] avg_train_loss: 0.297 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [600 / 1130] avg_train_loss: 0.2954 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [700 / 1130] avg_train_loss: 0.2926 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [800 / 1130] avg_train_loss: 0.2996 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [900 / 1130] avg_train_loss: 0.2892 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [1000 / 1130] avg_train_loss: 0.2906 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [128 / 200] Step: [1100 / 1130] avg_train_loss: 0.2901 | train_auc: 0.9764 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 128 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1891 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1769 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4148 | val_auc: 0.7011 | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6597 | val_auc: 0.6715 | lr: 7.289999999999999e-09
[Epoch: 128 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7551 | val_auc: 0.7184 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 129
[TRAIN] Train model
Epoch [129 / 200] Step: [100 / 1130] avg_train_loss: 0.2429 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [200 / 1130] avg_train_loss: 0.2819 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [300 / 1130] avg_train_loss: 0.2607 | train_auc: 0.9821 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [400 / 1130] avg_train_loss: 0.2683 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [500 / 1130] avg_train_loss: 0.2957 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [600 / 1130] avg_train_loss: 0.2907 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [700 / 1130] avg_train_loss: 0.2907 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [800 / 1130] avg_train_loss: 0.2927 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [900 / 1130] avg_train_loss: 0.2931 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [1000 / 1130] avg_train_loss: 0.2952 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [129 / 200] Step: [1100 / 1130] avg_train_loss: 0.2907 | train_auc: 0.9779 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 129 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.18 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1831 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4679 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6663 | val_auc: 0.6851 | lr: 7.289999999999999e-09
[Epoch: 129 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7303 | val_auc: 0.7406 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 130
[TRAIN] Train model
Epoch [130 / 200] Step: [100 / 1130] avg_train_loss: 0.3178 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [200 / 1130] avg_train_loss: 0.309 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [300 / 1130] avg_train_loss: 0.3043 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [400 / 1130] avg_train_loss: 0.3001 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [500 / 1130] avg_train_loss: 0.2915 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [600 / 1130] avg_train_loss: 0.2741 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [700 / 1130] avg_train_loss: 0.284 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [800 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [900 / 1130] avg_train_loss: 0.2782 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [1000 / 1130] avg_train_loss: 0.2798 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [130 / 200] Step: [1100 / 1130] avg_train_loss: 0.2846 | train_auc: 0.9793 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 130 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1463 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1429 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4194 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6707 | val_auc: 0.6995 | lr: 7.289999999999999e-09
[Epoch: 130 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7898 | val_auc: 0.734 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 131
[TRAIN] Train model
Epoch [131 / 200] Step: [100 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [200 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [300 / 1130] avg_train_loss: 0.3158 | train_auc: 0.9687 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [400 / 1130] avg_train_loss: 0.294 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [500 / 1130] avg_train_loss: 0.2953 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [600 / 1130] avg_train_loss: 0.2808 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [700 / 1130] avg_train_loss: 0.2709 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [800 / 1130] avg_train_loss: 0.2796 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [900 / 1130] avg_train_loss: 0.28 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [1000 / 1130] avg_train_loss: 0.2733 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [131 / 200] Step: [1100 / 1130] avg_train_loss: 0.2808 | train_auc: 0.9784 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 131 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1542 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1615 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4246 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6435 | val_auc: 0.7165 | lr: 7.289999999999999e-09
[Epoch: 131 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7371 | val_auc: 0.7545 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 132
[TRAIN] Train model
Epoch [132 / 200] Step: [100 / 1130] avg_train_loss: 0.2266 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [200 / 1130] avg_train_loss: 0.3077 | train_auc: 0.9708 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [300 / 1130] avg_train_loss: 0.2863 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [400 / 1130] avg_train_loss: 0.2833 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [500 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [600 / 1130] avg_train_loss: 0.251 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [700 / 1130] avg_train_loss: 0.2524 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [800 / 1130] avg_train_loss: 0.2736 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [900 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [1000 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [132 / 200] Step: [1100 / 1130] avg_train_loss: 0.2744 | train_auc: 0.9796 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 132 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1239 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1156 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4008 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6878 | val_auc: 0.7012 | lr: 7.289999999999999e-09
[Epoch: 132 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8185 | val_auc: 0.7442 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 133
[TRAIN] Train model
Epoch [133 / 200] Step: [100 / 1130] avg_train_loss: 0.3069 | train_auc: 0.9709 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [200 / 1130] avg_train_loss: 0.3013 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [300 / 1130] avg_train_loss: 0.2856 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [400 / 1130] avg_train_loss: 0.2875 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [500 / 1130] avg_train_loss: 0.27 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [600 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [700 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [800 / 1130] avg_train_loss: 0.2699 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [900 / 1130] avg_train_loss: 0.2739 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [1000 / 1130] avg_train_loss: 0.2844 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [133 / 200] Step: [1100 / 1130] avg_train_loss: 0.2945 | train_auc: 0.9738 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 133 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1602 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1554 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4005 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6264 | val_auc: 0.7012 | lr: 7.289999999999999e-09
[Epoch: 133 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7007 | val_auc: 0.7558 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 134
[TRAIN] Train model
Epoch [134 / 200] Step: [100 / 1130] avg_train_loss: 0.3449 | train_auc: 0.9603 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [200 / 1130] avg_train_loss: 0.2976 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [300 / 1130] avg_train_loss: 0.2854 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [400 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [500 / 1130] avg_train_loss: 0.2743 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [600 / 1130] avg_train_loss: 0.2854 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [700 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [800 / 1130] avg_train_loss: 0.2915 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [900 / 1130] avg_train_loss: 0.2881 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [1000 / 1130] avg_train_loss: 0.2806 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [134 / 200] Step: [1100 / 1130] avg_train_loss: 0.2802 | train_auc: 0.9771 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 134 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1694 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1646 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3947 | val_auc: 0.7487 | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6224 | val_auc: 0.7012 | lr: 7.289999999999999e-09
[Epoch: 134 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7254 | val_auc: 0.7424 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 135
[TRAIN] Train model
Epoch [135 / 200] Step: [100 / 1130] avg_train_loss: 0.2128 | train_auc: 0.9923 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [200 / 1130] avg_train_loss: 0.2482 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [300 / 1130] avg_train_loss: 0.2579 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [400 / 1130] avg_train_loss: 0.2436 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [500 / 1130] avg_train_loss: 0.2471 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [600 / 1130] avg_train_loss: 0.2421 | train_auc: 0.9874 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [700 / 1130] avg_train_loss: 0.2453 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [800 / 1130] avg_train_loss: 0.2527 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [900 / 1130] avg_train_loss: 0.2634 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [1000 / 1130] avg_train_loss: 0.2611 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [135 / 200] Step: [1100 / 1130] avg_train_loss: 0.2633 | train_auc: 0.9813 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 135 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1711 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1692 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3983 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6319 | val_auc: 0.6978 | lr: 7.289999999999999e-09
[Epoch: 135 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7408 | val_auc: 0.7371 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 136
[TRAIN] Train model
Epoch [136 / 200] Step: [100 / 1130] avg_train_loss: 0.2497 | train_auc: 0.9813 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [200 / 1130] avg_train_loss: 0.2422 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [300 / 1130] avg_train_loss: 0.2518 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [400 / 1130] avg_train_loss: 0.2535 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [500 / 1130] avg_train_loss: 0.2757 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [600 / 1130] avg_train_loss: 0.276 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [700 / 1130] avg_train_loss: 0.276 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [800 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [900 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [1000 / 1130] avg_train_loss: 0.2692 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [136 / 200] Step: [1100 / 1130] avg_train_loss: 0.2662 | train_auc: 0.9818 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 136 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1925 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1875 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4171 | val_auc: 0.7434 | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6357 | val_auc: 0.6969 | lr: 7.289999999999999e-09
[Epoch: 136 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7099 | val_auc: 0.7442 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 137
[TRAIN] Train model
Epoch [137 / 200] Step: [100 / 1130] avg_train_loss: 0.3332 | train_auc: 0.968 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [200 / 1130] avg_train_loss: 0.3402 | train_auc: 0.961 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [300 / 1130] avg_train_loss: 0.3444 | train_auc: 0.9619 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [400 / 1130] avg_train_loss: 0.3203 | train_auc: 0.969 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [500 / 1130] avg_train_loss: 0.3162 | train_auc: 0.9699 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [600 / 1130] avg_train_loss: 0.3142 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [700 / 1130] avg_train_loss: 0.3039 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [800 / 1130] avg_train_loss: 0.2925 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [900 / 1130] avg_train_loss: 0.2922 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [1000 / 1130] avg_train_loss: 0.296 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [137 / 200] Step: [1100 / 1130] avg_train_loss: 0.2962 | train_auc: 0.9738 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 137 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2769 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2476 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.455 | val_auc: 0.6296 | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6665 | val_auc: 0.6205 | lr: 7.289999999999999e-09
[Epoch: 137 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7555 | val_auc: 0.672 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 138
[TRAIN] Train model
Epoch [138 / 200] Step: [100 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9866 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [200 / 1130] avg_train_loss: 0.2682 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [300 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [400 / 1130] avg_train_loss: 0.2653 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [500 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [600 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [700 / 1130] avg_train_loss: 0.2743 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [800 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [900 / 1130] avg_train_loss: 0.2716 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [1000 / 1130] avg_train_loss: 0.274 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [138 / 200] Step: [1100 / 1130] avg_train_loss: 0.2818 | train_auc: 0.978 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 138 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1354 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1323 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4111 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6676 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 138 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7889 | val_auc: 0.7384 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 139
[TRAIN] Train model
Epoch [139 / 200] Step: [100 / 1130] avg_train_loss: 0.2926 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [200 / 1130] avg_train_loss: 0.2446 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [300 / 1130] avg_train_loss: 0.2246 | train_auc: 0.9898 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [400 / 1130] avg_train_loss: 0.2393 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [500 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [600 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [700 / 1130] avg_train_loss: 0.269 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [800 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [900 / 1130] avg_train_loss: 0.2543 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [1000 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [139 / 200] Step: [1100 / 1130] avg_train_loss: 0.2647 | train_auc: 0.9815 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 139 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1924 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1835 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4248 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6351 | val_auc: 0.6961 | lr: 7.289999999999999e-09
[Epoch: 139 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7216 | val_auc: 0.7366 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 140
[TRAIN] Train model
Epoch [140 / 200] Step: [100 / 1130] avg_train_loss: 0.2254 | train_auc: 0.9926 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [200 / 1130] avg_train_loss: 0.2716 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [300 / 1130] avg_train_loss: 0.3212 | train_auc: 0.9689 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [400 / 1130] avg_train_loss: 0.3097 | train_auc: 0.9714 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [500 / 1130] avg_train_loss: 0.2973 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [600 / 1130] avg_train_loss: 0.2793 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [700 / 1130] avg_train_loss: 0.2807 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [800 / 1130] avg_train_loss: 0.2745 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [900 / 1130] avg_train_loss: 0.2745 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [1000 / 1130] avg_train_loss: 0.277 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [140 / 200] Step: [1100 / 1130] avg_train_loss: 0.2792 | train_auc: 0.9793 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 140 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1793 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1715 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4136 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.642 | val_auc: 0.6952 | lr: 7.289999999999999e-09
[Epoch: 140 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7195 | val_auc: 0.7518 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 141
[TRAIN] Train model
Epoch [141 / 200] Step: [100 / 1130] avg_train_loss: 0.2349 | train_auc: 0.9873 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [200 / 1130] avg_train_loss: 0.2034 | train_auc: 0.9934 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [300 / 1130] avg_train_loss: 0.2279 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [400 / 1130] avg_train_loss: 0.236 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [500 / 1130] avg_train_loss: 0.2395 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [600 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [700 / 1130] avg_train_loss: 0.2455 | train_auc: 0.9859 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [800 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [900 / 1130] avg_train_loss: 0.2666 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [1000 / 1130] avg_train_loss: 0.2634 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [141 / 200] Step: [1100 / 1130] avg_train_loss: 0.2645 | train_auc: 0.9811 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 141 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1621 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1613 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3925 | val_auc: 0.7487 | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6347 | val_auc: 0.6978 | lr: 7.289999999999999e-09
[Epoch: 141 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7241 | val_auc: 0.7491 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 142
[TRAIN] Train model
Epoch [142 / 200] Step: [100 / 1130] avg_train_loss: 0.2108 | train_auc: 0.9944 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [200 / 1130] avg_train_loss: 0.2252 | train_auc: 0.9926 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [300 / 1130] avg_train_loss: 0.2151 | train_auc: 0.9938 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [400 / 1130] avg_train_loss: 0.2462 | train_auc: 0.9863 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [500 / 1130] avg_train_loss: 0.2566 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [600 / 1130] avg_train_loss: 0.2527 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [700 / 1130] avg_train_loss: 0.2525 | train_auc: 0.9848 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [800 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [900 / 1130] avg_train_loss: 0.2605 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [1000 / 1130] avg_train_loss: 0.2604 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [142 / 200] Step: [1100 / 1130] avg_train_loss: 0.2673 | train_auc: 0.9824 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 142 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1495 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1583 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4038 | val_auc: 0.7169 | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6445 | val_auc: 0.691 | lr: 7.289999999999999e-09
[Epoch: 142 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7315 | val_auc: 0.7384 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 143
[TRAIN] Train model
Epoch [143 / 200] Step: [100 / 1130] avg_train_loss: 0.3767 | train_auc: 0.9599 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [200 / 1130] avg_train_loss: 0.3283 | train_auc: 0.9705 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [300 / 1130] avg_train_loss: 0.2911 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [400 / 1130] avg_train_loss: 0.283 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [500 / 1130] avg_train_loss: 0.2878 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [600 / 1130] avg_train_loss: 0.2835 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [700 / 1130] avg_train_loss: 0.2816 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [800 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [900 / 1130] avg_train_loss: 0.2868 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [1000 / 1130] avg_train_loss: 0.2888 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [143 / 200] Step: [1100 / 1130] avg_train_loss: 0.2796 | train_auc: 0.979 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 143 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1742 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1794 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4198 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6517 | val_auc: 0.663 | lr: 7.289999999999999e-09
[Epoch: 143 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7467 | val_auc: 0.7206 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 144
[TRAIN] Train model
Epoch [144 / 200] Step: [100 / 1130] avg_train_loss: 0.2351 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [200 / 1130] avg_train_loss: 0.2669 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [300 / 1130] avg_train_loss: 0.2605 | train_auc: 0.9894 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [400 / 1130] avg_train_loss: 0.282 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [500 / 1130] avg_train_loss: 0.2798 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [600 / 1130] avg_train_loss: 0.2795 | train_auc: 0.9811 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [700 / 1130] avg_train_loss: 0.2785 | train_auc: 0.9803 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [800 / 1130] avg_train_loss: 0.2873 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [900 / 1130] avg_train_loss: 0.2993 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [1000 / 1130] avg_train_loss: 0.3019 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [144 / 200] Step: [1100 / 1130] avg_train_loss: 0.2955 | train_auc: 0.9766 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 144 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.102 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1124 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.392 | val_auc: 0.7566 | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.67 | val_auc: 0.7284 | lr: 7.289999999999999e-09
[Epoch: 144 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8109 | val_auc: 0.7674 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 145
[TRAIN] Train model
Epoch [145 / 200] Step: [100 / 1130] avg_train_loss: 0.2605 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [200 / 1130] avg_train_loss: 0.2676 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [300 / 1130] avg_train_loss: 0.2704 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [400 / 1130] avg_train_loss: 0.2696 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [500 / 1130] avg_train_loss: 0.2701 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [600 / 1130] avg_train_loss: 0.275 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [700 / 1130] avg_train_loss: 0.2672 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [800 / 1130] avg_train_loss: 0.265 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [900 / 1130] avg_train_loss: 0.265 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [1000 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [145 / 200] Step: [1100 / 1130] avg_train_loss: 0.2567 | train_auc: 0.9817 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 145 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2293 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2171 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4499 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6595 | val_auc: 0.6715 | lr: 7.289999999999999e-09
[Epoch: 145 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7221 | val_auc: 0.7224 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 146
[TRAIN] Train model
Epoch [146 / 200] Step: [100 / 1130] avg_train_loss: 0.3915 | train_auc: 0.9398 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [200 / 1130] avg_train_loss: 0.3382 | train_auc: 0.9631 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [300 / 1130] avg_train_loss: 0.3211 | train_auc: 0.9683 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [400 / 1130] avg_train_loss: 0.3152 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [500 / 1130] avg_train_loss: 0.3056 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [600 / 1130] avg_train_loss: 0.2899 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [700 / 1130] avg_train_loss: 0.286 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [800 / 1130] avg_train_loss: 0.2807 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [900 / 1130] avg_train_loss: 0.2749 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [1000 / 1130] avg_train_loss: 0.2654 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [146 / 200] Step: [1100 / 1130] avg_train_loss: 0.2694 | train_auc: 0.9812 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 146 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1641 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1623 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.418 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6649 | val_auc: 0.6689 | lr: 7.289999999999999e-09
[Epoch: 146 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7811 | val_auc: 0.7059 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 147
[TRAIN] Train model
Epoch [147 / 200] Step: [100 / 1130] avg_train_loss: 0.2986 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [200 / 1130] avg_train_loss: 0.3061 | train_auc: 0.9725 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [300 / 1130] avg_train_loss: 0.3148 | train_auc: 0.9705 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [400 / 1130] avg_train_loss: 0.3106 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [500 / 1130] avg_train_loss: 0.2886 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [600 / 1130] avg_train_loss: 0.2998 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [700 / 1130] avg_train_loss: 0.2956 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [800 / 1130] avg_train_loss: 0.3026 | train_auc: 0.9728 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [900 / 1130] avg_train_loss: 0.2977 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [1000 / 1130] avg_train_loss: 0.2896 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [147 / 200] Step: [1100 / 1130] avg_train_loss: 0.2885 | train_auc: 0.9759 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 147 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.226 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2215 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4502 | val_auc: 0.627 | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6682 | val_auc: 0.6256 | lr: 7.289999999999999e-09
[Epoch: 147 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7303 | val_auc: 0.6996 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 148
[TRAIN] Train model
Epoch [148 / 200] Step: [100 / 1130] avg_train_loss: 0.2348 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [200 / 1130] avg_train_loss: 0.2354 | train_auc: 0.9871 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [300 / 1130] avg_train_loss: 0.2389 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [400 / 1130] avg_train_loss: 0.2362 | train_auc: 0.9876 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [500 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [600 / 1130] avg_train_loss: 0.2587 | train_auc: 0.9825 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [700 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [800 / 1130] avg_train_loss: 0.2574 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [900 / 1130] avg_train_loss: 0.2603 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [1000 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [148 / 200] Step: [1100 / 1130] avg_train_loss: 0.2649 | train_auc: 0.9811 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 148 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2194 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2065 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4245 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6606 | val_auc: 0.6537 | lr: 7.289999999999999e-09
[Epoch: 148 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7323 | val_auc: 0.709 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 149
[TRAIN] Train model
Epoch [149 / 200] Step: [100 / 1130] avg_train_loss: 0.2382 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [200 / 1130] avg_train_loss: 0.2756 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [300 / 1130] avg_train_loss: 0.2768 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [400 / 1130] avg_train_loss: 0.293 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [500 / 1130] avg_train_loss: 0.2885 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [600 / 1130] avg_train_loss: 0.2841 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [700 / 1130] avg_train_loss: 0.2798 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [800 / 1130] avg_train_loss: 0.2817 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [900 / 1130] avg_train_loss: 0.286 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [1000 / 1130] avg_train_loss: 0.2815 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [149 / 200] Step: [1100 / 1130] avg_train_loss: 0.2923 | train_auc: 0.975 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 149 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2212 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1999 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4402 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6649 | val_auc: 0.6664 | lr: 7.289999999999999e-09
[Epoch: 149 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7389 | val_auc: 0.7277 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 150
[TRAIN] Train model
Epoch [150 / 200] Step: [100 / 1130] avg_train_loss: 0.2439 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [200 / 1130] avg_train_loss: 0.2223 | train_auc: 0.9921 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [300 / 1130] avg_train_loss: 0.2478 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [400 / 1130] avg_train_loss: 0.2536 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [500 / 1130] avg_train_loss: 0.2648 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [600 / 1130] avg_train_loss: 0.2583 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [700 / 1130] avg_train_loss: 0.2632 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [800 / 1130] avg_train_loss: 0.2666 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [900 / 1130] avg_train_loss: 0.2609 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [1000 / 1130] avg_train_loss: 0.2673 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [150 / 200] Step: [1100 / 1130] avg_train_loss: 0.2703 | train_auc: 0.9807 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 150 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2278 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2159 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4282 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6343 | val_auc: 0.6732 | lr: 7.289999999999999e-09
[Epoch: 150 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7022 | val_auc: 0.7233 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 151
[TRAIN] Train model
Epoch [151 / 200] Step: [100 / 1130] avg_train_loss: 0.3018 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [200 / 1130] avg_train_loss: 0.2936 | train_auc: 0.969 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [300 / 1130] avg_train_loss: 0.2674 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [400 / 1130] avg_train_loss: 0.2832 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [500 / 1130] avg_train_loss: 0.3017 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [600 / 1130] avg_train_loss: 0.307 | train_auc: 0.9704 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [700 / 1130] avg_train_loss: 0.301 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [800 / 1130] avg_train_loss: 0.2872 | train_auc: 0.9755 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [900 / 1130] avg_train_loss: 0.2905 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [1000 / 1130] avg_train_loss: 0.285 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [151 / 200] Step: [1100 / 1130] avg_train_loss: 0.282 | train_auc: 0.9768 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 151 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2404 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2362 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4962 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6647 | val_auc: 0.6902 | lr: 7.289999999999999e-09
[Epoch: 151 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7032 | val_auc: 0.7406 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 152
[TRAIN] Train model
Epoch [152 / 200] Step: [100 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [200 / 1130] avg_train_loss: 0.2782 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [300 / 1130] avg_train_loss: 0.2804 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [400 / 1130] avg_train_loss: 0.3159 | train_auc: 0.9668 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [500 / 1130] avg_train_loss: 0.302 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [600 / 1130] avg_train_loss: 0.3016 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [700 / 1130] avg_train_loss: 0.3102 | train_auc: 0.9698 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [800 / 1130] avg_train_loss: 0.3234 | train_auc: 0.9669 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [900 / 1130] avg_train_loss: 0.3172 | train_auc: 0.9683 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [1000 / 1130] avg_train_loss: 0.3131 | train_auc: 0.9687 | lr : 7.289999999999999e-09
Epoch [152 / 200] Step: [1100 / 1130] avg_train_loss: 0.3153 | train_auc: 0.9685 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 152 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.158 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.158 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4102 | val_auc: 0.7275 | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6477 | val_auc: 0.7029 | lr: 7.289999999999999e-09
[Epoch: 152 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7277 | val_auc: 0.7496 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 153
[TRAIN] Train model
Epoch [153 / 200] Step: [100 / 1130] avg_train_loss: 0.2303 | train_auc: 0.9897 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [200 / 1130] avg_train_loss: 0.2504 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [300 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [400 / 1130] avg_train_loss: 0.2659 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [500 / 1130] avg_train_loss: 0.2826 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [600 / 1130] avg_train_loss: 0.2819 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [700 / 1130] avg_train_loss: 0.2839 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [800 / 1130] avg_train_loss: 0.2969 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [900 / 1130] avg_train_loss: 0.2968 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [1000 / 1130] avg_train_loss: 0.296 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [153 / 200] Step: [1100 / 1130] avg_train_loss: 0.2903 | train_auc: 0.9763 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 153 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.129 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1357 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.402 | val_auc: 0.7328 | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6384 | val_auc: 0.7224 | lr: 7.289999999999999e-09
[Epoch: 153 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7475 | val_auc: 0.7549 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 154
[TRAIN] Train model
Epoch [154 / 200] Step: [100 / 1130] avg_train_loss: 0.2993 | train_auc: 0.9714 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [200 / 1130] avg_train_loss: 0.2847 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [300 / 1130] avg_train_loss: 0.271 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [400 / 1130] avg_train_loss: 0.2866 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [500 / 1130] avg_train_loss: 0.29 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [600 / 1130] avg_train_loss: 0.2974 | train_auc: 0.973 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [700 / 1130] avg_train_loss: 0.2877 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [800 / 1130] avg_train_loss: 0.283 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [900 / 1130] avg_train_loss: 0.2876 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [1000 / 1130] avg_train_loss: 0.2825 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [154 / 200] Step: [1100 / 1130] avg_train_loss: 0.2812 | train_auc: 0.9771 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 154 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1921 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1816 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4266 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6556 | val_auc: 0.6579 | lr: 7.289999999999999e-09
[Epoch: 154 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7439 | val_auc: 0.7152 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 155
[TRAIN] Train model
Epoch [155 / 200] Step: [100 / 1130] avg_train_loss: 0.3003 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [200 / 1130] avg_train_loss: 0.3043 | train_auc: 0.9735 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [300 / 1130] avg_train_loss: 0.2839 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [400 / 1130] avg_train_loss: 0.2942 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [500 / 1130] avg_train_loss: 0.3187 | train_auc: 0.9686 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [600 / 1130] avg_train_loss: 0.308 | train_auc: 0.9708 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [700 / 1130] avg_train_loss: 0.3116 | train_auc: 0.9696 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [800 / 1130] avg_train_loss: 0.3078 | train_auc: 0.9717 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [900 / 1130] avg_train_loss: 0.2994 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [1000 / 1130] avg_train_loss: 0.2943 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [155 / 200] Step: [1100 / 1130] avg_train_loss: 0.2941 | train_auc: 0.9751 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 155 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1946 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1802 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4223 | val_auc: 0.6746 | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6596 | val_auc: 0.6604 | lr: 7.289999999999999e-09
[Epoch: 155 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7659 | val_auc: 0.7059 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 156
[TRAIN] Train model
Epoch [156 / 200] Step: [100 / 1130] avg_train_loss: 0.3312 | train_auc: 0.9666 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [200 / 1130] avg_train_loss: 0.3015 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [300 / 1130] avg_train_loss: 0.3315 | train_auc: 0.9718 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [400 / 1130] avg_train_loss: 0.3173 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [500 / 1130] avg_train_loss: 0.3095 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [600 / 1130] avg_train_loss: 0.3054 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [700 / 1130] avg_train_loss: 0.306 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [800 / 1130] avg_train_loss: 0.3024 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [900 / 1130] avg_train_loss: 0.2993 | train_auc: 0.9752 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [1000 / 1130] avg_train_loss: 0.2919 | train_auc: 0.9765 | lr : 7.289999999999999e-09
Epoch [156 / 200] Step: [1100 / 1130] avg_train_loss: 0.2987 | train_auc: 0.9749 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 156 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1609 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.157 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4023 | val_auc: 0.7196 | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.637 | val_auc: 0.6969 | lr: 7.289999999999999e-09
[Epoch: 156 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7252 | val_auc: 0.7464 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 157
[TRAIN] Train model
Epoch [157 / 200] Step: [100 / 1130] avg_train_loss: 0.2752 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [200 / 1130] avg_train_loss: 0.2581 | train_auc: 0.9845 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [300 / 1130] avg_train_loss: 0.2602 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [400 / 1130] avg_train_loss: 0.2617 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [500 / 1130] avg_train_loss: 0.2669 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [600 / 1130] avg_train_loss: 0.2654 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [700 / 1130] avg_train_loss: 0.257 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [800 / 1130] avg_train_loss: 0.2567 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [900 / 1130] avg_train_loss: 0.2636 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [1000 / 1130] avg_train_loss: 0.2736 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [157 / 200] Step: [1100 / 1130] avg_train_loss: 0.2843 | train_auc: 0.9775 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 157 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2269 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2062 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4613 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6799 | val_auc: 0.663 | lr: 7.289999999999999e-09
[Epoch: 157 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.741 | val_auc: 0.7317 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 158
[TRAIN] Train model
Epoch [158 / 200] Step: [100 / 1130] avg_train_loss: 0.3504 | train_auc: 0.9601 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [200 / 1130] avg_train_loss: 0.3422 | train_auc: 0.9606 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [300 / 1130] avg_train_loss: 0.3212 | train_auc: 0.967 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [400 / 1130] avg_train_loss: 0.3209 | train_auc: 0.9683 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [500 / 1130] avg_train_loss: 0.3068 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [600 / 1130] avg_train_loss: 0.2988 | train_auc: 0.9737 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [700 / 1130] avg_train_loss: 0.3024 | train_auc: 0.972 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [800 / 1130] avg_train_loss: 0.2987 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [900 / 1130] avg_train_loss: 0.2997 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [1000 / 1130] avg_train_loss: 0.2891 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [158 / 200] Step: [1100 / 1130] avg_train_loss: 0.2863 | train_auc: 0.9762 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 158 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1788 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1722 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4186 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6552 | val_auc: 0.6604 | lr: 7.289999999999999e-09
[Epoch: 158 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7302 | val_auc: 0.7237 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 159
[TRAIN] Train model
Epoch [159 / 200] Step: [100 / 1130] avg_train_loss: 0.272 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [200 / 1130] avg_train_loss: 0.2693 | train_auc: 0.9714 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [300 / 1130] avg_train_loss: 0.2554 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [400 / 1130] avg_train_loss: 0.2396 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [500 / 1130] avg_train_loss: 0.2662 | train_auc: 0.9758 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [600 / 1130] avg_train_loss: 0.2781 | train_auc: 0.973 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [700 / 1130] avg_train_loss: 0.2818 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [800 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [900 / 1130] avg_train_loss: 0.274 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [1000 / 1130] avg_train_loss: 0.2666 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [159 / 200] Step: [1100 / 1130] avg_train_loss: 0.269 | train_auc: 0.9783 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 159 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2418 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2145 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4477 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6684 | val_auc: 0.6613 | lr: 7.289999999999999e-09
[Epoch: 159 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7494 | val_auc: 0.709 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 160
[TRAIN] Train model
Epoch [160 / 200] Step: [100 / 1130] avg_train_loss: 0.3221 | train_auc: 0.9543 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [200 / 1130] avg_train_loss: 0.3783 | train_auc: 0.9438 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [300 / 1130] avg_train_loss: 0.3299 | train_auc: 0.9585 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [400 / 1130] avg_train_loss: 0.3126 | train_auc: 0.9644 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [500 / 1130] avg_train_loss: 0.3033 | train_auc: 0.9686 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [600 / 1130] avg_train_loss: 0.2952 | train_auc: 0.9707 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [700 / 1130] avg_train_loss: 0.2833 | train_auc: 0.9738 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [800 / 1130] avg_train_loss: 0.2805 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [900 / 1130] avg_train_loss: 0.28 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [1000 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [160 / 200] Step: [1100 / 1130] avg_train_loss: 0.273 | train_auc: 0.9786 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 160 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2217 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2006 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4415 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6474 | val_auc: 0.6706 | lr: 7.289999999999999e-09
[Epoch: 160 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7062 | val_auc: 0.7447 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 161
[TRAIN] Train model
Epoch [161 / 200] Step: [100 / 1130] avg_train_loss: 0.3361 | train_auc: 0.9632 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [200 / 1130] avg_train_loss: 0.3054 | train_auc: 0.9721 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [300 / 1130] avg_train_loss: 0.3115 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [400 / 1130] avg_train_loss: 0.2898 | train_auc: 0.9739 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [500 / 1130] avg_train_loss: 0.292 | train_auc: 0.9703 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [600 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9706 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [700 / 1130] avg_train_loss: 0.2796 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [800 / 1130] avg_train_loss: 0.2791 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [900 / 1130] avg_train_loss: 0.2721 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [1000 / 1130] avg_train_loss: 0.2685 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [161 / 200] Step: [1100 / 1130] avg_train_loss: 0.2759 | train_auc: 0.977 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 161 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1845 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1771 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4275 | val_auc: 0.664 | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6425 | val_auc: 0.6783 | lr: 7.289999999999999e-09
[Epoch: 161 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7006 | val_auc: 0.7447 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 162
[TRAIN] Train model
Epoch [162 / 200] Step: [100 / 1130] avg_train_loss: 0.2366 | train_auc: 0.9917 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [200 / 1130] avg_train_loss: 0.2909 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [300 / 1130] avg_train_loss: 0.2714 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [400 / 1130] avg_train_loss: 0.2883 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [500 / 1130] avg_train_loss: 0.2826 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [600 / 1130] avg_train_loss: 0.291 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [700 / 1130] avg_train_loss: 0.2871 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [800 / 1130] avg_train_loss: 0.2861 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [900 / 1130] avg_train_loss: 0.2865 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [1000 / 1130] avg_train_loss: 0.2823 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [162 / 200] Step: [1100 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9758 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 162 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1953 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1843 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.415 | val_auc: 0.6667 | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6393 | val_auc: 0.6613 | lr: 7.289999999999999e-09
[Epoch: 162 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7274 | val_auc: 0.7179 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 163
[TRAIN] Train model
Epoch [163 / 200] Step: [100 / 1130] avg_train_loss: 0.2194 | train_auc: 0.9911 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [200 / 1130] avg_train_loss: 0.2152 | train_auc: 0.9929 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [300 / 1130] avg_train_loss: 0.2541 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [400 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [500 / 1130] avg_train_loss: 0.2596 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [600 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [700 / 1130] avg_train_loss: 0.2683 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [800 / 1130] avg_train_loss: 0.2679 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [900 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [1000 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [163 / 200] Step: [1100 / 1130] avg_train_loss: 0.2785 | train_auc: 0.9785 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 163 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.181 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1814 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4143 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6305 | val_auc: 0.6834 | lr: 7.289999999999999e-09
[Epoch: 163 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7243 | val_auc: 0.7215 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 164
[TRAIN] Train model
Epoch [164 / 200] Step: [100 / 1130] avg_train_loss: 0.2775 | train_auc: 0.988 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [200 / 1130] avg_train_loss: 0.2491 | train_auc: 0.9869 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [300 / 1130] avg_train_loss: 0.2324 | train_auc: 0.9892 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [400 / 1130] avg_train_loss: 0.2354 | train_auc: 0.9881 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [500 / 1130] avg_train_loss: 0.2528 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [600 / 1130] avg_train_loss: 0.2471 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [700 / 1130] avg_train_loss: 0.2562 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [800 / 1130] avg_train_loss: 0.264 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [900 / 1130] avg_train_loss: 0.2814 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [1000 / 1130] avg_train_loss: 0.2796 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [164 / 200] Step: [1100 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9775 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 164 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1985 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1886 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4293 | val_auc: 0.6534 | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6702 | val_auc: 0.6299 | lr: 7.289999999999999e-09
[Epoch: 164 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7594 | val_auc: 0.6992 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 165
[TRAIN] Train model
Epoch [165 / 200] Step: [100 / 1130] avg_train_loss: 0.2943 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [200 / 1130] avg_train_loss: 0.2859 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [300 / 1130] avg_train_loss: 0.268 | train_auc: 0.9824 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [400 / 1130] avg_train_loss: 0.276 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [500 / 1130] avg_train_loss: 0.2785 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [600 / 1130] avg_train_loss: 0.2736 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [700 / 1130] avg_train_loss: 0.2786 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [800 / 1130] avg_train_loss: 0.277 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [900 / 1130] avg_train_loss: 0.2804 | train_auc: 0.9805 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [1000 / 1130] avg_train_loss: 0.2806 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [165 / 200] Step: [1100 / 1130] avg_train_loss: 0.2792 | train_auc: 0.9807 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 165 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2248 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2273 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4361 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6406 | val_auc: 0.657 | lr: 7.289999999999999e-09
[Epoch: 165 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7172 | val_auc: 0.7108 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 166
[TRAIN] Train model
Epoch [166 / 200] Step: [100 / 1130] avg_train_loss: 0.1967 | train_auc: 0.9952 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [200 / 1130] avg_train_loss: 0.1924 | train_auc: 0.9947 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [300 / 1130] avg_train_loss: 0.2131 | train_auc: 0.9909 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [400 / 1130] avg_train_loss: 0.259 | train_auc: 0.979 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [500 / 1130] avg_train_loss: 0.256 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [600 / 1130] avg_train_loss: 0.2744 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [700 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [800 / 1130] avg_train_loss: 0.2743 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [900 / 1130] avg_train_loss: 0.2777 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [1000 / 1130] avg_train_loss: 0.2728 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [166 / 200] Step: [1100 / 1130] avg_train_loss: 0.2731 | train_auc: 0.9786 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 166 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1365 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.137 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.398 | val_auc: 0.7593 | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6578 | val_auc: 0.7114 | lr: 7.289999999999999e-09
[Epoch: 166 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7808 | val_auc: 0.7473 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 167
[TRAIN] Train model
Epoch [167 / 200] Step: [100 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [200 / 1130] avg_train_loss: 0.221 | train_auc: 0.9922 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [300 / 1130] avg_train_loss: 0.2334 | train_auc: 0.9902 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [400 / 1130] avg_train_loss: 0.2665 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [500 / 1130] avg_train_loss: 0.281 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [600 / 1130] avg_train_loss: 0.283 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [700 / 1130] avg_train_loss: 0.287 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [800 / 1130] avg_train_loss: 0.2846 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [900 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [1000 / 1130] avg_train_loss: 0.2792 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [167 / 200] Step: [1100 / 1130] avg_train_loss: 0.2799 | train_auc: 0.9776 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 167 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.241 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2293 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4325 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6322 | val_auc: 0.6562 | lr: 7.289999999999999e-09
[Epoch: 167 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7048 | val_auc: 0.7148 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 168
[TRAIN] Train model
Epoch [168 / 200] Step: [100 / 1130] avg_train_loss: 0.2084 | train_auc: 0.9947 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [200 / 1130] avg_train_loss: 0.2749 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [300 / 1130] avg_train_loss: 0.2778 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [400 / 1130] avg_train_loss: 0.2565 | train_auc: 0.9809 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [500 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [600 / 1130] avg_train_loss: 0.2608 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [700 / 1130] avg_train_loss: 0.2618 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [800 / 1130] avg_train_loss: 0.2606 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [900 / 1130] avg_train_loss: 0.2635 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [1000 / 1130] avg_train_loss: 0.2595 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [168 / 200] Step: [1100 / 1130] avg_train_loss: 0.2612 | train_auc: 0.9827 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 168 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1867 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.184 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4033 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6236 | val_auc: 0.6935 | lr: 7.289999999999999e-09
[Epoch: 168 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7196 | val_auc: 0.7353 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 169
[TRAIN] Train model
Epoch [169 / 200] Step: [100 / 1130] avg_train_loss: 0.3028 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [200 / 1130] avg_train_loss: 0.2735 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [300 / 1130] avg_train_loss: 0.3212 | train_auc: 0.9698 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [400 / 1130] avg_train_loss: 0.3013 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [500 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [600 / 1130] avg_train_loss: 0.2817 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [700 / 1130] avg_train_loss: 0.2801 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [800 / 1130] avg_train_loss: 0.2802 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [900 / 1130] avg_train_loss: 0.2845 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [1000 / 1130] avg_train_loss: 0.2847 | train_auc: 0.9771 | lr : 7.289999999999999e-09
Epoch [169 / 200] Step: [1100 / 1130] avg_train_loss: 0.2931 | train_auc: 0.9757 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 169 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1683 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.172 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4273 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6416 | val_auc: 0.7054 | lr: 7.289999999999999e-09
[Epoch: 169 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7232 | val_auc: 0.7522 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 170
[TRAIN] Train model
Epoch [170 / 200] Step: [100 / 1130] avg_train_loss: 0.2519 | train_auc: 0.9883 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [200 / 1130] avg_train_loss: 0.2576 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [300 / 1130] avg_train_loss: 0.2482 | train_auc: 0.9891 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [400 / 1130] avg_train_loss: 0.2946 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [500 / 1130] avg_train_loss: 0.2794 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [600 / 1130] avg_train_loss: 0.2827 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [700 / 1130] avg_train_loss: 0.2858 | train_auc: 0.977 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [800 / 1130] avg_train_loss: 0.2822 | train_auc: 0.9763 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [900 / 1130] avg_train_loss: 0.2781 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [1000 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [170 / 200] Step: [1100 / 1130] avg_train_loss: 0.2744 | train_auc: 0.9795 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 170 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.132 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1366 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3917 | val_auc: 0.7407 | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6498 | val_auc: 0.702 | lr: 7.289999999999999e-09
[Epoch: 170 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7553 | val_auc: 0.7438 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 171
[TRAIN] Train model
Epoch [171 / 200] Step: [100 / 1130] avg_train_loss: 0.2882 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [200 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [300 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9868 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [400 / 1130] avg_train_loss: 0.2674 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [500 / 1130] avg_train_loss: 0.2562 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [600 / 1130] avg_train_loss: 0.2615 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [700 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [800 / 1130] avg_train_loss: 0.2744 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [900 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [1000 / 1130] avg_train_loss: 0.268 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [171 / 200] Step: [1100 / 1130] avg_train_loss: 0.2711 | train_auc: 0.9811 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 171 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1787 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.18 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4106 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.638 | val_auc: 0.6545 | lr: 7.289999999999999e-09
[Epoch: 171 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7166 | val_auc: 0.7215 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 172
[TRAIN] Train model
Epoch [172 / 200] Step: [100 / 1130] avg_train_loss: 0.1609 | train_auc: 0.9991 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [200 / 1130] avg_train_loss: 0.2263 | train_auc: 0.9886 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [300 / 1130] avg_train_loss: 0.2443 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [400 / 1130] avg_train_loss: 0.2538 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [500 / 1130] avg_train_loss: 0.257 | train_auc: 0.9839 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [600 / 1130] avg_train_loss: 0.2739 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [700 / 1130] avg_train_loss: 0.2793 | train_auc: 0.9786 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [800 / 1130] avg_train_loss: 0.2811 | train_auc: 0.9767 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [900 / 1130] avg_train_loss: 0.2788 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [1000 / 1130] avg_train_loss: 0.2858 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [172 / 200] Step: [1100 / 1130] avg_train_loss: 0.2804 | train_auc: 0.9761 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 172 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1845 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1775 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4197 | val_auc: 0.6984 | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6423 | val_auc: 0.6825 | lr: 7.289999999999999e-09
[Epoch: 172 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7196 | val_auc: 0.7362 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 173
[TRAIN] Train model
Epoch [173 / 200] Step: [100 / 1130] avg_train_loss: 0.2516 | train_auc: 0.99 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [200 / 1130] avg_train_loss: 0.2631 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [300 / 1130] avg_train_loss: 0.2622 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [400 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [500 / 1130] avg_train_loss: 0.2754 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [600 / 1130] avg_train_loss: 0.2803 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [700 / 1130] avg_train_loss: 0.2896 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [800 / 1130] avg_train_loss: 0.2897 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [900 / 1130] avg_train_loss: 0.3001 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [1000 / 1130] avg_train_loss: 0.3031 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [173 / 200] Step: [1100 / 1130] avg_train_loss: 0.308 | train_auc: 0.9717 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 173 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2158 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1997 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4449 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.683 | val_auc: 0.6367 | lr: 7.289999999999999e-09
[Epoch: 173 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7692 | val_auc: 0.6939 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 174
[TRAIN] Train model
Epoch [174 / 200] Step: [100 / 1130] avg_train_loss: 0.2863 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [200 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [300 / 1130] avg_train_loss: 0.2729 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [400 / 1130] avg_train_loss: 0.2626 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [500 / 1130] avg_train_loss: 0.2612 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [600 / 1130] avg_train_loss: 0.2738 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [700 / 1130] avg_train_loss: 0.2702 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [800 / 1130] avg_train_loss: 0.2739 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [900 / 1130] avg_train_loss: 0.2763 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [1000 / 1130] avg_train_loss: 0.281 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [174 / 200] Step: [1100 / 1130] avg_train_loss: 0.2872 | train_auc: 0.9773 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 174 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1517 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1488 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4477 | val_auc: 0.627 | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6839 | val_auc: 0.6698 | lr: 7.289999999999999e-09
[Epoch: 174 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7838 | val_auc: 0.7117 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 175
[TRAIN] Train model
Epoch [175 / 200] Step: [100 / 1130] avg_train_loss: 0.2693 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [200 / 1130] avg_train_loss: 0.2465 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [300 / 1130] avg_train_loss: 0.2588 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [400 / 1130] avg_train_loss: 0.2601 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [500 / 1130] avg_train_loss: 0.2701 | train_auc: 0.9794 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [600 / 1130] avg_train_loss: 0.2758 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [700 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [800 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [900 / 1130] avg_train_loss: 0.2774 | train_auc: 0.9782 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [1000 / 1130] avg_train_loss: 0.2755 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [175 / 200] Step: [1100 / 1130] avg_train_loss: 0.2776 | train_auc: 0.9779 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 175 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3161 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2889 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.482 | val_auc: 0.6561 | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6784 | val_auc: 0.6273 | lr: 7.289999999999999e-09
[Epoch: 175 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7333 | val_auc: 0.6889 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 176
[TRAIN] Train model
Epoch [176 / 200] Step: [100 / 1130] avg_train_loss: 0.3195 | train_auc: 0.962 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [200 / 1130] avg_train_loss: 0.3008 | train_auc: 0.9716 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [300 / 1130] avg_train_loss: 0.2927 | train_auc: 0.9724 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [400 / 1130] avg_train_loss: 0.2777 | train_auc: 0.9764 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [500 / 1130] avg_train_loss: 0.2695 | train_auc: 0.9784 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [600 / 1130] avg_train_loss: 0.2785 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [700 / 1130] avg_train_loss: 0.2718 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [800 / 1130] avg_train_loss: 0.2754 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [900 / 1130] avg_train_loss: 0.2704 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [1000 / 1130] avg_train_loss: 0.271 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [176 / 200] Step: [1100 / 1130] avg_train_loss: 0.2699 | train_auc: 0.9792 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 176 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1393 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1457 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3959 | val_auc: 0.7513 | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6327 | val_auc: 0.7131 | lr: 7.289999999999999e-09
[Epoch: 176 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7255 | val_auc: 0.7611 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 177
[TRAIN] Train model
Epoch [177 / 200] Step: [100 / 1130] avg_train_loss: 0.3072 | train_auc: 0.9657 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [200 / 1130] avg_train_loss: 0.2544 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [300 / 1130] avg_train_loss: 0.2505 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [400 / 1130] avg_train_loss: 0.2396 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [500 / 1130] avg_train_loss: 0.2532 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [600 / 1130] avg_train_loss: 0.2494 | train_auc: 0.9846 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [700 / 1130] avg_train_loss: 0.2445 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [800 / 1130] avg_train_loss: 0.2457 | train_auc: 0.9857 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [900 / 1130] avg_train_loss: 0.2523 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [1000 / 1130] avg_train_loss: 0.2575 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [177 / 200] Step: [1100 / 1130] avg_train_loss: 0.2546 | train_auc: 0.9832 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 177 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1673 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1592 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3998 | val_auc: 0.7249 | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6562 | val_auc: 0.6766 | lr: 7.289999999999999e-09
[Epoch: 177 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7762 | val_auc: 0.7219 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 178
[TRAIN] Train model
Epoch [178 / 200] Step: [100 / 1130] avg_train_loss: 0.232 | train_auc: 0.9905 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [200 / 1130] avg_train_loss: 0.2182 | train_auc: 0.9915 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [300 / 1130] avg_train_loss: 0.2481 | train_auc: 0.9867 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [400 / 1130] avg_train_loss: 0.2686 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [500 / 1130] avg_train_loss: 0.2656 | train_auc: 0.9828 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [600 / 1130] avg_train_loss: 0.2615 | train_auc: 0.9833 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [700 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [800 / 1130] avg_train_loss: 0.2598 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [900 / 1130] avg_train_loss: 0.2564 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [1000 / 1130] avg_train_loss: 0.2644 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [178 / 200] Step: [1100 / 1130] avg_train_loss: 0.269 | train_auc: 0.9819 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 178 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2925 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2684 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4889 | val_auc: 0.6323 | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.682 | val_auc: 0.6188 | lr: 7.289999999999999e-09
[Epoch: 178 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7142 | val_auc: 0.7019 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 179
[TRAIN] Train model
Epoch [179 / 200] Step: [100 / 1130] avg_train_loss: 0.2909 | train_auc: 0.9795 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [200 / 1130] avg_train_loss: 0.2704 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [300 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9832 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [400 / 1130] avg_train_loss: 0.2642 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [500 / 1130] avg_train_loss: 0.2698 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [600 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [700 / 1130] avg_train_loss: 0.2668 | train_auc: 0.9823 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [800 / 1130] avg_train_loss: 0.2675 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [900 / 1130] avg_train_loss: 0.2656 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [1000 / 1130] avg_train_loss: 0.2669 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [179 / 200] Step: [1100 / 1130] avg_train_loss: 0.264 | train_auc: 0.9821 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 179 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2506 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2383 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.454 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6479 | val_auc: 0.6503 | lr: 7.289999999999999e-09
[Epoch: 179 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7112 | val_auc: 0.7117 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 180
[TRAIN] Train model
Epoch [180 / 200] Step: [100 / 1130] avg_train_loss: 0.3079 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [200 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [300 / 1130] avg_train_loss: 0.2842 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [400 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [500 / 1130] avg_train_loss: 0.2911 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [600 / 1130] avg_train_loss: 0.2876 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [700 / 1130] avg_train_loss: 0.2818 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [800 / 1130] avg_train_loss: 0.2889 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [900 / 1130] avg_train_loss: 0.2858 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [1000 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [180 / 200] Step: [1100 / 1130] avg_train_loss: 0.2805 | train_auc: 0.9763 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 180 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1637 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1707 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4325 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6594 | val_auc: 0.6859 | lr: 7.289999999999999e-09
[Epoch: 180 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7409 | val_auc: 0.734 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 181
[TRAIN] Train model
Epoch [181 / 200] Step: [100 / 1130] avg_train_loss: 0.218 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [200 / 1130] avg_train_loss: 0.2341 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [300 / 1130] avg_train_loss: 0.2226 | train_auc: 0.9909 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [400 / 1130] avg_train_loss: 0.2293 | train_auc: 0.9893 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [500 / 1130] avg_train_loss: 0.2423 | train_auc: 0.9858 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [600 / 1130] avg_train_loss: 0.2477 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [700 / 1130] avg_train_loss: 0.2524 | train_auc: 0.9835 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [800 / 1130] avg_train_loss: 0.2491 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [900 / 1130] avg_train_loss: 0.2463 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [1000 / 1130] avg_train_loss: 0.2561 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [181 / 200] Step: [1100 / 1130] avg_train_loss: 0.2637 | train_auc: 0.9812 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 181 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1582 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.16 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4096 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6371 | val_auc: 0.6893 | lr: 7.289999999999999e-09
[Epoch: 181 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7086 | val_auc: 0.7536 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 182
[TRAIN] Train model
Epoch [182 / 200] Step: [100 / 1130] avg_train_loss: 0.37 | train_auc: 0.9574 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [200 / 1130] avg_train_loss: 0.3394 | train_auc: 0.968 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [300 / 1130] avg_train_loss: 0.3327 | train_auc: 0.9674 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [400 / 1130] avg_train_loss: 0.319 | train_auc: 0.9706 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [500 / 1130] avg_train_loss: 0.308 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [600 / 1130] avg_train_loss: 0.3015 | train_auc: 0.9736 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [700 / 1130] avg_train_loss: 0.2967 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [800 / 1130] avg_train_loss: 0.2922 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [900 / 1130] avg_train_loss: 0.2915 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [1000 / 1130] avg_train_loss: 0.2884 | train_auc: 0.9743 | lr : 7.289999999999999e-09
Epoch [182 / 200] Step: [1100 / 1130] avg_train_loss: 0.2885 | train_auc: 0.9743 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 182 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1431 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1399 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4059 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6706 | val_auc: 0.6817 | lr: 7.289999999999999e-09
[Epoch: 182 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.769 | val_auc: 0.7357 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 183
[TRAIN] Train model
Epoch [183 / 200] Step: [100 / 1130] avg_train_loss: 0.2955 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [200 / 1130] avg_train_loss: 0.3116 | train_auc: 0.9712 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [300 / 1130] avg_train_loss: 0.3151 | train_auc: 0.9725 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [400 / 1130] avg_train_loss: 0.3159 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [500 / 1130] avg_train_loss: 0.2955 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [600 / 1130] avg_train_loss: 0.3036 | train_auc: 0.975 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [700 / 1130] avg_train_loss: 0.3053 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [800 / 1130] avg_train_loss: 0.313 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [900 / 1130] avg_train_loss: 0.3036 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [1000 / 1130] avg_train_loss: 0.3096 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [183 / 200] Step: [1100 / 1130] avg_train_loss: 0.302 | train_auc: 0.9749 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 183 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.186 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1958 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4424 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.667 | val_auc: 0.6477 | lr: 7.289999999999999e-09
[Epoch: 183 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7391 | val_auc: 0.7152 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 184
[TRAIN] Train model
Epoch [184 / 200] Step: [100 / 1130] avg_train_loss: 0.2816 | train_auc: 0.9615 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [200 / 1130] avg_train_loss: 0.2401 | train_auc: 0.981 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [300 / 1130] avg_train_loss: 0.2684 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [400 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [500 / 1130] avg_train_loss: 0.2826 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [600 / 1130] avg_train_loss: 0.281 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [700 / 1130] avg_train_loss: 0.2763 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [800 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9781 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [900 / 1130] avg_train_loss: 0.2769 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [1000 / 1130] avg_train_loss: 0.2789 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [184 / 200] Step: [1100 / 1130] avg_train_loss: 0.286 | train_auc: 0.9776 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 184 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1903 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1991 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4471 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.661 | val_auc: 0.657 | lr: 7.289999999999999e-09
[Epoch: 184 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7172 | val_auc: 0.7228 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 185
[TRAIN] Train model
Epoch [185 / 200] Step: [100 / 1130] avg_train_loss: 0.2184 | train_auc: 0.9921 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [200 / 1130] avg_train_loss: 0.2454 | train_auc: 0.9865 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [300 / 1130] avg_train_loss: 0.2882 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [400 / 1130] avg_train_loss: 0.2814 | train_auc: 0.9808 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [500 / 1130] avg_train_loss: 0.2571 | train_auc: 0.985 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [600 / 1130] avg_train_loss: 0.2556 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [700 / 1130] avg_train_loss: 0.2535 | train_auc: 0.9856 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [800 / 1130] avg_train_loss: 0.2547 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [900 / 1130] avg_train_loss: 0.2683 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [1000 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [185 / 200] Step: [1100 / 1130] avg_train_loss: 0.2843 | train_auc: 0.9774 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 185 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.126 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.119 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4064 | val_auc: 0.6878 | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6954 | val_auc: 0.6808 | lr: 7.289999999999999e-09
[Epoch: 185 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8284 | val_auc: 0.7259 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 186
[TRAIN] Train model
Epoch [186 / 200] Step: [100 / 1130] avg_train_loss: 0.4123 | train_auc: 0.947 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [200 / 1130] avg_train_loss: 0.3135 | train_auc: 0.9732 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [300 / 1130] avg_train_loss: 0.336 | train_auc: 0.9677 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [400 / 1130] avg_train_loss: 0.3238 | train_auc: 0.97 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [500 / 1130] avg_train_loss: 0.3081 | train_auc: 0.9722 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [600 / 1130] avg_train_loss: 0.322 | train_auc: 0.9691 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [700 / 1130] avg_train_loss: 0.3301 | train_auc: 0.9663 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [800 / 1130] avg_train_loss: 0.3138 | train_auc: 0.9696 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [900 / 1130] avg_train_loss: 0.3146 | train_auc: 0.9698 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [1000 / 1130] avg_train_loss: 0.3069 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [186 / 200] Step: [1100 / 1130] avg_train_loss: 0.3035 | train_auc: 0.9732 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 186 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1593 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1524 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.399 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6432 | val_auc: 0.6902 | lr: 7.289999999999999e-09
[Epoch: 186 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7337 | val_auc: 0.738 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 187
[TRAIN] Train model
Epoch [187 / 200] Step: [100 / 1130] avg_train_loss: 0.2573 | train_auc: 0.9851 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [200 / 1130] avg_train_loss: 0.2418 | train_auc: 0.9864 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [300 / 1130] avg_train_loss: 0.2367 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [400 / 1130] avg_train_loss: 0.2322 | train_auc: 0.9897 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [500 / 1130] avg_train_loss: 0.2458 | train_auc: 0.987 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [600 / 1130] avg_train_loss: 0.2542 | train_auc: 0.9854 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [700 / 1130] avg_train_loss: 0.2618 | train_auc: 0.9838 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [800 / 1130] avg_train_loss: 0.259 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [900 / 1130] avg_train_loss: 0.2641 | train_auc: 0.9836 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [1000 / 1130] avg_train_loss: 0.2655 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [187 / 200] Step: [1100 / 1130] avg_train_loss: 0.2588 | train_auc: 0.9845 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 187 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2049 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1862 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4451 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.666 | val_auc: 0.6698 | lr: 7.289999999999999e-09
[Epoch: 187 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7319 | val_auc: 0.7313 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 188
[TRAIN] Train model
Epoch [188 / 200] Step: [100 / 1130] avg_train_loss: 0.3211 | train_auc: 0.9544 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [200 / 1130] avg_train_loss: 0.285 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [300 / 1130] avg_train_loss: 0.2609 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [400 / 1130] avg_train_loss: 0.2862 | train_auc: 0.9733 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [500 / 1130] avg_train_loss: 0.2748 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [600 / 1130] avg_train_loss: 0.2664 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [700 / 1130] avg_train_loss: 0.2577 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [800 / 1130] avg_train_loss: 0.2784 | train_auc: 0.9757 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [900 / 1130] avg_train_loss: 0.2825 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [1000 / 1130] avg_train_loss: 0.2776 | train_auc: 0.9779 | lr : 7.289999999999999e-09
Epoch [188 / 200] Step: [1100 / 1130] avg_train_loss: 0.2771 | train_auc: 0.9782 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 188 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.224 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.214 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4395 | val_auc: 0.6799 | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.658 | val_auc: 0.6503 | lr: 7.289999999999999e-09
[Epoch: 188 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7446 | val_auc: 0.6979 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 189
[TRAIN] Train model
Epoch [189 / 200] Step: [100 / 1130] avg_train_loss: 0.2048 | train_auc: 0.9925 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [200 / 1130] avg_train_loss: 0.2752 | train_auc: 0.9745 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [300 / 1130] avg_train_loss: 0.2613 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [400 / 1130] avg_train_loss: 0.2792 | train_auc: 0.9762 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [500 / 1130] avg_train_loss: 0.2709 | train_auc: 0.9792 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [600 / 1130] avg_train_loss: 0.2665 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [700 / 1130] avg_train_loss: 0.2651 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [800 / 1130] avg_train_loss: 0.2802 | train_auc: 0.9787 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [900 / 1130] avg_train_loss: 0.2852 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [1000 / 1130] avg_train_loss: 0.2805 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [189 / 200] Step: [1100 / 1130] avg_train_loss: 0.28 | train_auc: 0.9794 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 189 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2611 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2242 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4464 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6685 | val_auc: 0.6621 | lr: 7.289999999999999e-09
[Epoch: 189 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7431 | val_auc: 0.7179 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 190
[TRAIN] Train model
Epoch [190 / 200] Step: [100 / 1130] avg_train_loss: 0.2744 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [200 / 1130] avg_train_loss: 0.2987 | train_auc: 0.9744 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [300 / 1130] avg_train_loss: 0.3076 | train_auc: 0.9693 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [400 / 1130] avg_train_loss: 0.3002 | train_auc: 0.9731 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [500 / 1130] avg_train_loss: 0.2824 | train_auc: 0.9776 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [600 / 1130] avg_train_loss: 0.2726 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [700 / 1130] avg_train_loss: 0.2761 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [800 / 1130] avg_train_loss: 0.2765 | train_auc: 0.9806 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [900 / 1130] avg_train_loss: 0.2815 | train_auc: 0.9798 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [1000 / 1130] avg_train_loss: 0.2795 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [190 / 200] Step: [1100 / 1130] avg_train_loss: 0.2747 | train_auc: 0.9804 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 190 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.0937 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.0957 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.41 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.7162 | val_auc: 0.7207 | lr: 7.289999999999999e-09
[Epoch: 190 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.8686 | val_auc: 0.7607 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 191
[TRAIN] Train model
Epoch [191 / 200] Step: [100 / 1130] avg_train_loss: 0.2414 | train_auc: 0.9816 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [200 / 1130] avg_train_loss: 0.2261 | train_auc: 0.986 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [300 / 1130] avg_train_loss: 0.2434 | train_auc: 0.9847 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [400 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9814 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [500 / 1130] avg_train_loss: 0.267 | train_auc: 0.9791 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [600 / 1130] avg_train_loss: 0.2602 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [700 / 1130] avg_train_loss: 0.2572 | train_auc: 0.9815 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [800 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9827 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [900 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9818 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [1000 / 1130] avg_train_loss: 0.2618 | train_auc: 0.9822 | lr : 7.289999999999999e-09
Epoch [191 / 200] Step: [1100 / 1130] avg_train_loss: 0.2622 | train_auc: 0.9816 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 191 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1511 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1536 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.3942 | val_auc: 0.754 | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6314 | val_auc: 0.7037 | lr: 7.289999999999999e-09
[Epoch: 191 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7362 | val_auc: 0.7424 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 192
[TRAIN] Train model
Epoch [192 / 200] Step: [100 / 1130] avg_train_loss: 0.2525 | train_auc: 0.9852 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [200 / 1130] avg_train_loss: 0.27 | train_auc: 0.9807 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [300 / 1130] avg_train_loss: 0.278 | train_auc: 0.9772 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [400 / 1130] avg_train_loss: 0.276 | train_auc: 0.9774 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [500 / 1130] avg_train_loss: 0.2624 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [600 / 1130] avg_train_loss: 0.2623 | train_auc: 0.9819 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [700 / 1130] avg_train_loss: 0.277 | train_auc: 0.9773 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [800 / 1130] avg_train_loss: 0.2809 | train_auc: 0.9759 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [900 / 1130] avg_train_loss: 0.2813 | train_auc: 0.9746 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [1000 / 1130] avg_train_loss: 0.283 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [192 / 200] Step: [1100 / 1130] avg_train_loss: 0.2856 | train_auc: 0.9735 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 192 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1577 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1612 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4514 | val_auc: 0.6455 | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.669 | val_auc: 0.6834 | lr: 7.289999999999999e-09
[Epoch: 192 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7521 | val_auc: 0.7348 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 193
[TRAIN] Train model
Epoch [193 / 200] Step: [100 / 1130] avg_train_loss: 0.272 | train_auc: 0.9855 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [200 / 1130] avg_train_loss: 0.2773 | train_auc: 0.9801 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [300 / 1130] avg_train_loss: 0.2597 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [400 / 1130] avg_train_loss: 0.237 | train_auc: 0.9875 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [500 / 1130] avg_train_loss: 0.2601 | train_auc: 0.9837 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [600 / 1130] avg_train_loss: 0.2545 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [700 / 1130] avg_train_loss: 0.2592 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [800 / 1130] avg_train_loss: 0.2608 | train_auc: 0.9843 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [900 / 1130] avg_train_loss: 0.2603 | train_auc: 0.984 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [1000 / 1130] avg_train_loss: 0.2621 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [193 / 200] Step: [1100 / 1130] avg_train_loss: 0.2641 | train_auc: 0.9837 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 193 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1748 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1713 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4555 | val_auc: 0.6323 | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6734 | val_auc: 0.6672 | lr: 7.289999999999999e-09
[Epoch: 193 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7492 | val_auc: 0.7273 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 194
[TRAIN] Train model
Epoch [194 / 200] Step: [100 / 1130] avg_train_loss: 0.3053 | train_auc: 0.9693 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [200 / 1130] avg_train_loss: 0.2646 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [300 / 1130] avg_train_loss: 0.2661 | train_auc: 0.98 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [400 / 1130] avg_train_loss: 0.2783 | train_auc: 0.9778 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [500 / 1130] avg_train_loss: 0.2743 | train_auc: 0.9793 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [600 / 1130] avg_train_loss: 0.265 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [700 / 1130] avg_train_loss: 0.254 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [800 / 1130] avg_train_loss: 0.2509 | train_auc: 0.9844 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [900 / 1130] avg_train_loss: 0.2688 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [1000 / 1130] avg_train_loss: 0.2627 | train_auc: 0.9817 | lr : 7.289999999999999e-09
Epoch [194 / 200] Step: [1100 / 1130] avg_train_loss: 0.2704 | train_auc: 0.9803 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 194 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.3106 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.276 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4786 | val_auc: 0.6429 | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6815 | val_auc: 0.6197 | lr: 7.289999999999999e-09
[Epoch: 194 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7386 | val_auc: 0.6858 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 195
[TRAIN] Train model
Epoch [195 / 200] Step: [100 / 1130] avg_train_loss: 0.2044 | train_auc: 0.9906 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [200 / 1130] avg_train_loss: 0.2336 | train_auc: 0.9885 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [300 / 1130] avg_train_loss: 0.2253 | train_auc: 0.9912 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [400 / 1130] avg_train_loss: 0.225 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [500 / 1130] avg_train_loss: 0.237 | train_auc: 0.9878 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [600 / 1130] avg_train_loss: 0.2358 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [700 / 1130] avg_train_loss: 0.2577 | train_auc: 0.9829 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [800 / 1130] avg_train_loss: 0.2563 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [900 / 1130] avg_train_loss: 0.2608 | train_auc: 0.9826 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [1000 / 1130] avg_train_loss: 0.2686 | train_auc: 0.9812 | lr : 7.289999999999999e-09
Epoch [195 / 200] Step: [1100 / 1130] avg_train_loss: 0.2736 | train_auc: 0.9802 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 195 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1714 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1745 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4046 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6299 | val_auc: 0.6961 | lr: 7.289999999999999e-09
[Epoch: 195 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7251 | val_auc: 0.7375 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 196
[TRAIN] Train model
Epoch [196 / 200] Step: [100 / 1130] avg_train_loss: 0.3399 | train_auc: 0.9568 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [200 / 1130] avg_train_loss: 0.3193 | train_auc: 0.9674 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [300 / 1130] avg_train_loss: 0.2667 | train_auc: 0.9785 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [400 / 1130] avg_train_loss: 0.2865 | train_auc: 0.9734 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [500 / 1130] avg_train_loss: 0.2874 | train_auc: 0.9751 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [600 / 1130] avg_train_loss: 0.2935 | train_auc: 0.9742 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [700 / 1130] avg_train_loss: 0.2959 | train_auc: 0.9748 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [800 / 1130] avg_train_loss: 0.2887 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [900 / 1130] avg_train_loss: 0.2821 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [1000 / 1130] avg_train_loss: 0.2761 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [196 / 200] Step: [1100 / 1130] avg_train_loss: 0.2814 | train_auc: 0.979 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 196 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2003 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1944 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4309 | val_auc: 0.7143 | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6495 | val_auc: 0.6851 | lr: 7.289999999999999e-09
[Epoch: 196 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7117 | val_auc: 0.7424 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 197
[TRAIN] Train model
Epoch [197 / 200] Step: [100 / 1130] avg_train_loss: 0.1985 | train_auc: 0.991 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [200 / 1130] avg_train_loss: 0.2201 | train_auc: 0.9904 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [300 / 1130] avg_train_loss: 0.2459 | train_auc: 0.9842 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [400 / 1130] avg_train_loss: 0.2468 | train_auc: 0.9849 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [500 / 1130] avg_train_loss: 0.2672 | train_auc: 0.9802 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [600 / 1130] avg_train_loss: 0.2709 | train_auc: 0.9797 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [700 / 1130] avg_train_loss: 0.2724 | train_auc: 0.9796 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [800 / 1130] avg_train_loss: 0.2731 | train_auc: 0.9788 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [900 / 1130] avg_train_loss: 0.2797 | train_auc: 0.978 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [1000 / 1130] avg_train_loss: 0.2782 | train_auc: 0.9783 | lr : 7.289999999999999e-09
Epoch [197 / 200] Step: [1100 / 1130] avg_train_loss: 0.2736 | train_auc: 0.9793 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 197 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2252 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2147 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.457 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6854 | val_auc: 0.6248 | lr: 7.289999999999999e-09
[Epoch: 197 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7395 | val_auc: 0.6979 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 198
[TRAIN] Train model
Epoch [198 / 200] Step: [100 / 1130] avg_train_loss: 0.3154 | train_auc: 0.9643 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [200 / 1130] avg_train_loss: 0.2674 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [300 / 1130] avg_train_loss: 0.2603 | train_auc: 0.982 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [400 / 1130] avg_train_loss: 0.2551 | train_auc: 0.9834 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [500 / 1130] avg_train_loss: 0.2917 | train_auc: 0.9747 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [600 / 1130] avg_train_loss: 0.2818 | train_auc: 0.9775 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [700 / 1130] avg_train_loss: 0.2875 | train_auc: 0.976 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [800 / 1130] avg_train_loss: 0.2913 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [900 / 1130] avg_train_loss: 0.2878 | train_auc: 0.9753 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [1000 / 1130] avg_train_loss: 0.2828 | train_auc: 0.9766 | lr : 7.289999999999999e-09
Epoch [198 / 200] Step: [1100 / 1130] avg_train_loss: 0.28 | train_auc: 0.9777 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 198 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.1372 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.139 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4115 | val_auc: 0.6905 | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.665 | val_auc: 0.6952 | lr: 7.289999999999999e-09
[Epoch: 198 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7777 | val_auc: 0.7389 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 199
[TRAIN] Train model
Epoch [199 / 200] Step: [100 / 1130] avg_train_loss: 0.317 | train_auc: 0.9719 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [200 / 1130] avg_train_loss: 0.2567 | train_auc: 0.9841 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [300 / 1130] avg_train_loss: 0.2759 | train_auc: 0.9804 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [400 / 1130] avg_train_loss: 0.2986 | train_auc: 0.9737 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [500 / 1130] avg_train_loss: 0.3071 | train_auc: 0.9723 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [600 / 1130] avg_train_loss: 0.2963 | train_auc: 0.9749 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [700 / 1130] avg_train_loss: 0.293 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [800 / 1130] avg_train_loss: 0.2867 | train_auc: 0.9768 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [900 / 1130] avg_train_loss: 0.2955 | train_auc: 0.9754 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [1000 / 1130] avg_train_loss: 0.3028 | train_auc: 0.9729 | lr : 7.289999999999999e-09
Epoch [199 / 200] Step: [1100 / 1130] avg_train_loss: 0.2989 | train_auc: 0.9737 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 199 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2035 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.1936 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4358 | val_auc: 0.672 | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6673 | val_auc: 0.652 | lr: 7.289999999999999e-09
[Epoch: 199 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.7557 | val_auc: 0.7028 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 200
[TRAIN] Train model
Epoch [200 / 200] Step: [100 / 1130] avg_train_loss: 0.2198 | train_auc: 0.9928 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [200 / 1130] avg_train_loss: 0.2439 | train_auc: 0.9872 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [300 / 1130] avg_train_loss: 0.2596 | train_auc: 0.983 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [400 / 1130] avg_train_loss: 0.2932 | train_auc: 0.9741 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [500 / 1130] avg_train_loss: 0.286 | train_auc: 0.9756 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [600 / 1130] avg_train_loss: 0.2869 | train_auc: 0.9761 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [700 / 1130] avg_train_loss: 0.2864 | train_auc: 0.9769 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [800 / 1130] avg_train_loss: 0.2751 | train_auc: 0.9789 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [900 / 1130] avg_train_loss: 0.2703 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [1000 / 1130] avg_train_loss: 0.2724 | train_auc: 0.9799 | lr : 7.289999999999999e-09
Epoch [200 / 200] Step: [1100 / 1130] avg_train_loss: 0.2818 | train_auc: 0.9769 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 200 / 200 | Single batch number: 20 / 120] avg_val_loss: 0.2462 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 40 / 120] avg_val_loss: 0.2356 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 60 / 120] avg_val_loss: 0.4567 | val_auc: 0.6958 | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 80 / 120] avg_val_loss: 0.6431 | val_auc: 0.6698 | lr: 7.289999999999999e-09
[Epoch: 200 / 200 | Single batch number: 100 / 120] avg_val_loss: 0.6667 | val_auc: 0.7438 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[INFO] Execution duration: 327.00 minutes 54.72 seconds
Completed Meniscus Coronal Training
---------------------------------
Starting Meniscus Sagittal Training...
[SEED] Setting seeds for reproducibility...
src/models-to-submit/pretrained
[TRAIN] Creating logs folder: "./logs/20250311-104052_meniscus_sagittal"
[TRAIN] Loading Data Loaders
[DATALOADER] __init__ task: meniscus, plane: sagittal, train: train
[DATALOADER] __init__ weights: [1, 1.8463476070528968]
[DATALOADER] __init__ task: meniscus, plane: sagittal, train: valid
[DATALOADER] __init__ weights: [1, 1.3076923076923077]
[TRAIN] Instantiate Model
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[TRAIN] Defining Optimizer
[TRAIN] Starting Training!
[TRAIN] Epochs = 100
[TRAIN] EPOCH # 1
[TRAIN] Train model
Epoch [1 / 100] Step: [100 / 1130] avg_train_loss: 1.0014 | train_auc: 0.5218 | lr : 1e-05
Epoch [1 / 100] Step: [200 / 1130] avg_train_loss: 0.9777 | train_auc: 0.5208 | lr : 1e-05
Epoch [1 / 100] Step: [300 / 1130] avg_train_loss: 0.9582 | train_auc: 0.522 | lr : 1e-05
Epoch [1 / 100] Step: [400 / 1130] avg_train_loss: 0.9542 | train_auc: 0.5055 | lr : 1e-05
Epoch [1 / 100] Step: [500 / 1130] avg_train_loss: 0.9484 | train_auc: 0.4988 | lr : 1e-05
Epoch [1 / 100] Step: [600 / 1130] avg_train_loss: 0.9426 | train_auc: 0.5025 | lr : 1e-05
Epoch [1 / 100] Step: [700 / 1130] avg_train_loss: 0.9358 | train_auc: 0.5135 | lr : 1e-05
Epoch [1 / 100] Step: [800 / 1130] avg_train_loss: 0.9332 | train_auc: 0.5072 | lr : 1e-05
Epoch [1 / 100] Step: [900 / 1130] avg_train_loss: 0.9268 | train_auc: 0.5157 | lr : 1e-05
Epoch [1 / 100] Step: [1000 / 1130] avg_train_loss: 0.9261 | train_auc: 0.5133 | lr : 1e-05
Epoch [1 / 100] Step: [1100 / 1130] avg_train_loss: 0.9247 | train_auc: 0.5173 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 1 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.6632 | val_auc: nan | lr: 1e-05
[Epoch: 1 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.6856 | val_auc: nan | lr: 1e-05
[Epoch: 1 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.7118 | val_auc: 0.4471 | lr: 1e-05
[Epoch: 1 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7438 | val_auc: 0.4431 | lr: 1e-05
[Epoch: 1 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7538 | val_auc: 0.5561 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_sagittal_train_auc_0.5179_val_auc_0.6162_train_loss_0.9241_val_loss_0.7712_epoch_1_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.9.pth"
[TRAIN] EPOCH # 2
[TRAIN] Train model
Epoch [2 / 100] Step: [100 / 1130] avg_train_loss: 0.8947 | train_auc: 0.5762 | lr : 1e-05
Epoch [2 / 100] Step: [200 / 1130] avg_train_loss: 0.8939 | train_auc: 0.5618 | lr : 1e-05
Epoch [2 / 100] Step: [300 / 1130] avg_train_loss: 0.8977 | train_auc: 0.5753 | lr : 1e-05
Epoch [2 / 100] Step: [400 / 1130] avg_train_loss: 0.8936 | train_auc: 0.565 | lr : 1e-05
Epoch [2 / 100] Step: [500 / 1130] avg_train_loss: 0.8946 | train_auc: 0.5649 | lr : 1e-05
Epoch [2 / 100] Step: [600 / 1130] avg_train_loss: 0.9016 | train_auc: 0.5544 | lr : 1e-05
Epoch [2 / 100] Step: [700 / 1130] avg_train_loss: 0.9007 | train_auc: 0.5699 | lr : 1e-05
Epoch [2 / 100] Step: [800 / 1130] avg_train_loss: 0.9012 | train_auc: 0.574 | lr : 1e-05
Epoch [2 / 100] Step: [900 / 1130] avg_train_loss: 0.895 | train_auc: 0.585 | lr : 1e-05
Epoch [2 / 100] Step: [1000 / 1130] avg_train_loss: 0.8914 | train_auc: 0.5945 | lr : 1e-05
Epoch [2 / 100] Step: [1100 / 1130] avg_train_loss: 0.8834 | train_auc: 0.6101 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 2 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.5546 | val_auc: nan | lr: 1e-05
[Epoch: 2 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5397 | val_auc: nan | lr: 1e-05
[Epoch: 2 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6144 | val_auc: 0.4868 | lr: 1e-05
[Epoch: 2 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6918 | val_auc: 0.4677 | lr: 1e-05
[Epoch: 2 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.742 | val_auc: 0.5258 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 3
[TRAIN] Train model
Epoch [3 / 100] Step: [100 / 1130] avg_train_loss: 0.8347 | train_auc: 0.7115 | lr : 1e-05
Epoch [3 / 100] Step: [200 / 1130] avg_train_loss: 0.8698 | train_auc: 0.673 | lr : 1e-05
Epoch [3 / 100] Step: [300 / 1130] avg_train_loss: 0.8587 | train_auc: 0.694 | lr : 1e-05
Epoch [3 / 100] Step: [400 / 1130] avg_train_loss: 0.853 | train_auc: 0.7034 | lr : 1e-05
Epoch [3 / 100] Step: [500 / 1130] avg_train_loss: 0.8504 | train_auc: 0.7058 | lr : 1e-05
Epoch [3 / 100] Step: [600 / 1130] avg_train_loss: 0.8461 | train_auc: 0.7097 | lr : 1e-05
Epoch [3 / 100] Step: [700 / 1130] avg_train_loss: 0.8508 | train_auc: 0.6937 | lr : 1e-05
Epoch [3 / 100] Step: [800 / 1130] avg_train_loss: 0.8449 | train_auc: 0.7009 | lr : 1e-05
Epoch [3 / 100] Step: [900 / 1130] avg_train_loss: 0.8448 | train_auc: 0.6953 | lr : 1e-05
Epoch [3 / 100] Step: [1000 / 1130] avg_train_loss: 0.8384 | train_auc: 0.6975 | lr : 1e-05
Epoch [3 / 100] Step: [1100 / 1130] avg_train_loss: 0.8378 | train_auc: 0.6935 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 3 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4341 | val_auc: nan | lr: 1e-05
[Epoch: 3 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4281 | val_auc: nan | lr: 1e-05
[Epoch: 3 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5328 | val_auc: 0.6376 | lr: 1e-05
[Epoch: 3 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6456 | val_auc: 0.618 | lr: 1e-05
[Epoch: 3 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7186 | val_auc: 0.6671 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_sagittal_train_auc_0.6881_val_auc_0.6374_train_loss_0.8405_val_loss_0.8142_epoch_3_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.9.pth"
[TRAIN] EPOCH # 4
[TRAIN] Train model
Epoch [4 / 100] Step: [100 / 1130] avg_train_loss: 0.7885 | train_auc: 0.7409 | lr : 1e-05
Epoch [4 / 100] Step: [200 / 1130] avg_train_loss: 0.7688 | train_auc: 0.7643 | lr : 1e-05
Epoch [4 / 100] Step: [300 / 1130] avg_train_loss: 0.7725 | train_auc: 0.7206 | lr : 1e-05
Epoch [4 / 100] Step: [400 / 1130] avg_train_loss: 0.7832 | train_auc: 0.6974 | lr : 1e-05
Epoch [4 / 100] Step: [500 / 1130] avg_train_loss: 0.8021 | train_auc: 0.694 | lr : 1e-05
Epoch [4 / 100] Step: [600 / 1130] avg_train_loss: 0.8065 | train_auc: 0.7066 | lr : 1e-05
Epoch [4 / 100] Step: [700 / 1130] avg_train_loss: 0.8168 | train_auc: 0.6989 | lr : 1e-05
Epoch [4 / 100] Step: [800 / 1130] avg_train_loss: 0.8148 | train_auc: 0.7003 | lr : 1e-05
Epoch [4 / 100] Step: [900 / 1130] avg_train_loss: 0.8227 | train_auc: 0.6953 | lr : 1e-05
Epoch [4 / 100] Step: [1000 / 1130] avg_train_loss: 0.8187 | train_auc: 0.702 | lr : 1e-05
Epoch [4 / 100] Step: [1100 / 1130] avg_train_loss: 0.8191 | train_auc: 0.7038 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 4 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4618 | val_auc: nan | lr: 1e-05
[Epoch: 4 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5162 | val_auc: nan | lr: 1e-05
[Epoch: 4 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5843 | val_auc: 0.7037 | lr: 1e-05
[Epoch: 4 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.665 | val_auc: 0.6706 | lr: 1e-05
[Epoch: 4 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7105 | val_auc: 0.6734 | lr: 1e-05
----------------------------------------------------------------------------------------------------
Model saved: "my-data/models/training/pretrained/model_base_meniscus_sagittal_train_auc_0.7040_val_auc_0.6553_train_loss_0.8191_val_loss_0.7721_epoch_4_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.9.pth"
[TRAIN] EPOCH # 5
[TRAIN] Train model
Epoch [5 / 100] Step: [100 / 1130] avg_train_loss: 0.785 | train_auc: 0.7842 | lr : 1e-05
Epoch [5 / 100] Step: [200 / 1130] avg_train_loss: 0.7533 | train_auc: 0.8189 | lr : 1e-05
Epoch [5 / 100] Step: [300 / 1130] avg_train_loss: 0.7447 | train_auc: 0.8136 | lr : 1e-05
Epoch [5 / 100] Step: [400 / 1130] avg_train_loss: 0.7662 | train_auc: 0.7816 | lr : 1e-05
Epoch [5 / 100] Step: [500 / 1130] avg_train_loss: 0.7691 | train_auc: 0.7821 | lr : 1e-05
Epoch [5 / 100] Step: [600 / 1130] avg_train_loss: 0.7687 | train_auc: 0.7763 | lr : 1e-05
Epoch [5 / 100] Step: [700 / 1130] avg_train_loss: 0.7722 | train_auc: 0.7696 | lr : 1e-05
Epoch [5 / 100] Step: [800 / 1130] avg_train_loss: 0.7735 | train_auc: 0.7592 | lr : 1e-05
Epoch [5 / 100] Step: [900 / 1130] avg_train_loss: 0.7694 | train_auc: 0.7638 | lr : 1e-05
Epoch [5 / 100] Step: [1000 / 1130] avg_train_loss: 0.769 | train_auc: 0.7623 | lr : 1e-05
Epoch [5 / 100] Step: [1100 / 1130] avg_train_loss: 0.7768 | train_auc: 0.7558 | lr : 1e-05
[EVALUATE] Evaluate model
[Epoch: 5 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4033 | val_auc: nan | lr: 1e-05
[Epoch: 5 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4302 | val_auc: nan | lr: 1e-05
[Epoch: 5 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5454 | val_auc: 0.5556 | lr: 1e-05
[Epoch: 5 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.658 | val_auc: 0.5374 | lr: 1e-05
[Epoch: 5 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7182 | val_auc: 0.6056 | lr: 1e-05
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 6
[TRAIN] Train model
Epoch [6 / 100] Step: [100 / 1130] avg_train_loss: 0.731 | train_auc: 0.8138 | lr : 3e-06
Epoch [6 / 100] Step: [200 / 1130] avg_train_loss: 0.7665 | train_auc: 0.7849 | lr : 3e-06
Epoch [6 / 100] Step: [300 / 1130] avg_train_loss: 0.7656 | train_auc: 0.7785 | lr : 3e-06
Epoch [6 / 100] Step: [400 / 1130] avg_train_loss: 0.7474 | train_auc: 0.7878 | lr : 3e-06
Epoch [6 / 100] Step: [500 / 1130] avg_train_loss: 0.7275 | train_auc: 0.8075 | lr : 3e-06
Epoch [6 / 100] Step: [600 / 1130] avg_train_loss: 0.712 | train_auc: 0.8223 | lr : 3e-06
Epoch [6 / 100] Step: [700 / 1130] avg_train_loss: 0.7046 | train_auc: 0.828 | lr : 3e-06
Epoch [6 / 100] Step: [800 / 1130] avg_train_loss: 0.6964 | train_auc: 0.8312 | lr : 3e-06
Epoch [6 / 100] Step: [900 / 1130] avg_train_loss: 0.7048 | train_auc: 0.8234 | lr : 3e-06
Epoch [6 / 100] Step: [1000 / 1130] avg_train_loss: 0.7106 | train_auc: 0.8188 | lr : 3e-06
Epoch [6 / 100] Step: [1100 / 1130] avg_train_loss: 0.7065 | train_auc: 0.8226 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 6 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4359 | val_auc: nan | lr: 3e-06
[Epoch: 6 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4916 | val_auc: nan | lr: 3e-06
[Epoch: 6 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5721 | val_auc: 0.7354 | lr: 3e-06
[Epoch: 6 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6768 | val_auc: 0.5968 | lr: 3e-06
[Epoch: 6 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7179 | val_auc: 0.6283 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 7
[TRAIN] Train model
Epoch [7 / 100] Step: [100 / 1130] avg_train_loss: 0.6766 | train_auc: 0.8573 | lr : 3e-06
Epoch [7 / 100] Step: [200 / 1130] avg_train_loss: 0.6503 | train_auc: 0.8756 | lr : 3e-06
Epoch [7 / 100] Step: [300 / 1130] avg_train_loss: 0.6668 | train_auc: 0.8604 | lr : 3e-06
Epoch [7 / 100] Step: [400 / 1130] avg_train_loss: 0.6756 | train_auc: 0.8546 | lr : 3e-06
Epoch [7 / 100] Step: [500 / 1130] avg_train_loss: 0.6764 | train_auc: 0.8445 | lr : 3e-06
Epoch [7 / 100] Step: [600 / 1130] avg_train_loss: 0.6649 | train_auc: 0.8534 | lr : 3e-06
Epoch [7 / 100] Step: [700 / 1130] avg_train_loss: 0.6716 | train_auc: 0.8472 | lr : 3e-06
Epoch [7 / 100] Step: [800 / 1130] avg_train_loss: 0.6657 | train_auc: 0.8515 | lr : 3e-06
Epoch [7 / 100] Step: [900 / 1130] avg_train_loss: 0.672 | train_auc: 0.8445 | lr : 3e-06
Epoch [7 / 100] Step: [1000 / 1130] avg_train_loss: 0.6801 | train_auc: 0.8382 | lr : 3e-06
Epoch [7 / 100] Step: [1100 / 1130] avg_train_loss: 0.6781 | train_auc: 0.8381 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 7 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.494 | val_auc: nan | lr: 3e-06
[Epoch: 7 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5411 | val_auc: nan | lr: 3e-06
[Epoch: 7 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.605 | val_auc: 0.6296 | lr: 3e-06
[Epoch: 7 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6875 | val_auc: 0.5747 | lr: 3e-06
[Epoch: 7 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7122 | val_auc: 0.6332 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 8
[TRAIN] Train model
Epoch [8 / 100] Step: [100 / 1130] avg_train_loss: 0.6607 | train_auc: 0.8133 | lr : 3e-06
Epoch [8 / 100] Step: [200 / 1130] avg_train_loss: 0.6517 | train_auc: 0.8539 | lr : 3e-06
Epoch [8 / 100] Step: [300 / 1130] avg_train_loss: 0.648 | train_auc: 0.8555 | lr : 3e-06
Epoch [8 / 100] Step: [400 / 1130] avg_train_loss: 0.6513 | train_auc: 0.8598 | lr : 3e-06
Epoch [8 / 100] Step: [500 / 1130] avg_train_loss: 0.6368 | train_auc: 0.8664 | lr : 3e-06
Epoch [8 / 100] Step: [600 / 1130] avg_train_loss: 0.6488 | train_auc: 0.862 | lr : 3e-06
Epoch [8 / 100] Step: [700 / 1130] avg_train_loss: 0.6466 | train_auc: 0.8658 | lr : 3e-06
Epoch [8 / 100] Step: [800 / 1130] avg_train_loss: 0.6369 | train_auc: 0.8699 | lr : 3e-06
Epoch [8 / 100] Step: [900 / 1130] avg_train_loss: 0.6409 | train_auc: 0.8626 | lr : 3e-06
Epoch [8 / 100] Step: [1000 / 1130] avg_train_loss: 0.6419 | train_auc: 0.8613 | lr : 3e-06
Epoch [8 / 100] Step: [1100 / 1130] avg_train_loss: 0.646 | train_auc: 0.8596 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 8 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4894 | val_auc: nan | lr: 3e-06
[Epoch: 8 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5524 | val_auc: nan | lr: 3e-06
[Epoch: 8 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6174 | val_auc: 0.6984 | lr: 3e-06
[Epoch: 8 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6984 | val_auc: 0.6053 | lr: 3e-06
[Epoch: 8 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7166 | val_auc: 0.6466 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 9
[TRAIN] Train model
Epoch [9 / 100] Step: [100 / 1130] avg_train_loss: 0.6413 | train_auc: 0.8507 | lr : 3e-06
Epoch [9 / 100] Step: [200 / 1130] avg_train_loss: 0.6547 | train_auc: 0.8477 | lr : 3e-06
Epoch [9 / 100] Step: [300 / 1130] avg_train_loss: 0.6363 | train_auc: 0.8502 | lr : 3e-06
Epoch [9 / 100] Step: [400 / 1130] avg_train_loss: 0.6221 | train_auc: 0.8659 | lr : 3e-06
Epoch [9 / 100] Step: [500 / 1130] avg_train_loss: 0.6092 | train_auc: 0.8754 | lr : 3e-06
Epoch [9 / 100] Step: [600 / 1130] avg_train_loss: 0.6163 | train_auc: 0.8733 | lr : 3e-06
Epoch [9 / 100] Step: [700 / 1130] avg_train_loss: 0.6187 | train_auc: 0.8704 | lr : 3e-06
Epoch [9 / 100] Step: [800 / 1130] avg_train_loss: 0.6127 | train_auc: 0.8756 | lr : 3e-06
Epoch [9 / 100] Step: [900 / 1130] avg_train_loss: 0.6218 | train_auc: 0.8689 | lr : 3e-06
Epoch [9 / 100] Step: [1000 / 1130] avg_train_loss: 0.6272 | train_auc: 0.8673 | lr : 3e-06
Epoch [9 / 100] Step: [1100 / 1130] avg_train_loss: 0.6281 | train_auc: 0.8668 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 9 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4908 | val_auc: nan | lr: 3e-06
[Epoch: 9 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5531 | val_auc: nan | lr: 3e-06
[Epoch: 9 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6185 | val_auc: 0.6693 | lr: 3e-06
[Epoch: 9 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7126 | val_auc: 0.5857 | lr: 3e-06
[Epoch: 9 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7342 | val_auc: 0.627 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 10
[TRAIN] Train model
Epoch [10 / 100] Step: [100 / 1130] avg_train_loss: 0.6498 | train_auc: 0.8598 | lr : 3e-06
Epoch [10 / 100] Step: [200 / 1130] avg_train_loss: 0.64 | train_auc: 0.8624 | lr : 3e-06
Epoch [10 / 100] Step: [300 / 1130] avg_train_loss: 0.6504 | train_auc: 0.8589 | lr : 3e-06
Epoch [10 / 100] Step: [400 / 1130] avg_train_loss: 0.6412 | train_auc: 0.864 | lr : 3e-06
Epoch [10 / 100] Step: [500 / 1130] avg_train_loss: 0.6291 | train_auc: 0.873 | lr : 3e-06
Epoch [10 / 100] Step: [600 / 1130] avg_train_loss: 0.6205 | train_auc: 0.8794 | lr : 3e-06
Epoch [10 / 100] Step: [700 / 1130] avg_train_loss: 0.6155 | train_auc: 0.8817 | lr : 3e-06
Epoch [10 / 100] Step: [800 / 1130] avg_train_loss: 0.6186 | train_auc: 0.882 | lr : 3e-06
Epoch [10 / 100] Step: [900 / 1130] avg_train_loss: 0.6076 | train_auc: 0.8856 | lr : 3e-06
Epoch [10 / 100] Step: [1000 / 1130] avg_train_loss: 0.6016 | train_auc: 0.8891 | lr : 3e-06
Epoch [10 / 100] Step: [1100 / 1130] avg_train_loss: 0.5971 | train_auc: 0.8923 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 10 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.5185 | val_auc: nan | lr: 3e-06
[Epoch: 10 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5957 | val_auc: nan | lr: 3e-06
[Epoch: 10 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.663 | val_auc: 0.5344 | lr: 3e-06
[Epoch: 10 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7446 | val_auc: 0.4873 | lr: 3e-06
[Epoch: 10 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7503 | val_auc: 0.586 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 11
[TRAIN] Train model
Epoch [11 / 100] Step: [100 / 1130] avg_train_loss: 0.538 | train_auc: 0.9248 | lr : 3e-06
Epoch [11 / 100] Step: [200 / 1130] avg_train_loss: 0.5564 | train_auc: 0.9111 | lr : 3e-06
Epoch [11 / 100] Step: [300 / 1130] avg_train_loss: 0.5408 | train_auc: 0.9147 | lr : 3e-06
Epoch [11 / 100] Step: [400 / 1130] avg_train_loss: 0.5566 | train_auc: 0.9104 | lr : 3e-06
Epoch [11 / 100] Step: [500 / 1130] avg_train_loss: 0.5531 | train_auc: 0.9101 | lr : 3e-06
Epoch [11 / 100] Step: [600 / 1130] avg_train_loss: 0.5406 | train_auc: 0.9167 | lr : 3e-06
Epoch [11 / 100] Step: [700 / 1130] avg_train_loss: 0.5552 | train_auc: 0.9112 | lr : 3e-06
Epoch [11 / 100] Step: [800 / 1130] avg_train_loss: 0.5578 | train_auc: 0.9097 | lr : 3e-06
Epoch [11 / 100] Step: [900 / 1130] avg_train_loss: 0.559 | train_auc: 0.9094 | lr : 3e-06
Epoch [11 / 100] Step: [1000 / 1130] avg_train_loss: 0.5735 | train_auc: 0.8994 | lr : 3e-06
Epoch [11 / 100] Step: [1100 / 1130] avg_train_loss: 0.5785 | train_auc: 0.8982 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 11 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.5486 | val_auc: nan | lr: 3e-06
[Epoch: 11 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.62 | val_auc: nan | lr: 3e-06
[Epoch: 11 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.7007 | val_auc: 0.5529 | lr: 3e-06
[Epoch: 11 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7582 | val_auc: 0.534 | lr: 3e-06
[Epoch: 11 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7633 | val_auc: 0.6061 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 12
[TRAIN] Train model
Epoch [12 / 100] Step: [100 / 1130] avg_train_loss: 0.6412 | train_auc: 0.8601 | lr : 3e-06
Epoch [12 / 100] Step: [200 / 1130] avg_train_loss: 0.5923 | train_auc: 0.8904 | lr : 3e-06
Epoch [12 / 100] Step: [300 / 1130] avg_train_loss: 0.6067 | train_auc: 0.866 | lr : 3e-06
Epoch [12 / 100] Step: [400 / 1130] avg_train_loss: 0.6147 | train_auc: 0.8675 | lr : 3e-06
Epoch [12 / 100] Step: [500 / 1130] avg_train_loss: 0.6071 | train_auc: 0.8669 | lr : 3e-06
Epoch [12 / 100] Step: [600 / 1130] avg_train_loss: 0.6068 | train_auc: 0.8685 | lr : 3e-06
Epoch [12 / 100] Step: [700 / 1130] avg_train_loss: 0.6032 | train_auc: 0.8754 | lr : 3e-06
Epoch [12 / 100] Step: [800 / 1130] avg_train_loss: 0.6011 | train_auc: 0.877 | lr : 3e-06
Epoch [12 / 100] Step: [900 / 1130] avg_train_loss: 0.5998 | train_auc: 0.8773 | lr : 3e-06
Epoch [12 / 100] Step: [1000 / 1130] avg_train_loss: 0.5942 | train_auc: 0.879 | lr : 3e-06
Epoch [12 / 100] Step: [1100 / 1130] avg_train_loss: 0.5972 | train_auc: 0.8777 | lr : 3e-06
[EVALUATE] Evaluate model
[Epoch: 12 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.5072 | val_auc: nan | lr: 3e-06
[Epoch: 12 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5537 | val_auc: nan | lr: 3e-06
[Epoch: 12 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6574 | val_auc: 0.6032 | lr: 3e-06
[Epoch: 12 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7436 | val_auc: 0.573 | lr: 3e-06
[Epoch: 12 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7506 | val_auc: 0.6234 | lr: 3e-06
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 13
[TRAIN] Train model
Epoch [13 / 100] Step: [100 / 1130] avg_train_loss: 0.5804 | train_auc: 0.8935 | lr : 9e-07
Epoch [13 / 100] Step: [200 / 1130] avg_train_loss: 0.5407 | train_auc: 0.9087 | lr : 9e-07
Epoch [13 / 100] Step: [300 / 1130] avg_train_loss: 0.5371 | train_auc: 0.9117 | lr : 9e-07
Epoch [13 / 100] Step: [400 / 1130] avg_train_loss: 0.5382 | train_auc: 0.911 | lr : 9e-07
Epoch [13 / 100] Step: [500 / 1130] avg_train_loss: 0.5687 | train_auc: 0.8962 | lr : 9e-07
Epoch [13 / 100] Step: [600 / 1130] avg_train_loss: 0.5576 | train_auc: 0.902 | lr : 9e-07
Epoch [13 / 100] Step: [700 / 1130] avg_train_loss: 0.5499 | train_auc: 0.9063 | lr : 9e-07
Epoch [13 / 100] Step: [800 / 1130] avg_train_loss: 0.5458 | train_auc: 0.9092 | lr : 9e-07
Epoch [13 / 100] Step: [900 / 1130] avg_train_loss: 0.5478 | train_auc: 0.9076 | lr : 9e-07
Epoch [13 / 100] Step: [1000 / 1130] avg_train_loss: 0.5442 | train_auc: 0.9108 | lr : 9e-07
Epoch [13 / 100] Step: [1100 / 1130] avg_train_loss: 0.5437 | train_auc: 0.9101 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 13 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4113 | val_auc: nan | lr: 9e-07
[Epoch: 13 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4571 | val_auc: nan | lr: 9e-07
[Epoch: 13 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5845 | val_auc: 0.5159 | lr: 9e-07
[Epoch: 13 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7053 | val_auc: 0.5042 | lr: 9e-07
[Epoch: 13 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7334 | val_auc: 0.5985 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 14
[TRAIN] Train model
Epoch [14 / 100] Step: [100 / 1130] avg_train_loss: 0.4561 | train_auc: 0.9735 | lr : 9e-07
Epoch [14 / 100] Step: [200 / 1130] avg_train_loss: 0.4903 | train_auc: 0.9365 | lr : 9e-07
Epoch [14 / 100] Step: [300 / 1130] avg_train_loss: 0.5043 | train_auc: 0.9324 | lr : 9e-07
Epoch [14 / 100] Step: [400 / 1130] avg_train_loss: 0.4911 | train_auc: 0.9395 | lr : 9e-07
Epoch [14 / 100] Step: [500 / 1130] avg_train_loss: 0.5065 | train_auc: 0.9315 | lr : 9e-07
Epoch [14 / 100] Step: [600 / 1130] avg_train_loss: 0.5147 | train_auc: 0.9293 | lr : 9e-07
Epoch [14 / 100] Step: [700 / 1130] avg_train_loss: 0.5035 | train_auc: 0.936 | lr : 9e-07
Epoch [14 / 100] Step: [800 / 1130] avg_train_loss: 0.5122 | train_auc: 0.9295 | lr : 9e-07
Epoch [14 / 100] Step: [900 / 1130] avg_train_loss: 0.5105 | train_auc: 0.9274 | lr : 9e-07
Epoch [14 / 100] Step: [1000 / 1130] avg_train_loss: 0.5284 | train_auc: 0.915 | lr : 9e-07
Epoch [14 / 100] Step: [1100 / 1130] avg_train_loss: 0.5264 | train_auc: 0.9174 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 14 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4776 | val_auc: nan | lr: 9e-07
[Epoch: 14 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5536 | val_auc: nan | lr: 9e-07
[Epoch: 14 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6633 | val_auc: 0.5159 | lr: 9e-07
[Epoch: 14 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7527 | val_auc: 0.5017 | lr: 9e-07
[Epoch: 14 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7609 | val_auc: 0.5914 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 15
[TRAIN] Train model
Epoch [15 / 100] Step: [100 / 1130] avg_train_loss: 0.5419 | train_auc: 0.9177 | lr : 9e-07
Epoch [15 / 100] Step: [200 / 1130] avg_train_loss: 0.5199 | train_auc: 0.9209 | lr : 9e-07
Epoch [15 / 100] Step: [300 / 1130] avg_train_loss: 0.5442 | train_auc: 0.9079 | lr : 9e-07
Epoch [15 / 100] Step: [400 / 1130] avg_train_loss: 0.5423 | train_auc: 0.9073 | lr : 9e-07
Epoch [15 / 100] Step: [500 / 1130] avg_train_loss: 0.5351 | train_auc: 0.9094 | lr : 9e-07
Epoch [15 / 100] Step: [600 / 1130] avg_train_loss: 0.5214 | train_auc: 0.9145 | lr : 9e-07
Epoch [15 / 100] Step: [700 / 1130] avg_train_loss: 0.5211 | train_auc: 0.9192 | lr : 9e-07
Epoch [15 / 100] Step: [800 / 1130] avg_train_loss: 0.5283 | train_auc: 0.9142 | lr : 9e-07
Epoch [15 / 100] Step: [900 / 1130] avg_train_loss: 0.5261 | train_auc: 0.9174 | lr : 9e-07
Epoch [15 / 100] Step: [1000 / 1130] avg_train_loss: 0.5303 | train_auc: 0.9152 | lr : 9e-07
Epoch [15 / 100] Step: [1100 / 1130] avg_train_loss: 0.5273 | train_auc: 0.9167 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 15 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.364 | val_auc: nan | lr: 9e-07
[Epoch: 15 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4494 | val_auc: nan | lr: 9e-07
[Epoch: 15 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.535 | val_auc: 0.7143 | lr: 9e-07
[Epoch: 15 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6677 | val_auc: 0.6282 | lr: 9e-07
[Epoch: 15 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7115 | val_auc: 0.66 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 16
[TRAIN] Train model
Epoch [16 / 100] Step: [100 / 1130] avg_train_loss: 0.5553 | train_auc: 0.8904 | lr : 9e-07
Epoch [16 / 100] Step: [200 / 1130] avg_train_loss: 0.5056 | train_auc: 0.9276 | lr : 9e-07
Epoch [16 / 100] Step: [300 / 1130] avg_train_loss: 0.5168 | train_auc: 0.921 | lr : 9e-07
Epoch [16 / 100] Step: [400 / 1130] avg_train_loss: 0.5293 | train_auc: 0.9039 | lr : 9e-07
Epoch [16 / 100] Step: [500 / 1130] avg_train_loss: 0.5282 | train_auc: 0.9054 | lr : 9e-07
Epoch [16 / 100] Step: [600 / 1130] avg_train_loss: 0.5191 | train_auc: 0.9129 | lr : 9e-07
Epoch [16 / 100] Step: [700 / 1130] avg_train_loss: 0.5259 | train_auc: 0.9064 | lr : 9e-07
Epoch [16 / 100] Step: [800 / 1130] avg_train_loss: 0.5226 | train_auc: 0.9116 | lr : 9e-07
Epoch [16 / 100] Step: [900 / 1130] avg_train_loss: 0.5113 | train_auc: 0.9179 | lr : 9e-07
Epoch [16 / 100] Step: [1000 / 1130] avg_train_loss: 0.5067 | train_auc: 0.9227 | lr : 9e-07
Epoch [16 / 100] Step: [1100 / 1130] avg_train_loss: 0.5071 | train_auc: 0.922 | lr : 9e-07
[EVALUATE] Evaluate model
[Epoch: 16 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3529 | val_auc: nan | lr: 9e-07
[Epoch: 16 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4245 | val_auc: nan | lr: 9e-07
[Epoch: 16 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5489 | val_auc: 0.5767 | lr: 9e-07
[Epoch: 16 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6841 | val_auc: 0.5331 | lr: 9e-07
[Epoch: 16 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.712 | val_auc: 0.6225 | lr: 9e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 17
[TRAIN] Train model
Epoch [17 / 100] Step: [100 / 1130] avg_train_loss: 0.5322 | train_auc: 0.9025 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [200 / 1130] avg_train_loss: 0.5478 | train_auc: 0.8944 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [300 / 1130] avg_train_loss: 0.539 | train_auc: 0.9041 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [400 / 1130] avg_train_loss: 0.5429 | train_auc: 0.9072 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [500 / 1130] avg_train_loss: 0.5116 | train_auc: 0.9232 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [600 / 1130] avg_train_loss: 0.5087 | train_auc: 0.924 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [700 / 1130] avg_train_loss: 0.5087 | train_auc: 0.9231 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [800 / 1130] avg_train_loss: 0.5026 | train_auc: 0.9272 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [900 / 1130] avg_train_loss: 0.4964 | train_auc: 0.9303 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [1000 / 1130] avg_train_loss: 0.4934 | train_auc: 0.9305 | lr : 2.6999999999999996e-07
Epoch [17 / 100] Step: [1100 / 1130] avg_train_loss: 0.4951 | train_auc: 0.9277 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 17 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3443 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 17 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4165 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 17 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5417 | val_auc: 0.6296 | lr: 2.6999999999999996e-07
[Epoch: 17 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6774 | val_auc: 0.584 | lr: 2.6999999999999996e-07
[Epoch: 17 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7105 | val_auc: 0.6404 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 18
[TRAIN] Train model
Epoch [18 / 100] Step: [100 / 1130] avg_train_loss: 0.4772 | train_auc: 0.9287 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [200 / 1130] avg_train_loss: 0.4664 | train_auc: 0.9423 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [300 / 1130] avg_train_loss: 0.4705 | train_auc: 0.9413 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [400 / 1130] avg_train_loss: 0.4815 | train_auc: 0.932 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [500 / 1130] avg_train_loss: 0.5 | train_auc: 0.9233 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [600 / 1130] avg_train_loss: 0.4945 | train_auc: 0.9217 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [700 / 1130] avg_train_loss: 0.4941 | train_auc: 0.9232 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [800 / 1130] avg_train_loss: 0.502 | train_auc: 0.9225 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [900 / 1130] avg_train_loss: 0.4928 | train_auc: 0.9269 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [1000 / 1130] avg_train_loss: 0.4995 | train_auc: 0.9241 | lr : 2.6999999999999996e-07
Epoch [18 / 100] Step: [1100 / 1130] avg_train_loss: 0.4962 | train_auc: 0.9239 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 18 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4163 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 18 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4738 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 18 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.591 | val_auc: 0.5344 | lr: 2.6999999999999996e-07
[Epoch: 18 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7048 | val_auc: 0.5289 | lr: 2.6999999999999996e-07
[Epoch: 18 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7292 | val_auc: 0.611 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 19
[TRAIN] Train model
Epoch [19 / 100] Step: [100 / 1130] avg_train_loss: 0.5589 | train_auc: 0.8972 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [200 / 1130] avg_train_loss: 0.5373 | train_auc: 0.9104 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [300 / 1130] avg_train_loss: 0.5186 | train_auc: 0.9185 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [400 / 1130] avg_train_loss: 0.5002 | train_auc: 0.929 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [500 / 1130] avg_train_loss: 0.5019 | train_auc: 0.9276 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [600 / 1130] avg_train_loss: 0.5059 | train_auc: 0.927 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [700 / 1130] avg_train_loss: 0.5023 | train_auc: 0.9281 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [800 / 1130] avg_train_loss: 0.5052 | train_auc: 0.9265 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [900 / 1130] avg_train_loss: 0.5132 | train_auc: 0.9198 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [1000 / 1130] avg_train_loss: 0.5093 | train_auc: 0.9219 | lr : 2.6999999999999996e-07
Epoch [19 / 100] Step: [1100 / 1130] avg_train_loss: 0.5036 | train_auc: 0.9245 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 19 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4105 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 19 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4866 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 19 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6241 | val_auc: 0.455 | lr: 2.6999999999999996e-07
[Epoch: 19 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7401 | val_auc: 0.4737 | lr: 2.6999999999999996e-07
[Epoch: 19 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7557 | val_auc: 0.586 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 20
[TRAIN] Train model
Epoch [20 / 100] Step: [100 / 1130] avg_train_loss: 0.5135 | train_auc: 0.9253 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [200 / 1130] avg_train_loss: 0.4619 | train_auc: 0.9512 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [300 / 1130] avg_train_loss: 0.4863 | train_auc: 0.9391 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [400 / 1130] avg_train_loss: 0.4988 | train_auc: 0.9303 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [500 / 1130] avg_train_loss: 0.5059 | train_auc: 0.925 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [600 / 1130] avg_train_loss: 0.4991 | train_auc: 0.9303 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [700 / 1130] avg_train_loss: 0.5013 | train_auc: 0.9285 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [800 / 1130] avg_train_loss: 0.4941 | train_auc: 0.9308 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [900 / 1130] avg_train_loss: 0.4971 | train_auc: 0.9298 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [1000 / 1130] avg_train_loss: 0.4937 | train_auc: 0.9301 | lr : 2.6999999999999996e-07
Epoch [20 / 100] Step: [1100 / 1130] avg_train_loss: 0.5039 | train_auc: 0.9255 | lr : 2.6999999999999996e-07
[EVALUATE] Evaluate model
[Epoch: 20 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3602 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 20 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4388 | val_auc: nan | lr: 2.6999999999999996e-07
[Epoch: 20 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5247 | val_auc: 0.7989 | lr: 2.6999999999999996e-07
[Epoch: 20 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6609 | val_auc: 0.6757 | lr: 2.6999999999999996e-07
[Epoch: 20 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7113 | val_auc: 0.6791 | lr: 2.6999999999999996e-07
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 21
[TRAIN] Train model
Epoch [21 / 100] Step: [100 / 1130] avg_train_loss: 0.4907 | train_auc: 0.9307 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [200 / 1130] avg_train_loss: 0.5131 | train_auc: 0.9195 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [300 / 1130] avg_train_loss: 0.495 | train_auc: 0.9284 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [400 / 1130] avg_train_loss: 0.4964 | train_auc: 0.9308 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [500 / 1130] avg_train_loss: 0.4962 | train_auc: 0.9303 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [600 / 1130] avg_train_loss: 0.4947 | train_auc: 0.9304 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [700 / 1130] avg_train_loss: 0.4917 | train_auc: 0.9302 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [800 / 1130] avg_train_loss: 0.49 | train_auc: 0.931 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [900 / 1130] avg_train_loss: 0.4821 | train_auc: 0.9347 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [1000 / 1130] avg_train_loss: 0.4897 | train_auc: 0.9306 | lr : 8.099999999999998e-08
Epoch [21 / 100] Step: [1100 / 1130] avg_train_loss: 0.4893 | train_auc: 0.932 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 21 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.416 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 21 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4894 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 21 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5957 | val_auc: 0.6508 | lr: 8.099999999999998e-08
[Epoch: 21 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7066 | val_auc: 0.5832 | lr: 8.099999999999998e-08
[Epoch: 21 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7347 | val_auc: 0.6288 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 22
[TRAIN] Train model
Epoch [22 / 100] Step: [100 / 1130] avg_train_loss: 0.6766 | train_auc: 0.8336 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [200 / 1130] avg_train_loss: 0.5726 | train_auc: 0.9009 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [300 / 1130] avg_train_loss: 0.5291 | train_auc: 0.9187 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [400 / 1130] avg_train_loss: 0.5614 | train_auc: 0.8942 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [500 / 1130] avg_train_loss: 0.5381 | train_auc: 0.9042 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [600 / 1130] avg_train_loss: 0.5384 | train_auc: 0.9051 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [700 / 1130] avg_train_loss: 0.5303 | train_auc: 0.9095 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [800 / 1130] avg_train_loss: 0.5294 | train_auc: 0.9102 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [900 / 1130] avg_train_loss: 0.5152 | train_auc: 0.9172 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [1000 / 1130] avg_train_loss: 0.5153 | train_auc: 0.9181 | lr : 8.099999999999998e-08
Epoch [22 / 100] Step: [1100 / 1130] avg_train_loss: 0.5102 | train_auc: 0.9201 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 22 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4138 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 22 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4851 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 22 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5844 | val_auc: 0.672 | lr: 8.099999999999998e-08
[Epoch: 22 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6998 | val_auc: 0.6061 | lr: 8.099999999999998e-08
[Epoch: 22 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7363 | val_auc: 0.6355 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 23
[TRAIN] Train model
Epoch [23 / 100] Step: [100 / 1130] avg_train_loss: 0.5863 | train_auc: 0.884 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [200 / 1130] avg_train_loss: 0.5349 | train_auc: 0.9154 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [300 / 1130] avg_train_loss: 0.4748 | train_auc: 0.9423 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [400 / 1130] avg_train_loss: 0.4743 | train_auc: 0.9408 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [500 / 1130] avg_train_loss: 0.4936 | train_auc: 0.9301 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [600 / 1130] avg_train_loss: 0.5014 | train_auc: 0.93 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [700 / 1130] avg_train_loss: 0.4887 | train_auc: 0.9349 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [800 / 1130] avg_train_loss: 0.4944 | train_auc: 0.9308 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [900 / 1130] avg_train_loss: 0.4924 | train_auc: 0.9321 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [1000 / 1130] avg_train_loss: 0.4903 | train_auc: 0.9327 | lr : 8.099999999999998e-08
Epoch [23 / 100] Step: [1100 / 1130] avg_train_loss: 0.4917 | train_auc: 0.9319 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 23 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4076 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 23 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4776 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 23 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5982 | val_auc: 0.6111 | lr: 8.099999999999998e-08
[Epoch: 23 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7127 | val_auc: 0.5688 | lr: 8.099999999999998e-08
[Epoch: 23 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7338 | val_auc: 0.6315 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 24
[TRAIN] Train model
Epoch [24 / 100] Step: [100 / 1130] avg_train_loss: 0.4678 | train_auc: 0.9372 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [200 / 1130] avg_train_loss: 0.5246 | train_auc: 0.9175 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [300 / 1130] avg_train_loss: 0.5103 | train_auc: 0.9188 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [400 / 1130] avg_train_loss: 0.5057 | train_auc: 0.9273 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [500 / 1130] avg_train_loss: 0.5041 | train_auc: 0.9264 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [600 / 1130] avg_train_loss: 0.4965 | train_auc: 0.9295 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [700 / 1130] avg_train_loss: 0.5013 | train_auc: 0.9272 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [800 / 1130] avg_train_loss: 0.5002 | train_auc: 0.9279 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [900 / 1130] avg_train_loss: 0.5041 | train_auc: 0.9264 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [1000 / 1130] avg_train_loss: 0.4978 | train_auc: 0.9282 | lr : 8.099999999999998e-08
Epoch [24 / 100] Step: [1100 / 1130] avg_train_loss: 0.4951 | train_auc: 0.928 | lr : 8.099999999999998e-08
[EVALUATE] Evaluate model
[Epoch: 24 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4038 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 24 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4716 | val_auc: nan | lr: 8.099999999999998e-08
[Epoch: 24 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5968 | val_auc: 0.5503 | lr: 8.099999999999998e-08
[Epoch: 24 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7103 | val_auc: 0.5331 | lr: 8.099999999999998e-08
[Epoch: 24 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7274 | val_auc: 0.6185 | lr: 8.099999999999998e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 25
[TRAIN] Train model
Epoch [25 / 100] Step: [100 / 1130] avg_train_loss: 0.5874 | train_auc: 0.8952 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [200 / 1130] avg_train_loss: 0.5153 | train_auc: 0.9201 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [300 / 1130] avg_train_loss: 0.5086 | train_auc: 0.9244 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [400 / 1130] avg_train_loss: 0.4921 | train_auc: 0.9335 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [500 / 1130] avg_train_loss: 0.4927 | train_auc: 0.9355 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [600 / 1130] avg_train_loss: 0.5066 | train_auc: 0.9277 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [700 / 1130] avg_train_loss: 0.5065 | train_auc: 0.9278 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [800 / 1130] avg_train_loss: 0.4979 | train_auc: 0.9315 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [900 / 1130] avg_train_loss: 0.4889 | train_auc: 0.935 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [1000 / 1130] avg_train_loss: 0.4911 | train_auc: 0.9343 | lr : 2.4299999999999996e-08
Epoch [25 / 100] Step: [1100 / 1130] avg_train_loss: 0.4937 | train_auc: 0.9324 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 25 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3669 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 25 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4387 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 25 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.545 | val_auc: 0.7063 | lr: 2.4299999999999996e-08
[Epoch: 25 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.674 | val_auc: 0.6324 | lr: 2.4299999999999996e-08
[Epoch: 25 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7143 | val_auc: 0.6649 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 26
[TRAIN] Train model
Epoch [26 / 100] Step: [100 / 1130] avg_train_loss: 0.4299 | train_auc: 0.9795 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [200 / 1130] avg_train_loss: 0.4455 | train_auc: 0.9721 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [300 / 1130] avg_train_loss: 0.4521 | train_auc: 0.9643 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [400 / 1130] avg_train_loss: 0.4585 | train_auc: 0.9571 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [500 / 1130] avg_train_loss: 0.4645 | train_auc: 0.9498 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [600 / 1130] avg_train_loss: 0.4875 | train_auc: 0.9396 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [700 / 1130] avg_train_loss: 0.4825 | train_auc: 0.943 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [800 / 1130] avg_train_loss: 0.4866 | train_auc: 0.9393 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [900 / 1130] avg_train_loss: 0.4806 | train_auc: 0.9406 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [1000 / 1130] avg_train_loss: 0.4887 | train_auc: 0.9363 | lr : 2.4299999999999996e-08
Epoch [26 / 100] Step: [1100 / 1130] avg_train_loss: 0.493 | train_auc: 0.9336 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 26 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4072 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 26 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4727 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 26 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5847 | val_auc: 0.5714 | lr: 2.4299999999999996e-08
[Epoch: 26 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7048 | val_auc: 0.5433 | lr: 2.4299999999999996e-08
[Epoch: 26 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7286 | val_auc: 0.6239 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 27
[TRAIN] Train model
Epoch [27 / 100] Step: [100 / 1130] avg_train_loss: 0.501 | train_auc: 0.927 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [200 / 1130] avg_train_loss: 0.4817 | train_auc: 0.9294 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [300 / 1130] avg_train_loss: 0.512 | train_auc: 0.92 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [400 / 1130] avg_train_loss: 0.4895 | train_auc: 0.9294 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [500 / 1130] avg_train_loss: 0.4878 | train_auc: 0.9285 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [600 / 1130] avg_train_loss: 0.4894 | train_auc: 0.929 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [700 / 1130] avg_train_loss: 0.4784 | train_auc: 0.9349 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [800 / 1130] avg_train_loss: 0.477 | train_auc: 0.9348 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [900 / 1130] avg_train_loss: 0.4754 | train_auc: 0.9357 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [1000 / 1130] avg_train_loss: 0.4794 | train_auc: 0.9335 | lr : 2.4299999999999996e-08
Epoch [27 / 100] Step: [1100 / 1130] avg_train_loss: 0.48 | train_auc: 0.9319 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 27 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3699 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 27 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4375 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 27 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5665 | val_auc: 0.5873 | lr: 2.4299999999999996e-08
[Epoch: 27 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7006 | val_auc: 0.5441 | lr: 2.4299999999999996e-08
[Epoch: 27 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7321 | val_auc: 0.6185 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 28
[TRAIN] Train model
Epoch [28 / 100] Step: [100 / 1130] avg_train_loss: 0.54 | train_auc: 0.9234 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [200 / 1130] avg_train_loss: 0.5204 | train_auc: 0.9223 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [300 / 1130] avg_train_loss: 0.4936 | train_auc: 0.936 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [400 / 1130] avg_train_loss: 0.5069 | train_auc: 0.9269 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [500 / 1130] avg_train_loss: 0.5079 | train_auc: 0.928 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [600 / 1130] avg_train_loss: 0.5069 | train_auc: 0.9276 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [700 / 1130] avg_train_loss: 0.5178 | train_auc: 0.9203 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [800 / 1130] avg_train_loss: 0.503 | train_auc: 0.9283 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [900 / 1130] avg_train_loss: 0.5057 | train_auc: 0.9249 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [1000 / 1130] avg_train_loss: 0.5029 | train_auc: 0.9271 | lr : 2.4299999999999996e-08
Epoch [28 / 100] Step: [1100 / 1130] avg_train_loss: 0.503 | train_auc: 0.9273 | lr : 2.4299999999999996e-08
[EVALUATE] Evaluate model
[Epoch: 28 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4026 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 28 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4561 | val_auc: nan | lr: 2.4299999999999996e-08
[Epoch: 28 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5844 | val_auc: 0.5926 | lr: 2.4299999999999996e-08
[Epoch: 28 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6919 | val_auc: 0.5688 | lr: 2.4299999999999996e-08
[Epoch: 28 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7171 | val_auc: 0.6346 | lr: 2.4299999999999996e-08
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 29
[TRAIN] Train model
Epoch [29 / 100] Step: [100 / 1130] avg_train_loss: 0.4148 | train_auc: 0.9644 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [200 / 1130] avg_train_loss: 0.5206 | train_auc: 0.9058 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [300 / 1130] avg_train_loss: 0.4978 | train_auc: 0.9208 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [400 / 1130] avg_train_loss: 0.5025 | train_auc: 0.9167 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [500 / 1130] avg_train_loss: 0.5056 | train_auc: 0.9184 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [600 / 1130] avg_train_loss: 0.4987 | train_auc: 0.9231 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [700 / 1130] avg_train_loss: 0.4843 | train_auc: 0.9315 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [800 / 1130] avg_train_loss: 0.4822 | train_auc: 0.9331 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [900 / 1130] avg_train_loss: 0.4989 | train_auc: 0.9261 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [1000 / 1130] avg_train_loss: 0.4955 | train_auc: 0.9277 | lr : 7.289999999999999e-09
Epoch [29 / 100] Step: [1100 / 1130] avg_train_loss: 0.4868 | train_auc: 0.9326 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 29 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.382 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 29 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4559 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 29 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5514 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 29 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6832 | val_auc: 0.6019 | lr: 7.289999999999999e-09
[Epoch: 29 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7171 | val_auc: 0.6497 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 30
[TRAIN] Train model
Epoch [30 / 100] Step: [100 / 1130] avg_train_loss: 0.452 | train_auc: 0.9378 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [200 / 1130] avg_train_loss: 0.4974 | train_auc: 0.9201 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [300 / 1130] avg_train_loss: 0.4643 | train_auc: 0.9386 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [400 / 1130] avg_train_loss: 0.471 | train_auc: 0.9318 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [500 / 1130] avg_train_loss: 0.4773 | train_auc: 0.9302 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [600 / 1130] avg_train_loss: 0.4696 | train_auc: 0.936 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [700 / 1130] avg_train_loss: 0.4808 | train_auc: 0.932 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [800 / 1130] avg_train_loss: 0.4783 | train_auc: 0.9348 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [900 / 1130] avg_train_loss: 0.4742 | train_auc: 0.9366 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [1000 / 1130] avg_train_loss: 0.4705 | train_auc: 0.9387 | lr : 7.289999999999999e-09
Epoch [30 / 100] Step: [1100 / 1130] avg_train_loss: 0.4713 | train_auc: 0.9389 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 30 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3418 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 30 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.41 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 30 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5234 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 30 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6607 | val_auc: 0.6197 | lr: 7.289999999999999e-09
[Epoch: 30 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7101 | val_auc: 0.6649 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 31
[TRAIN] Train model
Epoch [31 / 100] Step: [100 / 1130] avg_train_loss: 0.5448 | train_auc: 0.8871 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [200 / 1130] avg_train_loss: 0.4948 | train_auc: 0.9153 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [300 / 1130] avg_train_loss: 0.5222 | train_auc: 0.9062 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [400 / 1130] avg_train_loss: 0.5288 | train_auc: 0.903 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [500 / 1130] avg_train_loss: 0.5261 | train_auc: 0.9053 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [600 / 1130] avg_train_loss: 0.5357 | train_auc: 0.9036 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [700 / 1130] avg_train_loss: 0.5122 | train_auc: 0.9157 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [800 / 1130] avg_train_loss: 0.5017 | train_auc: 0.9202 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [900 / 1130] avg_train_loss: 0.5013 | train_auc: 0.9214 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [1000 / 1130] avg_train_loss: 0.4955 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [31 / 100] Step: [1100 / 1130] avg_train_loss: 0.4918 | train_auc: 0.9271 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 31 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.416 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 31 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4898 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 31 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6036 | val_auc: 0.5423 | lr: 7.289999999999999e-09
[Epoch: 31 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7142 | val_auc: 0.5314 | lr: 7.289999999999999e-09
[Epoch: 31 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7369 | val_auc: 0.6105 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 32
[TRAIN] Train model
Epoch [32 / 100] Step: [100 / 1130] avg_train_loss: 0.454 | train_auc: 0.9402 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [200 / 1130] avg_train_loss: 0.4758 | train_auc: 0.9442 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [300 / 1130] avg_train_loss: 0.4676 | train_auc: 0.949 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [400 / 1130] avg_train_loss: 0.4752 | train_auc: 0.9462 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [500 / 1130] avg_train_loss: 0.4826 | train_auc: 0.9403 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [600 / 1130] avg_train_loss: 0.4821 | train_auc: 0.9381 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [700 / 1130] avg_train_loss: 0.4856 | train_auc: 0.9371 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [800 / 1130] avg_train_loss: 0.4886 | train_auc: 0.9352 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [900 / 1130] avg_train_loss: 0.4936 | train_auc: 0.9317 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [1000 / 1130] avg_train_loss: 0.4951 | train_auc: 0.9315 | lr : 7.289999999999999e-09
Epoch [32 / 100] Step: [1100 / 1130] avg_train_loss: 0.4987 | train_auc: 0.9298 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 32 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3615 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 32 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4227 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 32 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5517 | val_auc: 0.5979 | lr: 7.289999999999999e-09
[Epoch: 32 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6827 | val_auc: 0.5696 | lr: 7.289999999999999e-09
[Epoch: 32 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7254 | val_auc: 0.6257 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 33
[TRAIN] Train model
Epoch [33 / 100] Step: [100 / 1130] avg_train_loss: 0.4143 | train_auc: 0.9682 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [200 / 1130] avg_train_loss: 0.4824 | train_auc: 0.9379 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [300 / 1130] avg_train_loss: 0.4774 | train_auc: 0.9361 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [400 / 1130] avg_train_loss: 0.4819 | train_auc: 0.933 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [500 / 1130] avg_train_loss: 0.4943 | train_auc: 0.9291 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [600 / 1130] avg_train_loss: 0.4843 | train_auc: 0.9338 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [700 / 1130] avg_train_loss: 0.4871 | train_auc: 0.9323 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [800 / 1130] avg_train_loss: 0.4878 | train_auc: 0.9306 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [900 / 1130] avg_train_loss: 0.4759 | train_auc: 0.9365 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [1000 / 1130] avg_train_loss: 0.4797 | train_auc: 0.9336 | lr : 7.289999999999999e-09
Epoch [33 / 100] Step: [1100 / 1130] avg_train_loss: 0.4718 | train_auc: 0.9383 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 33 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3924 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 33 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.47 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 33 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5815 | val_auc: 0.5688 | lr: 7.289999999999999e-09
[Epoch: 33 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7014 | val_auc: 0.5467 | lr: 7.289999999999999e-09
[Epoch: 33 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7205 | val_auc: 0.6359 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 34
[TRAIN] Train model
Epoch [34 / 100] Step: [100 / 1130] avg_train_loss: 0.4555 | train_auc: 0.9497 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [200 / 1130] avg_train_loss: 0.4822 | train_auc: 0.9376 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [300 / 1130] avg_train_loss: 0.4999 | train_auc: 0.9302 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [400 / 1130] avg_train_loss: 0.4846 | train_auc: 0.9385 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [500 / 1130] avg_train_loss: 0.5194 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [600 / 1130] avg_train_loss: 0.4989 | train_auc: 0.9352 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [700 / 1130] avg_train_loss: 0.502 | train_auc: 0.9322 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [800 / 1130] avg_train_loss: 0.5059 | train_auc: 0.9316 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [900 / 1130] avg_train_loss: 0.5161 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [1000 / 1130] avg_train_loss: 0.5177 | train_auc: 0.9217 | lr : 7.289999999999999e-09
Epoch [34 / 100] Step: [1100 / 1130] avg_train_loss: 0.5143 | train_auc: 0.922 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 34 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3814 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 34 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4552 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 34 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5845 | val_auc: 0.5159 | lr: 7.289999999999999e-09
[Epoch: 34 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.703 | val_auc: 0.5221 | lr: 7.289999999999999e-09
[Epoch: 34 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7297 | val_auc: 0.6132 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 35
[TRAIN] Train model
Epoch [35 / 100] Step: [100 / 1130] avg_train_loss: 0.5205 | train_auc: 0.914 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [200 / 1130] avg_train_loss: 0.5205 | train_auc: 0.9108 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [300 / 1130] avg_train_loss: 0.5159 | train_auc: 0.9118 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [400 / 1130] avg_train_loss: 0.5137 | train_auc: 0.9118 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [500 / 1130] avg_train_loss: 0.5127 | train_auc: 0.9117 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [600 / 1130] avg_train_loss: 0.5062 | train_auc: 0.9165 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [700 / 1130] avg_train_loss: 0.4909 | train_auc: 0.925 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [800 / 1130] avg_train_loss: 0.4946 | train_auc: 0.9234 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [900 / 1130] avg_train_loss: 0.4939 | train_auc: 0.9238 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [1000 / 1130] avg_train_loss: 0.488 | train_auc: 0.9254 | lr : 7.289999999999999e-09
Epoch [35 / 100] Step: [1100 / 1130] avg_train_loss: 0.4933 | train_auc: 0.9253 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 35 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3979 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 35 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4719 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 35 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5886 | val_auc: 0.6667 | lr: 7.289999999999999e-09
[Epoch: 35 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6971 | val_auc: 0.6019 | lr: 7.289999999999999e-09
[Epoch: 35 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7192 | val_auc: 0.6462 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 36
[TRAIN] Train model
Epoch [36 / 100] Step: [100 / 1130] avg_train_loss: 0.5212 | train_auc: 0.9111 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [200 / 1130] avg_train_loss: 0.4611 | train_auc: 0.931 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [300 / 1130] avg_train_loss: 0.4655 | train_auc: 0.9345 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [400 / 1130] avg_train_loss: 0.4632 | train_auc: 0.9374 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [500 / 1130] avg_train_loss: 0.466 | train_auc: 0.9394 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [600 / 1130] avg_train_loss: 0.4628 | train_auc: 0.9431 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [700 / 1130] avg_train_loss: 0.4662 | train_auc: 0.9407 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [800 / 1130] avg_train_loss: 0.4657 | train_auc: 0.9407 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [900 / 1130] avg_train_loss: 0.4644 | train_auc: 0.9411 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [1000 / 1130] avg_train_loss: 0.4686 | train_auc: 0.9414 | lr : 7.289999999999999e-09
Epoch [36 / 100] Step: [1100 / 1130] avg_train_loss: 0.4782 | train_auc: 0.9365 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 36 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4044 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 36 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4812 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 36 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5866 | val_auc: 0.6296 | lr: 7.289999999999999e-09
[Epoch: 36 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7003 | val_auc: 0.562 | lr: 7.289999999999999e-09
[Epoch: 36 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7151 | val_auc: 0.6399 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 37
[TRAIN] Train model
Epoch [37 / 100] Step: [100 / 1130] avg_train_loss: 0.4381 | train_auc: 0.9554 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [200 / 1130] avg_train_loss: 0.4906 | train_auc: 0.9281 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [300 / 1130] avg_train_loss: 0.5069 | train_auc: 0.9224 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [400 / 1130] avg_train_loss: 0.5065 | train_auc: 0.922 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [500 / 1130] avg_train_loss: 0.5011 | train_auc: 0.9243 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [600 / 1130] avg_train_loss: 0.4982 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [700 / 1130] avg_train_loss: 0.4876 | train_auc: 0.9308 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [800 / 1130] avg_train_loss: 0.4922 | train_auc: 0.9302 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [900 / 1130] avg_train_loss: 0.4841 | train_auc: 0.9325 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [1000 / 1130] avg_train_loss: 0.491 | train_auc: 0.9304 | lr : 7.289999999999999e-09
Epoch [37 / 100] Step: [1100 / 1130] avg_train_loss: 0.4911 | train_auc: 0.9298 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 37 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4276 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 37 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.491 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 37 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6202 | val_auc: 0.5079 | lr: 7.289999999999999e-09
[Epoch: 37 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7182 | val_auc: 0.5297 | lr: 7.289999999999999e-09
[Epoch: 37 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7513 | val_auc: 0.5891 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 38
[TRAIN] Train model
Epoch [38 / 100] Step: [100 / 1130] avg_train_loss: 0.4683 | train_auc: 0.9442 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [200 / 1130] avg_train_loss: 0.4925 | train_auc: 0.9236 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [300 / 1130] avg_train_loss: 0.4861 | train_auc: 0.9311 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [400 / 1130] avg_train_loss: 0.5043 | train_auc: 0.9217 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [500 / 1130] avg_train_loss: 0.4941 | train_auc: 0.928 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [600 / 1130] avg_train_loss: 0.4954 | train_auc: 0.927 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [700 / 1130] avg_train_loss: 0.5022 | train_auc: 0.922 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [800 / 1130] avg_train_loss: 0.5001 | train_auc: 0.9234 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [900 / 1130] avg_train_loss: 0.5021 | train_auc: 0.9235 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [1000 / 1130] avg_train_loss: 0.4985 | train_auc: 0.9253 | lr : 7.289999999999999e-09
Epoch [38 / 100] Step: [1100 / 1130] avg_train_loss: 0.4988 | train_auc: 0.9268 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 38 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.434 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 38 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4887 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 38 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6054 | val_auc: 0.5556 | lr: 7.289999999999999e-09
[Epoch: 38 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7095 | val_auc: 0.5552 | lr: 7.289999999999999e-09
[Epoch: 38 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7348 | val_auc: 0.6154 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 39
[TRAIN] Train model
Epoch [39 / 100] Step: [100 / 1130] avg_train_loss: 0.5075 | train_auc: 0.9166 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [200 / 1130] avg_train_loss: 0.5237 | train_auc: 0.9178 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [300 / 1130] avg_train_loss: 0.5074 | train_auc: 0.9214 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [400 / 1130] avg_train_loss: 0.5155 | train_auc: 0.915 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [500 / 1130] avg_train_loss: 0.5009 | train_auc: 0.9246 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [600 / 1130] avg_train_loss: 0.4946 | train_auc: 0.9254 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [700 / 1130] avg_train_loss: 0.4964 | train_auc: 0.9259 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [800 / 1130] avg_train_loss: 0.4806 | train_auc: 0.9325 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [900 / 1130] avg_train_loss: 0.482 | train_auc: 0.9311 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [1000 / 1130] avg_train_loss: 0.4798 | train_auc: 0.9332 | lr : 7.289999999999999e-09
Epoch [39 / 100] Step: [1100 / 1130] avg_train_loss: 0.4789 | train_auc: 0.9327 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 39 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3639 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 39 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4298 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 39 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5432 | val_auc: 0.627 | lr: 7.289999999999999e-09
[Epoch: 39 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6831 | val_auc: 0.5688 | lr: 7.289999999999999e-09
[Epoch: 39 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7126 | val_auc: 0.6404 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 40
[TRAIN] Train model
Epoch [40 / 100] Step: [100 / 1130] avg_train_loss: 0.4672 | train_auc: 0.9337 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [200 / 1130] avg_train_loss: 0.4723 | train_auc: 0.9348 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [300 / 1130] avg_train_loss: 0.4666 | train_auc: 0.942 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [400 / 1130] avg_train_loss: 0.4514 | train_auc: 0.9494 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [500 / 1130] avg_train_loss: 0.4659 | train_auc: 0.9441 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [600 / 1130] avg_train_loss: 0.4635 | train_auc: 0.9399 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [700 / 1130] avg_train_loss: 0.4747 | train_auc: 0.9345 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [800 / 1130] avg_train_loss: 0.4815 | train_auc: 0.9321 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [900 / 1130] avg_train_loss: 0.4741 | train_auc: 0.9372 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [1000 / 1130] avg_train_loss: 0.477 | train_auc: 0.9353 | lr : 7.289999999999999e-09
Epoch [40 / 100] Step: [1100 / 1130] avg_train_loss: 0.4757 | train_auc: 0.9362 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 40 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3669 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 40 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4401 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 40 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5474 | val_auc: 0.7063 | lr: 7.289999999999999e-09
[Epoch: 40 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6706 | val_auc: 0.6367 | lr: 7.289999999999999e-09
[Epoch: 40 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7143 | val_auc: 0.6564 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 41
[TRAIN] Train model
Epoch [41 / 100] Step: [100 / 1130] avg_train_loss: 0.5077 | train_auc: 0.946 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [200 / 1130] avg_train_loss: 0.486 | train_auc: 0.9356 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [300 / 1130] avg_train_loss: 0.4675 | train_auc: 0.944 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [400 / 1130] avg_train_loss: 0.4458 | train_auc: 0.9531 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [500 / 1130] avg_train_loss: 0.4739 | train_auc: 0.942 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [600 / 1130] avg_train_loss: 0.4715 | train_auc: 0.943 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [700 / 1130] avg_train_loss: 0.4709 | train_auc: 0.9427 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [800 / 1130] avg_train_loss: 0.4892 | train_auc: 0.9337 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [900 / 1130] avg_train_loss: 0.4862 | train_auc: 0.9339 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [1000 / 1130] avg_train_loss: 0.487 | train_auc: 0.9347 | lr : 7.289999999999999e-09
Epoch [41 / 100] Step: [1100 / 1130] avg_train_loss: 0.4877 | train_auc: 0.9351 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 41 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4086 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 41 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4878 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 41 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5976 | val_auc: 0.5899 | lr: 7.289999999999999e-09
[Epoch: 41 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7114 | val_auc: 0.5458 | lr: 7.289999999999999e-09
[Epoch: 41 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.725 | val_auc: 0.6337 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 42
[TRAIN] Train model
Epoch [42 / 100] Step: [100 / 1130] avg_train_loss: 0.5343 | train_auc: 0.914 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [200 / 1130] avg_train_loss: 0.4957 | train_auc: 0.9231 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [300 / 1130] avg_train_loss: 0.5136 | train_auc: 0.9154 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [400 / 1130] avg_train_loss: 0.4968 | train_auc: 0.9226 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [500 / 1130] avg_train_loss: 0.4901 | train_auc: 0.9249 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [600 / 1130] avg_train_loss: 0.4893 | train_auc: 0.9234 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [700 / 1130] avg_train_loss: 0.4821 | train_auc: 0.9283 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [800 / 1130] avg_train_loss: 0.4887 | train_auc: 0.9269 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [900 / 1130] avg_train_loss: 0.4966 | train_auc: 0.9236 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [1000 / 1130] avg_train_loss: 0.4926 | train_auc: 0.9266 | lr : 7.289999999999999e-09
Epoch [42 / 100] Step: [1100 / 1130] avg_train_loss: 0.4872 | train_auc: 0.9274 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 42 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3757 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 42 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4352 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 42 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5692 | val_auc: 0.5661 | lr: 7.289999999999999e-09
[Epoch: 42 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.705 | val_auc: 0.5314 | lr: 7.289999999999999e-09
[Epoch: 42 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.744 | val_auc: 0.602 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 43
[TRAIN] Train model
Epoch [43 / 100] Step: [100 / 1130] avg_train_loss: 0.4045 | train_auc: 0.9777 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [200 / 1130] avg_train_loss: 0.4273 | train_auc: 0.966 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [300 / 1130] avg_train_loss: 0.4433 | train_auc: 0.9531 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [400 / 1130] avg_train_loss: 0.4514 | train_auc: 0.9498 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [500 / 1130] avg_train_loss: 0.4641 | train_auc: 0.9433 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [600 / 1130] avg_train_loss: 0.4698 | train_auc: 0.9421 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [700 / 1130] avg_train_loss: 0.4695 | train_auc: 0.942 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [800 / 1130] avg_train_loss: 0.4664 | train_auc: 0.942 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [900 / 1130] avg_train_loss: 0.4616 | train_auc: 0.9436 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [1000 / 1130] avg_train_loss: 0.4661 | train_auc: 0.9417 | lr : 7.289999999999999e-09
Epoch [43 / 100] Step: [1100 / 1130] avg_train_loss: 0.4737 | train_auc: 0.9371 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 43 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3947 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 43 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4408 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 43 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5953 | val_auc: 0.5079 | lr: 7.289999999999999e-09
[Epoch: 43 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7211 | val_auc: 0.5178 | lr: 7.289999999999999e-09
[Epoch: 43 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7505 | val_auc: 0.6012 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 44
[TRAIN] Train model
Epoch [44 / 100] Step: [100 / 1130] avg_train_loss: 0.4422 | train_auc: 0.9504 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [200 / 1130] avg_train_loss: 0.4409 | train_auc: 0.9513 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [300 / 1130] avg_train_loss: 0.4729 | train_auc: 0.9424 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [400 / 1130] avg_train_loss: 0.4669 | train_auc: 0.9437 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [500 / 1130] avg_train_loss: 0.4712 | train_auc: 0.9403 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [600 / 1130] avg_train_loss: 0.4792 | train_auc: 0.9376 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [700 / 1130] avg_train_loss: 0.4857 | train_auc: 0.934 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [800 / 1130] avg_train_loss: 0.4826 | train_auc: 0.9342 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [900 / 1130] avg_train_loss: 0.4906 | train_auc: 0.9291 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [1000 / 1130] avg_train_loss: 0.4899 | train_auc: 0.9282 | lr : 7.289999999999999e-09
Epoch [44 / 100] Step: [1100 / 1130] avg_train_loss: 0.4893 | train_auc: 0.9289 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 44 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3336 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 44 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.3976 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 44 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5292 | val_auc: 0.6693 | lr: 7.289999999999999e-09
[Epoch: 44 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6732 | val_auc: 0.6087 | lr: 7.289999999999999e-09
[Epoch: 44 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7295 | val_auc: 0.639 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 45
[TRAIN] Train model
Epoch [45 / 100] Step: [100 / 1130] avg_train_loss: 0.5055 | train_auc: 0.9229 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [200 / 1130] avg_train_loss: 0.5245 | train_auc: 0.9107 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [300 / 1130] avg_train_loss: 0.4957 | train_auc: 0.9273 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [400 / 1130] avg_train_loss: 0.4793 | train_auc: 0.9348 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [500 / 1130] avg_train_loss: 0.4913 | train_auc: 0.928 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [600 / 1130] avg_train_loss: 0.5065 | train_auc: 0.916 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [700 / 1130] avg_train_loss: 0.5015 | train_auc: 0.9188 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [800 / 1130] avg_train_loss: 0.4985 | train_auc: 0.9205 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [900 / 1130] avg_train_loss: 0.4877 | train_auc: 0.9263 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [1000 / 1130] avg_train_loss: 0.4846 | train_auc: 0.9296 | lr : 7.289999999999999e-09
Epoch [45 / 100] Step: [1100 / 1130] avg_train_loss: 0.4895 | train_auc: 0.9292 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 45 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.411 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 45 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.475 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 45 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5812 | val_auc: 0.5635 | lr: 7.289999999999999e-09
[Epoch: 45 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6982 | val_auc: 0.5365 | lr: 7.289999999999999e-09
[Epoch: 45 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7249 | val_auc: 0.6145 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 46
[TRAIN] Train model
Epoch [46 / 100] Step: [100 / 1130] avg_train_loss: 0.4889 | train_auc: 0.9255 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [200 / 1130] avg_train_loss: 0.4905 | train_auc: 0.9155 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [300 / 1130] avg_train_loss: 0.4946 | train_auc: 0.9239 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [400 / 1130] avg_train_loss: 0.5132 | train_auc: 0.915 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [500 / 1130] avg_train_loss: 0.5021 | train_auc: 0.92 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [600 / 1130] avg_train_loss: 0.4956 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [700 / 1130] avg_train_loss: 0.4899 | train_auc: 0.9297 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [800 / 1130] avg_train_loss: 0.4789 | train_auc: 0.9354 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [900 / 1130] avg_train_loss: 0.4681 | train_auc: 0.9397 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [1000 / 1130] avg_train_loss: 0.4687 | train_auc: 0.9387 | lr : 7.289999999999999e-09
Epoch [46 / 100] Step: [1100 / 1130] avg_train_loss: 0.4781 | train_auc: 0.9352 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 46 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3915 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 46 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4529 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 46 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5875 | val_auc: 0.5212 | lr: 7.289999999999999e-09
[Epoch: 46 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7045 | val_auc: 0.528 | lr: 7.289999999999999e-09
[Epoch: 46 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7365 | val_auc: 0.6101 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 47
[TRAIN] Train model
Epoch [47 / 100] Step: [100 / 1130] avg_train_loss: 0.4216 | train_auc: 0.9569 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [200 / 1130] avg_train_loss: 0.4797 | train_auc: 0.9378 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [300 / 1130] avg_train_loss: 0.4439 | train_auc: 0.9543 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [400 / 1130] avg_train_loss: 0.4464 | train_auc: 0.9502 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [500 / 1130] avg_train_loss: 0.4677 | train_auc: 0.944 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [600 / 1130] avg_train_loss: 0.4644 | train_auc: 0.9443 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [700 / 1130] avg_train_loss: 0.4761 | train_auc: 0.9376 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [800 / 1130] avg_train_loss: 0.4846 | train_auc: 0.9347 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [900 / 1130] avg_train_loss: 0.486 | train_auc: 0.9335 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [1000 / 1130] avg_train_loss: 0.4786 | train_auc: 0.9367 | lr : 7.289999999999999e-09
Epoch [47 / 100] Step: [1100 / 1130] avg_train_loss: 0.483 | train_auc: 0.9342 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 47 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3431 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 47 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4013 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 47 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5297 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 47 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.67 | val_auc: 0.5823 | lr: 7.289999999999999e-09
[Epoch: 47 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.713 | val_auc: 0.6404 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 48
[TRAIN] Train model
Epoch [48 / 100] Step: [100 / 1130] avg_train_loss: 0.4698 | train_auc: 0.932 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [200 / 1130] avg_train_loss: 0.4727 | train_auc: 0.9289 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [300 / 1130] avg_train_loss: 0.4666 | train_auc: 0.9349 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [400 / 1130] avg_train_loss: 0.4961 | train_auc: 0.9226 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [500 / 1130] avg_train_loss: 0.5011 | train_auc: 0.9269 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [600 / 1130] avg_train_loss: 0.5125 | train_auc: 0.9207 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [700 / 1130] avg_train_loss: 0.5171 | train_auc: 0.9188 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [800 / 1130] avg_train_loss: 0.5214 | train_auc: 0.9164 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [900 / 1130] avg_train_loss: 0.5271 | train_auc: 0.9151 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [1000 / 1130] avg_train_loss: 0.5216 | train_auc: 0.917 | lr : 7.289999999999999e-09
Epoch [48 / 100] Step: [1100 / 1130] avg_train_loss: 0.5103 | train_auc: 0.921 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 48 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4136 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 48 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4857 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 48 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6014 | val_auc: 0.4868 | lr: 7.289999999999999e-09
[Epoch: 48 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7234 | val_auc: 0.4907 | lr: 7.289999999999999e-09
[Epoch: 48 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.744 | val_auc: 0.5922 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 49
[TRAIN] Train model
Epoch [49 / 100] Step: [100 / 1130] avg_train_loss: 0.5461 | train_auc: 0.9158 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [200 / 1130] avg_train_loss: 0.5379 | train_auc: 0.9145 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [300 / 1130] avg_train_loss: 0.5193 | train_auc: 0.9273 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [400 / 1130] avg_train_loss: 0.5178 | train_auc: 0.9304 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [500 / 1130] avg_train_loss: 0.523 | train_auc: 0.9221 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [600 / 1130] avg_train_loss: 0.517 | train_auc: 0.9236 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [700 / 1130] avg_train_loss: 0.4986 | train_auc: 0.9294 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [800 / 1130] avg_train_loss: 0.4965 | train_auc: 0.9307 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [900 / 1130] avg_train_loss: 0.4904 | train_auc: 0.9328 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [1000 / 1130] avg_train_loss: 0.487 | train_auc: 0.9343 | lr : 7.289999999999999e-09
Epoch [49 / 100] Step: [1100 / 1130] avg_train_loss: 0.4903 | train_auc: 0.9322 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 49 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3809 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 49 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4585 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 49 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5803 | val_auc: 0.627 | lr: 7.289999999999999e-09
[Epoch: 49 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.693 | val_auc: 0.5849 | lr: 7.289999999999999e-09
[Epoch: 49 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7199 | val_auc: 0.6368 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 50
[TRAIN] Train model
Epoch [50 / 100] Step: [100 / 1130] avg_train_loss: 0.4678 | train_auc: 0.934 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [200 / 1130] avg_train_loss: 0.426 | train_auc: 0.955 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [300 / 1130] avg_train_loss: 0.4691 | train_auc: 0.9367 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [400 / 1130] avg_train_loss: 0.4901 | train_auc: 0.9301 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [500 / 1130] avg_train_loss: 0.492 | train_auc: 0.9296 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [600 / 1130] avg_train_loss: 0.4887 | train_auc: 0.9331 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [700 / 1130] avg_train_loss: 0.4916 | train_auc: 0.9295 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [800 / 1130] avg_train_loss: 0.4981 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [900 / 1130] avg_train_loss: 0.492 | train_auc: 0.9281 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [1000 / 1130] avg_train_loss: 0.492 | train_auc: 0.9288 | lr : 7.289999999999999e-09
Epoch [50 / 100] Step: [1100 / 1130] avg_train_loss: 0.4928 | train_auc: 0.929 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 50 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3358 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 50 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.3945 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 50 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5276 | val_auc: 0.5952 | lr: 7.289999999999999e-09
[Epoch: 50 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6683 | val_auc: 0.5764 | lr: 7.289999999999999e-09
[Epoch: 50 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7093 | val_auc: 0.6448 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 51
[TRAIN] Train model
Epoch [51 / 100] Step: [100 / 1130] avg_train_loss: 0.4924 | train_auc: 0.9274 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [200 / 1130] avg_train_loss: 0.5193 | train_auc: 0.9222 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [300 / 1130] avg_train_loss: 0.4923 | train_auc: 0.9335 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [400 / 1130] avg_train_loss: 0.5047 | train_auc: 0.9215 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [500 / 1130] avg_train_loss: 0.4879 | train_auc: 0.9306 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [600 / 1130] avg_train_loss: 0.5002 | train_auc: 0.9234 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [700 / 1130] avg_train_loss: 0.4954 | train_auc: 0.9274 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [800 / 1130] avg_train_loss: 0.4964 | train_auc: 0.9277 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [900 / 1130] avg_train_loss: 0.5045 | train_auc: 0.9246 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [1000 / 1130] avg_train_loss: 0.5061 | train_auc: 0.9227 | lr : 7.289999999999999e-09
Epoch [51 / 100] Step: [1100 / 1130] avg_train_loss: 0.5015 | train_auc: 0.9236 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 51 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3809 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 51 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.445 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 51 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.566 | val_auc: 0.6032 | lr: 7.289999999999999e-09
[Epoch: 51 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6942 | val_auc: 0.5424 | lr: 7.289999999999999e-09
[Epoch: 51 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7227 | val_auc: 0.619 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 52
[TRAIN] Train model
Epoch [52 / 100] Step: [100 / 1130] avg_train_loss: 0.5821 | train_auc: 0.8889 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [200 / 1130] avg_train_loss: 0.5128 | train_auc: 0.9218 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [300 / 1130] avg_train_loss: 0.5024 | train_auc: 0.9299 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [400 / 1130] avg_train_loss: 0.4892 | train_auc: 0.9359 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [500 / 1130] avg_train_loss: 0.4829 | train_auc: 0.9397 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [600 / 1130] avg_train_loss: 0.4788 | train_auc: 0.9405 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [700 / 1130] avg_train_loss: 0.4639 | train_auc: 0.9464 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [800 / 1130] avg_train_loss: 0.4638 | train_auc: 0.9457 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [900 / 1130] avg_train_loss: 0.4642 | train_auc: 0.9449 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [1000 / 1130] avg_train_loss: 0.4749 | train_auc: 0.9399 | lr : 7.289999999999999e-09
Epoch [52 / 100] Step: [1100 / 1130] avg_train_loss: 0.4736 | train_auc: 0.94 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 52 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3907 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 52 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4694 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 52 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5671 | val_auc: 0.6772 | lr: 7.289999999999999e-09
[Epoch: 52 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6906 | val_auc: 0.6044 | lr: 7.289999999999999e-09
[Epoch: 52 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7213 | val_auc: 0.6488 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 53
[TRAIN] Train model
Epoch [53 / 100] Step: [100 / 1130] avg_train_loss: 0.5172 | train_auc: 0.9316 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [200 / 1130] avg_train_loss: 0.5118 | train_auc: 0.9269 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [300 / 1130] avg_train_loss: 0.4968 | train_auc: 0.9292 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [400 / 1130] avg_train_loss: 0.478 | train_auc: 0.9381 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [500 / 1130] avg_train_loss: 0.4894 | train_auc: 0.9301 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [600 / 1130] avg_train_loss: 0.4963 | train_auc: 0.926 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [700 / 1130] avg_train_loss: 0.4989 | train_auc: 0.9261 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [800 / 1130] avg_train_loss: 0.5007 | train_auc: 0.9226 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [900 / 1130] avg_train_loss: 0.4918 | train_auc: 0.9275 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [1000 / 1130] avg_train_loss: 0.4885 | train_auc: 0.9302 | lr : 7.289999999999999e-09
Epoch [53 / 100] Step: [1100 / 1130] avg_train_loss: 0.4821 | train_auc: 0.9336 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 53 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3627 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 53 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4296 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 53 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5448 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 53 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6727 | val_auc: 0.6121 | lr: 7.289999999999999e-09
[Epoch: 53 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7115 | val_auc: 0.6578 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 54
[TRAIN] Train model
Epoch [54 / 100] Step: [100 / 1130] avg_train_loss: 0.4851 | train_auc: 0.9066 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [200 / 1130] avg_train_loss: 0.4959 | train_auc: 0.919 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [300 / 1130] avg_train_loss: 0.5268 | train_auc: 0.9142 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [400 / 1130] avg_train_loss: 0.5372 | train_auc: 0.9065 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [500 / 1130] avg_train_loss: 0.521 | train_auc: 0.9136 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [600 / 1130] avg_train_loss: 0.5065 | train_auc: 0.9196 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [700 / 1130] avg_train_loss: 0.5032 | train_auc: 0.9217 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [800 / 1130] avg_train_loss: 0.4994 | train_auc: 0.9239 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [900 / 1130] avg_train_loss: 0.4915 | train_auc: 0.9288 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [1000 / 1130] avg_train_loss: 0.4956 | train_auc: 0.93 | lr : 7.289999999999999e-09
Epoch [54 / 100] Step: [1100 / 1130] avg_train_loss: 0.495 | train_auc: 0.9302 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 54 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4315 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 54 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5154 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 54 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6263 | val_auc: 0.5423 | lr: 7.289999999999999e-09
[Epoch: 54 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7329 | val_auc: 0.534 | lr: 7.289999999999999e-09
[Epoch: 54 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.748 | val_auc: 0.6114 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 55
[TRAIN] Train model
Epoch [55 / 100] Step: [100 / 1130] avg_train_loss: 0.5275 | train_auc: 0.9064 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [200 / 1130] avg_train_loss: 0.4919 | train_auc: 0.9219 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [300 / 1130] avg_train_loss: 0.5022 | train_auc: 0.9195 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [400 / 1130] avg_train_loss: 0.5277 | train_auc: 0.908 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [500 / 1130] avg_train_loss: 0.5385 | train_auc: 0.9032 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [600 / 1130] avg_train_loss: 0.5252 | train_auc: 0.909 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [700 / 1130] avg_train_loss: 0.5071 | train_auc: 0.9186 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [800 / 1130] avg_train_loss: 0.5051 | train_auc: 0.9199 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [900 / 1130] avg_train_loss: 0.5159 | train_auc: 0.9163 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [1000 / 1130] avg_train_loss: 0.5102 | train_auc: 0.9189 | lr : 7.289999999999999e-09
Epoch [55 / 100] Step: [1100 / 1130] avg_train_loss: 0.5088 | train_auc: 0.919 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 55 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3923 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 55 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4578 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 55 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5736 | val_auc: 0.6243 | lr: 7.289999999999999e-09
[Epoch: 55 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.696 | val_auc: 0.5857 | lr: 7.289999999999999e-09
[Epoch: 55 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7252 | val_auc: 0.6373 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 56
[TRAIN] Train model
Epoch [56 / 100] Step: [100 / 1130] avg_train_loss: 0.4525 | train_auc: 0.9564 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [200 / 1130] avg_train_loss: 0.4655 | train_auc: 0.9453 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [300 / 1130] avg_train_loss: 0.4669 | train_auc: 0.9484 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [400 / 1130] avg_train_loss: 0.4666 | train_auc: 0.9433 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [500 / 1130] avg_train_loss: 0.4759 | train_auc: 0.94 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [600 / 1130] avg_train_loss: 0.4823 | train_auc: 0.9365 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [700 / 1130] avg_train_loss: 0.4864 | train_auc: 0.933 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [800 / 1130] avg_train_loss: 0.4888 | train_auc: 0.9324 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [900 / 1130] avg_train_loss: 0.4911 | train_auc: 0.9311 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [1000 / 1130] avg_train_loss: 0.487 | train_auc: 0.9335 | lr : 7.289999999999999e-09
Epoch [56 / 100] Step: [1100 / 1130] avg_train_loss: 0.4827 | train_auc: 0.9363 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 56 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4429 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 56 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5263 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 56 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6323 | val_auc: 0.5899 | lr: 7.289999999999999e-09
[Epoch: 56 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7319 | val_auc: 0.5475 | lr: 7.289999999999999e-09
[Epoch: 56 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7463 | val_auc: 0.6181 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 57
[TRAIN] Train model
Epoch [57 / 100] Step: [100 / 1130] avg_train_loss: 0.5045 | train_auc: 0.9457 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [200 / 1130] avg_train_loss: 0.4893 | train_auc: 0.9371 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [300 / 1130] avg_train_loss: 0.5037 | train_auc: 0.926 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [400 / 1130] avg_train_loss: 0.501 | train_auc: 0.9245 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [500 / 1130] avg_train_loss: 0.4909 | train_auc: 0.9304 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [600 / 1130] avg_train_loss: 0.5029 | train_auc: 0.9273 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [700 / 1130] avg_train_loss: 0.4938 | train_auc: 0.9292 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [800 / 1130] avg_train_loss: 0.484 | train_auc: 0.9325 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [900 / 1130] avg_train_loss: 0.4847 | train_auc: 0.9318 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [1000 / 1130] avg_train_loss: 0.4927 | train_auc: 0.9287 | lr : 7.289999999999999e-09
Epoch [57 / 100] Step: [1100 / 1130] avg_train_loss: 0.496 | train_auc: 0.9281 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 57 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3859 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 57 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4504 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 57 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5864 | val_auc: 0.537 | lr: 7.289999999999999e-09
[Epoch: 57 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7086 | val_auc: 0.5323 | lr: 7.289999999999999e-09
[Epoch: 57 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7388 | val_auc: 0.5998 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 58
[TRAIN] Train model
Epoch [58 / 100] Step: [100 / 1130] avg_train_loss: 0.4347 | train_auc: 0.9499 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [200 / 1130] avg_train_loss: 0.4731 | train_auc: 0.9368 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [300 / 1130] avg_train_loss: 0.4658 | train_auc: 0.944 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [400 / 1130] avg_train_loss: 0.4688 | train_auc: 0.9409 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [500 / 1130] avg_train_loss: 0.4627 | train_auc: 0.945 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [600 / 1130] avg_train_loss: 0.4866 | train_auc: 0.932 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [700 / 1130] avg_train_loss: 0.4963 | train_auc: 0.9278 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [800 / 1130] avg_train_loss: 0.4868 | train_auc: 0.9326 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [900 / 1130] avg_train_loss: 0.4822 | train_auc: 0.9356 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [1000 / 1130] avg_train_loss: 0.487 | train_auc: 0.9342 | lr : 7.289999999999999e-09
Epoch [58 / 100] Step: [1100 / 1130] avg_train_loss: 0.4883 | train_auc: 0.9333 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 58 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3878 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 58 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4741 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 58 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5908 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 58 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7154 | val_auc: 0.5756 | lr: 7.289999999999999e-09
[Epoch: 58 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7367 | val_auc: 0.6368 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 59
[TRAIN] Train model
Epoch [59 / 100] Step: [100 / 1130] avg_train_loss: 0.5806 | train_auc: 0.8992 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [200 / 1130] avg_train_loss: 0.592 | train_auc: 0.8924 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [300 / 1130] avg_train_loss: 0.5509 | train_auc: 0.9034 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [400 / 1130] avg_train_loss: 0.5248 | train_auc: 0.9174 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [500 / 1130] avg_train_loss: 0.5307 | train_auc: 0.9115 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [600 / 1130] avg_train_loss: 0.5275 | train_auc: 0.9122 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [700 / 1130] avg_train_loss: 0.5264 | train_auc: 0.9126 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [800 / 1130] avg_train_loss: 0.524 | train_auc: 0.9141 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [900 / 1130] avg_train_loss: 0.527 | train_auc: 0.9134 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [1000 / 1130] avg_train_loss: 0.5248 | train_auc: 0.9139 | lr : 7.289999999999999e-09
Epoch [59 / 100] Step: [1100 / 1130] avg_train_loss: 0.5183 | train_auc: 0.9174 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 59 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4271 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 59 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5077 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 59 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6234 | val_auc: 0.6164 | lr: 7.289999999999999e-09
[Epoch: 59 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7215 | val_auc: 0.5764 | lr: 7.289999999999999e-09
[Epoch: 59 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7485 | val_auc: 0.619 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 60
[TRAIN] Train model
Epoch [60 / 100] Step: [100 / 1130] avg_train_loss: 0.524 | train_auc: 0.9144 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [200 / 1130] avg_train_loss: 0.5234 | train_auc: 0.9122 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [300 / 1130] avg_train_loss: 0.5216 | train_auc: 0.9106 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [400 / 1130] avg_train_loss: 0.5236 | train_auc: 0.9101 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [500 / 1130] avg_train_loss: 0.5063 | train_auc: 0.9218 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [600 / 1130] avg_train_loss: 0.4923 | train_auc: 0.9281 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [700 / 1130] avg_train_loss: 0.4862 | train_auc: 0.9335 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [800 / 1130] avg_train_loss: 0.4848 | train_auc: 0.934 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [900 / 1130] avg_train_loss: 0.4881 | train_auc: 0.9339 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [1000 / 1130] avg_train_loss: 0.4873 | train_auc: 0.9327 | lr : 7.289999999999999e-09
Epoch [60 / 100] Step: [1100 / 1130] avg_train_loss: 0.4867 | train_auc: 0.9323 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 60 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4083 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 60 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4687 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 60 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5975 | val_auc: 0.5556 | lr: 7.289999999999999e-09
[Epoch: 60 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7149 | val_auc: 0.534 | lr: 7.289999999999999e-09
[Epoch: 60 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7411 | val_auc: 0.6092 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 61
[TRAIN] Train model
Epoch [61 / 100] Step: [100 / 1130] avg_train_loss: 0.5384 | train_auc: 0.914 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [200 / 1130] avg_train_loss: 0.5302 | train_auc: 0.9144 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [300 / 1130] avg_train_loss: 0.5177 | train_auc: 0.921 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [400 / 1130] avg_train_loss: 0.5135 | train_auc: 0.9234 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [500 / 1130] avg_train_loss: 0.501 | train_auc: 0.9259 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [600 / 1130] avg_train_loss: 0.4976 | train_auc: 0.9284 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [700 / 1130] avg_train_loss: 0.4904 | train_auc: 0.9323 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [800 / 1130] avg_train_loss: 0.4984 | train_auc: 0.9271 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [900 / 1130] avg_train_loss: 0.492 | train_auc: 0.9304 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [1000 / 1130] avg_train_loss: 0.4931 | train_auc: 0.9295 | lr : 7.289999999999999e-09
Epoch [61 / 100] Step: [1100 / 1130] avg_train_loss: 0.4942 | train_auc: 0.9291 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 61 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3952 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 61 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4708 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 61 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5942 | val_auc: 0.537 | lr: 7.289999999999999e-09
[Epoch: 61 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7093 | val_auc: 0.528 | lr: 7.289999999999999e-09
[Epoch: 61 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7323 | val_auc: 0.6101 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 62
[TRAIN] Train model
Epoch [62 / 100] Step: [100 / 1130] avg_train_loss: 0.4493 | train_auc: 0.9496 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [200 / 1130] avg_train_loss: 0.4709 | train_auc: 0.9431 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [300 / 1130] avg_train_loss: 0.4505 | train_auc: 0.9479 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [400 / 1130] avg_train_loss: 0.4561 | train_auc: 0.9488 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [500 / 1130] avg_train_loss: 0.4543 | train_auc: 0.9507 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [600 / 1130] avg_train_loss: 0.4634 | train_auc: 0.9487 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [700 / 1130] avg_train_loss: 0.4624 | train_auc: 0.9496 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [800 / 1130] avg_train_loss: 0.4627 | train_auc: 0.9488 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [900 / 1130] avg_train_loss: 0.4776 | train_auc: 0.9424 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [1000 / 1130] avg_train_loss: 0.4815 | train_auc: 0.9399 | lr : 7.289999999999999e-09
Epoch [62 / 100] Step: [1100 / 1130] avg_train_loss: 0.4812 | train_auc: 0.9395 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 62 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.392 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 62 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4692 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 62 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.584 | val_auc: 0.5767 | lr: 7.289999999999999e-09
[Epoch: 62 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6981 | val_auc: 0.5696 | lr: 7.289999999999999e-09
[Epoch: 62 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7329 | val_auc: 0.6279 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 63
[TRAIN] Train model
Epoch [63 / 100] Step: [100 / 1130] avg_train_loss: 0.4917 | train_auc: 0.9291 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [200 / 1130] avg_train_loss: 0.4568 | train_auc: 0.9467 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [300 / 1130] avg_train_loss: 0.4893 | train_auc: 0.9332 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [400 / 1130] avg_train_loss: 0.4983 | train_auc: 0.9327 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [500 / 1130] avg_train_loss: 0.48 | train_auc: 0.9393 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [600 / 1130] avg_train_loss: 0.4754 | train_auc: 0.9401 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [700 / 1130] avg_train_loss: 0.4725 | train_auc: 0.9408 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [800 / 1130] avg_train_loss: 0.4824 | train_auc: 0.9373 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [900 / 1130] avg_train_loss: 0.485 | train_auc: 0.9368 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [1000 / 1130] avg_train_loss: 0.4871 | train_auc: 0.9344 | lr : 7.289999999999999e-09
Epoch [63 / 100] Step: [1100 / 1130] avg_train_loss: 0.4921 | train_auc: 0.9322 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 63 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3601 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 63 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4428 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 63 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5458 | val_auc: 0.6614 | lr: 7.289999999999999e-09
[Epoch: 63 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6855 | val_auc: 0.584 | lr: 7.289999999999999e-09
[Epoch: 63 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7212 | val_auc: 0.6413 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 64
[TRAIN] Train model
Epoch [64 / 100] Step: [100 / 1130] avg_train_loss: 0.4979 | train_auc: 0.9188 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [200 / 1130] avg_train_loss: 0.4689 | train_auc: 0.9354 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [300 / 1130] avg_train_loss: 0.4615 | train_auc: 0.9453 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [400 / 1130] avg_train_loss: 0.4803 | train_auc: 0.9351 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [500 / 1130] avg_train_loss: 0.4667 | train_auc: 0.9385 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [600 / 1130] avg_train_loss: 0.4863 | train_auc: 0.9296 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [700 / 1130] avg_train_loss: 0.4884 | train_auc: 0.9297 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [800 / 1130] avg_train_loss: 0.4995 | train_auc: 0.9251 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [900 / 1130] avg_train_loss: 0.4944 | train_auc: 0.9269 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [1000 / 1130] avg_train_loss: 0.4925 | train_auc: 0.9263 | lr : 7.289999999999999e-09
Epoch [64 / 100] Step: [1100 / 1130] avg_train_loss: 0.4919 | train_auc: 0.9273 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 64 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3702 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 64 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4406 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 64 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5782 | val_auc: 0.5688 | lr: 7.289999999999999e-09
[Epoch: 64 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7123 | val_auc: 0.5187 | lr: 7.289999999999999e-09
[Epoch: 64 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.739 | val_auc: 0.6043 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 65
[TRAIN] Train model
Epoch [65 / 100] Step: [100 / 1130] avg_train_loss: 0.4651 | train_auc: 0.9412 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [200 / 1130] avg_train_loss: 0.4985 | train_auc: 0.9244 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [300 / 1130] avg_train_loss: 0.508 | train_auc: 0.9201 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [400 / 1130] avg_train_loss: 0.5047 | train_auc: 0.9218 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [500 / 1130] avg_train_loss: 0.494 | train_auc: 0.9279 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [600 / 1130] avg_train_loss: 0.4995 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [700 / 1130] avg_train_loss: 0.5015 | train_auc: 0.9242 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [800 / 1130] avg_train_loss: 0.5079 | train_auc: 0.9205 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [900 / 1130] avg_train_loss: 0.497 | train_auc: 0.9249 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [1000 / 1130] avg_train_loss: 0.4941 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [65 / 100] Step: [1100 / 1130] avg_train_loss: 0.497 | train_auc: 0.924 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 65 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3457 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 65 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4144 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 65 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5251 | val_auc: 0.7302 | lr: 7.289999999999999e-09
[Epoch: 65 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6731 | val_auc: 0.6188 | lr: 7.289999999999999e-09
[Epoch: 65 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7192 | val_auc: 0.6542 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 66
[TRAIN] Train model
Epoch [66 / 100] Step: [100 / 1130] avg_train_loss: 0.487 | train_auc: 0.934 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [200 / 1130] avg_train_loss: 0.4847 | train_auc: 0.9281 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [300 / 1130] avg_train_loss: 0.5118 | train_auc: 0.9169 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [400 / 1130] avg_train_loss: 0.4942 | train_auc: 0.9229 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [500 / 1130] avg_train_loss: 0.4946 | train_auc: 0.924 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [600 / 1130] avg_train_loss: 0.4916 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [700 / 1130] avg_train_loss: 0.4996 | train_auc: 0.9242 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [800 / 1130] avg_train_loss: 0.4918 | train_auc: 0.93 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [900 / 1130] avg_train_loss: 0.4894 | train_auc: 0.9328 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [1000 / 1130] avg_train_loss: 0.4956 | train_auc: 0.9309 | lr : 7.289999999999999e-09
Epoch [66 / 100] Step: [1100 / 1130] avg_train_loss: 0.4985 | train_auc: 0.9283 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 66 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4281 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 66 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5097 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 66 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6039 | val_auc: 0.627 | lr: 7.289999999999999e-09
[Epoch: 66 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7211 | val_auc: 0.5569 | lr: 7.289999999999999e-09
[Epoch: 66 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7379 | val_auc: 0.6266 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 67
[TRAIN] Train model
Epoch [67 / 100] Step: [100 / 1130] avg_train_loss: 0.469 | train_auc: 0.9454 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [200 / 1130] avg_train_loss: 0.4332 | train_auc: 0.9588 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [300 / 1130] avg_train_loss: 0.487 | train_auc: 0.9356 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [400 / 1130] avg_train_loss: 0.5071 | train_auc: 0.9278 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [500 / 1130] avg_train_loss: 0.4849 | train_auc: 0.9362 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [600 / 1130] avg_train_loss: 0.4788 | train_auc: 0.9381 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [700 / 1130] avg_train_loss: 0.4703 | train_auc: 0.9419 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [800 / 1130] avg_train_loss: 0.4775 | train_auc: 0.9372 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [900 / 1130] avg_train_loss: 0.4839 | train_auc: 0.9344 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [1000 / 1130] avg_train_loss: 0.4785 | train_auc: 0.937 | lr : 7.289999999999999e-09
Epoch [67 / 100] Step: [1100 / 1130] avg_train_loss: 0.4734 | train_auc: 0.9398 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 67 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3601 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 67 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4287 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 67 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5403 | val_auc: 0.6402 | lr: 7.289999999999999e-09
[Epoch: 67 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.681 | val_auc: 0.5823 | lr: 7.289999999999999e-09
[Epoch: 67 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7193 | val_auc: 0.6426 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 68
[TRAIN] Train model
Epoch [68 / 100] Step: [100 / 1130] avg_train_loss: 0.4804 | train_auc: 0.939 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [200 / 1130] avg_train_loss: 0.4891 | train_auc: 0.9318 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [300 / 1130] avg_train_loss: 0.4738 | train_auc: 0.9382 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [400 / 1130] avg_train_loss: 0.4646 | train_auc: 0.9431 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [500 / 1130] avg_train_loss: 0.4805 | train_auc: 0.9319 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [600 / 1130] avg_train_loss: 0.4878 | train_auc: 0.9296 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [700 / 1130] avg_train_loss: 0.4884 | train_auc: 0.9282 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [800 / 1130] avg_train_loss: 0.4896 | train_auc: 0.929 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [900 / 1130] avg_train_loss: 0.4931 | train_auc: 0.9274 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [1000 / 1130] avg_train_loss: 0.4902 | train_auc: 0.9278 | lr : 7.289999999999999e-09
Epoch [68 / 100] Step: [1100 / 1130] avg_train_loss: 0.4866 | train_auc: 0.9305 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 68 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3627 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 68 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4172 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 68 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5621 | val_auc: 0.5847 | lr: 7.289999999999999e-09
[Epoch: 68 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6939 | val_auc: 0.5433 | lr: 7.289999999999999e-09
[Epoch: 68 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7232 | val_auc: 0.6168 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 69
[TRAIN] Train model
Epoch [69 / 100] Step: [100 / 1130] avg_train_loss: 0.4834 | train_auc: 0.9366 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [200 / 1130] avg_train_loss: 0.5073 | train_auc: 0.9321 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [300 / 1130] avg_train_loss: 0.4698 | train_auc: 0.9429 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [400 / 1130] avg_train_loss: 0.4579 | train_auc: 0.9449 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [500 / 1130] avg_train_loss: 0.4573 | train_auc: 0.9469 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [600 / 1130] avg_train_loss: 0.4651 | train_auc: 0.9409 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [700 / 1130] avg_train_loss: 0.4626 | train_auc: 0.9419 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [800 / 1130] avg_train_loss: 0.4766 | train_auc: 0.9342 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [900 / 1130] avg_train_loss: 0.4755 | train_auc: 0.9346 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [1000 / 1130] avg_train_loss: 0.4765 | train_auc: 0.9343 | lr : 7.289999999999999e-09
Epoch [69 / 100] Step: [1100 / 1130] avg_train_loss: 0.4774 | train_auc: 0.9333 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 69 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3732 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 69 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4507 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 69 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5745 | val_auc: 0.5556 | lr: 7.289999999999999e-09
[Epoch: 69 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.706 | val_auc: 0.5365 | lr: 7.289999999999999e-09
[Epoch: 69 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7343 | val_auc: 0.6168 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 70
[TRAIN] Train model
Epoch [70 / 100] Step: [100 / 1130] avg_train_loss: 0.5406 | train_auc: 0.8991 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [200 / 1130] avg_train_loss: 0.5203 | train_auc: 0.917 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [300 / 1130] avg_train_loss: 0.5095 | train_auc: 0.9168 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [400 / 1130] avg_train_loss: 0.5038 | train_auc: 0.9173 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [500 / 1130] avg_train_loss: 0.4935 | train_auc: 0.9241 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [600 / 1130] avg_train_loss: 0.4928 | train_auc: 0.9251 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [700 / 1130] avg_train_loss: 0.4843 | train_auc: 0.9304 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [800 / 1130] avg_train_loss: 0.4989 | train_auc: 0.9229 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [900 / 1130] avg_train_loss: 0.5001 | train_auc: 0.9231 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [1000 / 1130] avg_train_loss: 0.4992 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [70 / 100] Step: [1100 / 1130] avg_train_loss: 0.4972 | train_auc: 0.9278 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 70 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3521 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 70 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4123 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 70 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5447 | val_auc: 0.6376 | lr: 7.289999999999999e-09
[Epoch: 70 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6838 | val_auc: 0.5942 | lr: 7.289999999999999e-09
[Epoch: 70 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7291 | val_auc: 0.6341 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 71
[TRAIN] Train model
Epoch [71 / 100] Step: [100 / 1130] avg_train_loss: 0.4746 | train_auc: 0.9307 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [200 / 1130] avg_train_loss: 0.4989 | train_auc: 0.9262 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [300 / 1130] avg_train_loss: 0.47 | train_auc: 0.9377 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [400 / 1130] avg_train_loss: 0.4786 | train_auc: 0.9388 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [500 / 1130] avg_train_loss: 0.4712 | train_auc: 0.941 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [600 / 1130] avg_train_loss: 0.4736 | train_auc: 0.9412 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [700 / 1130] avg_train_loss: 0.4842 | train_auc: 0.9353 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [800 / 1130] avg_train_loss: 0.4857 | train_auc: 0.9345 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [900 / 1130] avg_train_loss: 0.484 | train_auc: 0.9379 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [1000 / 1130] avg_train_loss: 0.4791 | train_auc: 0.939 | lr : 7.289999999999999e-09
Epoch [71 / 100] Step: [1100 / 1130] avg_train_loss: 0.4777 | train_auc: 0.9398 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 71 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.366 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 71 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4465 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 71 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.559 | val_auc: 0.6349 | lr: 7.289999999999999e-09
[Epoch: 71 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6844 | val_auc: 0.5798 | lr: 7.289999999999999e-09
[Epoch: 71 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7086 | val_auc: 0.6484 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 72
[TRAIN] Train model
Epoch [72 / 100] Step: [100 / 1130] avg_train_loss: 0.5529 | train_auc: 0.9157 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [200 / 1130] avg_train_loss: 0.5314 | train_auc: 0.9306 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [300 / 1130] avg_train_loss: 0.5 | train_auc: 0.9336 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [400 / 1130] avg_train_loss: 0.5049 | train_auc: 0.9312 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [500 / 1130] avg_train_loss: 0.4964 | train_auc: 0.9332 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [600 / 1130] avg_train_loss: 0.4824 | train_auc: 0.9374 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [700 / 1130] avg_train_loss: 0.48 | train_auc: 0.9373 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [800 / 1130] avg_train_loss: 0.4805 | train_auc: 0.936 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [900 / 1130] avg_train_loss: 0.4829 | train_auc: 0.935 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [1000 / 1130] avg_train_loss: 0.4766 | train_auc: 0.9384 | lr : 7.289999999999999e-09
Epoch [72 / 100] Step: [1100 / 1130] avg_train_loss: 0.4728 | train_auc: 0.941 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 72 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4052 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 72 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4929 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 72 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6086 | val_auc: 0.5767 | lr: 7.289999999999999e-09
[Epoch: 72 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7175 | val_auc: 0.5475 | lr: 7.289999999999999e-09
[Epoch: 72 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7373 | val_auc: 0.6168 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 73
[TRAIN] Train model
Epoch [73 / 100] Step: [100 / 1130] avg_train_loss: 0.4374 | train_auc: 0.9577 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [200 / 1130] avg_train_loss: 0.4441 | train_auc: 0.9509 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [300 / 1130] avg_train_loss: 0.4597 | train_auc: 0.9413 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [400 / 1130] avg_train_loss: 0.468 | train_auc: 0.9392 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [500 / 1130] avg_train_loss: 0.4783 | train_auc: 0.9319 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [600 / 1130] avg_train_loss: 0.4774 | train_auc: 0.9337 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [700 / 1130] avg_train_loss: 0.4806 | train_auc: 0.9339 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [800 / 1130] avg_train_loss: 0.4729 | train_auc: 0.9378 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [900 / 1130] avg_train_loss: 0.4786 | train_auc: 0.9358 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [1000 / 1130] avg_train_loss: 0.4797 | train_auc: 0.936 | lr : 7.289999999999999e-09
Epoch [73 / 100] Step: [1100 / 1130] avg_train_loss: 0.4824 | train_auc: 0.9347 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 73 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3742 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 73 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4444 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 73 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5475 | val_auc: 0.7778 | lr: 7.289999999999999e-09
[Epoch: 73 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6658 | val_auc: 0.6817 | lr: 7.289999999999999e-09
[Epoch: 73 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7156 | val_auc: 0.6742 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 74
[TRAIN] Train model
Epoch [74 / 100] Step: [100 / 1130] avg_train_loss: 0.4637 | train_auc: 0.9504 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [200 / 1130] avg_train_loss: 0.4995 | train_auc: 0.9231 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [300 / 1130] avg_train_loss: 0.5294 | train_auc: 0.9056 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [400 / 1130] avg_train_loss: 0.5492 | train_auc: 0.8979 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [500 / 1130] avg_train_loss: 0.537 | train_auc: 0.9066 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [600 / 1130] avg_train_loss: 0.5163 | train_auc: 0.9192 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [700 / 1130] avg_train_loss: 0.5296 | train_auc: 0.9143 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [800 / 1130] avg_train_loss: 0.5126 | train_auc: 0.92 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [900 / 1130] avg_train_loss: 0.5105 | train_auc: 0.9216 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [1000 / 1130] avg_train_loss: 0.4938 | train_auc: 0.9286 | lr : 7.289999999999999e-09
Epoch [74 / 100] Step: [1100 / 1130] avg_train_loss: 0.496 | train_auc: 0.9275 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 74 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3628 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 74 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4129 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 74 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.543 | val_auc: 0.619 | lr: 7.289999999999999e-09
[Epoch: 74 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6648 | val_auc: 0.5951 | lr: 7.289999999999999e-09
[Epoch: 74 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7028 | val_auc: 0.6484 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 75
[TRAIN] Train model
Epoch [75 / 100] Step: [100 / 1130] avg_train_loss: 0.4628 | train_auc: 0.9389 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [200 / 1130] avg_train_loss: 0.492 | train_auc: 0.933 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [300 / 1130] avg_train_loss: 0.4723 | train_auc: 0.9423 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [400 / 1130] avg_train_loss: 0.4601 | train_auc: 0.9443 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [500 / 1130] avg_train_loss: 0.4752 | train_auc: 0.9379 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [600 / 1130] avg_train_loss: 0.4747 | train_auc: 0.9378 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [700 / 1130] avg_train_loss: 0.4823 | train_auc: 0.9332 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [800 / 1130] avg_train_loss: 0.4914 | train_auc: 0.9289 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [900 / 1130] avg_train_loss: 0.4912 | train_auc: 0.9294 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [1000 / 1130] avg_train_loss: 0.4914 | train_auc: 0.9302 | lr : 7.289999999999999e-09
Epoch [75 / 100] Step: [1100 / 1130] avg_train_loss: 0.4855 | train_auc: 0.9329 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 75 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3916 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 75 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4646 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 75 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5873 | val_auc: 0.6852 | lr: 7.289999999999999e-09
[Epoch: 75 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6982 | val_auc: 0.6282 | lr: 7.289999999999999e-09
[Epoch: 75 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7309 | val_auc: 0.6515 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 76
[TRAIN] Train model
Epoch [76 / 100] Step: [100 / 1130] avg_train_loss: 0.5714 | train_auc: 0.8915 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [200 / 1130] avg_train_loss: 0.504 | train_auc: 0.9197 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [300 / 1130] avg_train_loss: 0.5199 | train_auc: 0.9109 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [400 / 1130] avg_train_loss: 0.5261 | train_auc: 0.9119 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [500 / 1130] avg_train_loss: 0.5302 | train_auc: 0.9087 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [600 / 1130] avg_train_loss: 0.521 | train_auc: 0.9149 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [700 / 1130] avg_train_loss: 0.5033 | train_auc: 0.9232 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [800 / 1130] avg_train_loss: 0.5134 | train_auc: 0.9166 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [900 / 1130] avg_train_loss: 0.5109 | train_auc: 0.9179 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [1000 / 1130] avg_train_loss: 0.5016 | train_auc: 0.9228 | lr : 7.289999999999999e-09
Epoch [76 / 100] Step: [1100 / 1130] avg_train_loss: 0.5012 | train_auc: 0.9218 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 76 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3777 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 76 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4446 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 76 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.569 | val_auc: 0.5608 | lr: 7.289999999999999e-09
[Epoch: 76 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6859 | val_auc: 0.5518 | lr: 7.289999999999999e-09
[Epoch: 76 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7133 | val_auc: 0.6266 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 77
[TRAIN] Train model
Epoch [77 / 100] Step: [100 / 1130] avg_train_loss: 0.546 | train_auc: 0.9086 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [200 / 1130] avg_train_loss: 0.5387 | train_auc: 0.9124 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [300 / 1130] avg_train_loss: 0.5248 | train_auc: 0.9175 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [400 / 1130] avg_train_loss: 0.5474 | train_auc: 0.9043 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [500 / 1130] avg_train_loss: 0.5365 | train_auc: 0.9092 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [600 / 1130] avg_train_loss: 0.5274 | train_auc: 0.9132 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [700 / 1130] avg_train_loss: 0.5318 | train_auc: 0.908 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [800 / 1130] avg_train_loss: 0.5139 | train_auc: 0.917 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [900 / 1130] avg_train_loss: 0.5101 | train_auc: 0.9186 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [1000 / 1130] avg_train_loss: 0.5018 | train_auc: 0.9233 | lr : 7.289999999999999e-09
Epoch [77 / 100] Step: [1100 / 1130] avg_train_loss: 0.4973 | train_auc: 0.9246 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 77 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3385 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 77 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.3835 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 77 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5215 | val_auc: 0.6085 | lr: 7.289999999999999e-09
[Epoch: 77 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6603 | val_auc: 0.5815 | lr: 7.289999999999999e-09
[Epoch: 77 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7056 | val_auc: 0.6395 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 78
[TRAIN] Train model
Epoch [78 / 100] Step: [100 / 1130] avg_train_loss: 0.4287 | train_auc: 0.9688 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [200 / 1130] avg_train_loss: 0.4429 | train_auc: 0.9589 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [300 / 1130] avg_train_loss: 0.4624 | train_auc: 0.9524 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [400 / 1130] avg_train_loss: 0.471 | train_auc: 0.9442 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [500 / 1130] avg_train_loss: 0.4691 | train_auc: 0.9435 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [600 / 1130] avg_train_loss: 0.4889 | train_auc: 0.9337 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [700 / 1130] avg_train_loss: 0.4749 | train_auc: 0.9394 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [800 / 1130] avg_train_loss: 0.4841 | train_auc: 0.9354 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [900 / 1130] avg_train_loss: 0.4913 | train_auc: 0.9321 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [1000 / 1130] avg_train_loss: 0.4982 | train_auc: 0.9294 | lr : 7.289999999999999e-09
Epoch [78 / 100] Step: [1100 / 1130] avg_train_loss: 0.4961 | train_auc: 0.9278 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 78 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4009 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 78 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4659 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 78 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5768 | val_auc: 0.5608 | lr: 7.289999999999999e-09
[Epoch: 78 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7021 | val_auc: 0.5272 | lr: 7.289999999999999e-09
[Epoch: 78 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7274 | val_auc: 0.6199 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 79
[TRAIN] Train model
Epoch [79 / 100] Step: [100 / 1130] avg_train_loss: 0.4995 | train_auc: 0.9253 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [200 / 1130] avg_train_loss: 0.4434 | train_auc: 0.95 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [300 / 1130] avg_train_loss: 0.4623 | train_auc: 0.9431 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [400 / 1130] avg_train_loss: 0.4674 | train_auc: 0.943 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [500 / 1130] avg_train_loss: 0.4568 | train_auc: 0.9451 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [600 / 1130] avg_train_loss: 0.4778 | train_auc: 0.9359 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [700 / 1130] avg_train_loss: 0.4783 | train_auc: 0.9364 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [800 / 1130] avg_train_loss: 0.4841 | train_auc: 0.9345 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [900 / 1130] avg_train_loss: 0.4881 | train_auc: 0.9324 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [1000 / 1130] avg_train_loss: 0.4956 | train_auc: 0.9287 | lr : 7.289999999999999e-09
Epoch [79 / 100] Step: [1100 / 1130] avg_train_loss: 0.4955 | train_auc: 0.9282 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 79 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3529 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 79 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4296 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 79 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5427 | val_auc: 0.6508 | lr: 7.289999999999999e-09
[Epoch: 79 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6854 | val_auc: 0.5823 | lr: 7.289999999999999e-09
[Epoch: 79 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7152 | val_auc: 0.6493 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 80
[TRAIN] Train model
Epoch [80 / 100] Step: [100 / 1130] avg_train_loss: 0.434 | train_auc: 0.954 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [200 / 1130] avg_train_loss: 0.4231 | train_auc: 0.9561 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [300 / 1130] avg_train_loss: 0.4402 | train_auc: 0.9519 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [400 / 1130] avg_train_loss: 0.462 | train_auc: 0.9433 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [500 / 1130] avg_train_loss: 0.4758 | train_auc: 0.9347 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [600 / 1130] avg_train_loss: 0.483 | train_auc: 0.9323 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [700 / 1130] avg_train_loss: 0.4692 | train_auc: 0.9377 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [800 / 1130] avg_train_loss: 0.4735 | train_auc: 0.9372 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [900 / 1130] avg_train_loss: 0.4663 | train_auc: 0.9406 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [1000 / 1130] avg_train_loss: 0.4699 | train_auc: 0.9391 | lr : 7.289999999999999e-09
Epoch [80 / 100] Step: [1100 / 1130] avg_train_loss: 0.4842 | train_auc: 0.9315 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 80 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3609 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 80 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4241 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 80 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.547 | val_auc: 0.5926 | lr: 7.289999999999999e-09
[Epoch: 80 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6819 | val_auc: 0.556 | lr: 7.289999999999999e-09
[Epoch: 80 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7164 | val_auc: 0.6239 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 81
[TRAIN] Train model
Epoch [81 / 100] Step: [100 / 1130] avg_train_loss: 0.4485 | train_auc: 0.9563 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [200 / 1130] avg_train_loss: 0.4852 | train_auc: 0.9344 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [300 / 1130] avg_train_loss: 0.4788 | train_auc: 0.9385 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [400 / 1130] avg_train_loss: 0.4819 | train_auc: 0.9377 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [500 / 1130] avg_train_loss: 0.4946 | train_auc: 0.9343 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [600 / 1130] avg_train_loss: 0.4851 | train_auc: 0.9381 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [700 / 1130] avg_train_loss: 0.4787 | train_auc: 0.9393 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [800 / 1130] avg_train_loss: 0.4773 | train_auc: 0.9395 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [900 / 1130] avg_train_loss: 0.4812 | train_auc: 0.9378 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [1000 / 1130] avg_train_loss: 0.4937 | train_auc: 0.9317 | lr : 7.289999999999999e-09
Epoch [81 / 100] Step: [1100 / 1130] avg_train_loss: 0.491 | train_auc: 0.9324 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 81 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.377 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 81 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4554 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 81 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5595 | val_auc: 0.7354 | lr: 7.289999999999999e-09
[Epoch: 81 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6904 | val_auc: 0.6435 | lr: 7.289999999999999e-09
[Epoch: 81 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7217 | val_auc: 0.6707 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 82
[TRAIN] Train model
Epoch [82 / 100] Step: [100 / 1130] avg_train_loss: 0.4818 | train_auc: 0.9473 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [200 / 1130] avg_train_loss: 0.4976 | train_auc: 0.936 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [300 / 1130] avg_train_loss: 0.5412 | train_auc: 0.9122 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [400 / 1130] avg_train_loss: 0.5227 | train_auc: 0.9213 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [500 / 1130] avg_train_loss: 0.5222 | train_auc: 0.9212 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [600 / 1130] avg_train_loss: 0.5183 | train_auc: 0.9218 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [700 / 1130] avg_train_loss: 0.5105 | train_auc: 0.9235 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [800 / 1130] avg_train_loss: 0.505 | train_auc: 0.9232 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [900 / 1130] avg_train_loss: 0.5016 | train_auc: 0.9257 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [1000 / 1130] avg_train_loss: 0.4965 | train_auc: 0.9273 | lr : 7.289999999999999e-09
Epoch [82 / 100] Step: [1100 / 1130] avg_train_loss: 0.4945 | train_auc: 0.9291 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 82 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4399 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 82 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4992 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 82 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.602 | val_auc: 0.6164 | lr: 7.289999999999999e-09
[Epoch: 82 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7044 | val_auc: 0.5815 | lr: 7.289999999999999e-09
[Epoch: 82 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7331 | val_auc: 0.6288 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 83
[TRAIN] Train model
Epoch [83 / 100] Step: [100 / 1130] avg_train_loss: 0.4616 | train_auc: 0.9416 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [200 / 1130] avg_train_loss: 0.454 | train_auc: 0.9393 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [300 / 1130] avg_train_loss: 0.4714 | train_auc: 0.9305 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [400 / 1130] avg_train_loss: 0.4923 | train_auc: 0.9208 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [500 / 1130] avg_train_loss: 0.5023 | train_auc: 0.9197 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [600 / 1130] avg_train_loss: 0.5139 | train_auc: 0.918 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [700 / 1130] avg_train_loss: 0.4975 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [800 / 1130] avg_train_loss: 0.5004 | train_auc: 0.925 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [900 / 1130] avg_train_loss: 0.498 | train_auc: 0.926 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [1000 / 1130] avg_train_loss: 0.4978 | train_auc: 0.9261 | lr : 7.289999999999999e-09
Epoch [83 / 100] Step: [1100 / 1130] avg_train_loss: 0.4972 | train_auc: 0.9279 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 83 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3839 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 83 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4561 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 83 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5754 | val_auc: 0.5794 | lr: 7.289999999999999e-09
[Epoch: 83 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7045 | val_auc: 0.5306 | lr: 7.289999999999999e-09
[Epoch: 83 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7239 | val_auc: 0.6221 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 84
[TRAIN] Train model
Epoch [84 / 100] Step: [100 / 1130] avg_train_loss: 0.3949 | train_auc: 0.9688 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [200 / 1130] avg_train_loss: 0.4108 | train_auc: 0.9617 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [300 / 1130] avg_train_loss: 0.4357 | train_auc: 0.9559 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [400 / 1130] avg_train_loss: 0.4658 | train_auc: 0.9418 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [500 / 1130] avg_train_loss: 0.4982 | train_auc: 0.9243 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [600 / 1130] avg_train_loss: 0.5257 | train_auc: 0.9115 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [700 / 1130] avg_train_loss: 0.5062 | train_auc: 0.9202 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [800 / 1130] avg_train_loss: 0.5087 | train_auc: 0.9198 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [900 / 1130] avg_train_loss: 0.5153 | train_auc: 0.9179 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [1000 / 1130] avg_train_loss: 0.51 | train_auc: 0.9202 | lr : 7.289999999999999e-09
Epoch [84 / 100] Step: [1100 / 1130] avg_train_loss: 0.499 | train_auc: 0.9268 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 84 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4244 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 84 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5092 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 84 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6016 | val_auc: 0.5847 | lr: 7.289999999999999e-09
[Epoch: 84 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7036 | val_auc: 0.5475 | lr: 7.289999999999999e-09
[Epoch: 84 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7192 | val_auc: 0.6217 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 85
[TRAIN] Train model
Epoch [85 / 100] Step: [100 / 1130] avg_train_loss: 0.466 | train_auc: 0.9533 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [200 / 1130] avg_train_loss: 0.4385 | train_auc: 0.955 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [300 / 1130] avg_train_loss: 0.4655 | train_auc: 0.9458 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [400 / 1130] avg_train_loss: 0.4749 | train_auc: 0.941 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [500 / 1130] avg_train_loss: 0.4924 | train_auc: 0.93 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [600 / 1130] avg_train_loss: 0.486 | train_auc: 0.933 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [700 / 1130] avg_train_loss: 0.4736 | train_auc: 0.9389 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [800 / 1130] avg_train_loss: 0.4766 | train_auc: 0.9361 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [900 / 1130] avg_train_loss: 0.4927 | train_auc: 0.9275 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [1000 / 1130] avg_train_loss: 0.4896 | train_auc: 0.9277 | lr : 7.289999999999999e-09
Epoch [85 / 100] Step: [1100 / 1130] avg_train_loss: 0.4846 | train_auc: 0.9313 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 85 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3454 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 85 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4206 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 85 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5471 | val_auc: 0.5873 | lr: 7.289999999999999e-09
[Epoch: 85 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6787 | val_auc: 0.5603 | lr: 7.289999999999999e-09
[Epoch: 85 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7077 | val_auc: 0.6279 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 86
[TRAIN] Train model
Epoch [86 / 100] Step: [100 / 1130] avg_train_loss: 0.4918 | train_auc: 0.9394 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [200 / 1130] avg_train_loss: 0.5055 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [300 / 1130] avg_train_loss: 0.5215 | train_auc: 0.9165 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [400 / 1130] avg_train_loss: 0.5111 | train_auc: 0.9246 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [500 / 1130] avg_train_loss: 0.5204 | train_auc: 0.9187 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [600 / 1130] avg_train_loss: 0.5227 | train_auc: 0.9159 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [700 / 1130] avg_train_loss: 0.5165 | train_auc: 0.9185 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [800 / 1130] avg_train_loss: 0.5061 | train_auc: 0.9246 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [900 / 1130] avg_train_loss: 0.499 | train_auc: 0.9289 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [1000 / 1130] avg_train_loss: 0.4952 | train_auc: 0.9294 | lr : 7.289999999999999e-09
Epoch [86 / 100] Step: [1100 / 1130] avg_train_loss: 0.4861 | train_auc: 0.9343 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 86 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3679 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 86 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4248 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 86 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5488 | val_auc: 0.5688 | lr: 7.289999999999999e-09
[Epoch: 86 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.684 | val_auc: 0.5475 | lr: 7.289999999999999e-09
[Epoch: 86 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7254 | val_auc: 0.619 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 87
[TRAIN] Train model
Epoch [87 / 100] Step: [100 / 1130] avg_train_loss: 0.4237 | train_auc: 0.9647 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [200 / 1130] avg_train_loss: 0.4269 | train_auc: 0.9664 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [300 / 1130] avg_train_loss: 0.4627 | train_auc: 0.9535 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [400 / 1130] avg_train_loss: 0.4945 | train_auc: 0.9335 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [500 / 1130] avg_train_loss: 0.5033 | train_auc: 0.9303 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [600 / 1130] avg_train_loss: 0.4966 | train_auc: 0.9329 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [700 / 1130] avg_train_loss: 0.4991 | train_auc: 0.934 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [800 / 1130] avg_train_loss: 0.5068 | train_auc: 0.929 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [900 / 1130] avg_train_loss: 0.5075 | train_auc: 0.9289 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [1000 / 1130] avg_train_loss: 0.5028 | train_auc: 0.9304 | lr : 7.289999999999999e-09
Epoch [87 / 100] Step: [1100 / 1130] avg_train_loss: 0.5024 | train_auc: 0.9317 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 87 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4573 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 87 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5427 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 87 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.641 | val_auc: 0.5899 | lr: 7.289999999999999e-09
[Epoch: 87 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7325 | val_auc: 0.5679 | lr: 7.289999999999999e-09
[Epoch: 87 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7486 | val_auc: 0.6266 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 88
[TRAIN] Train model
Epoch [88 / 100] Step: [100 / 1130] avg_train_loss: 0.4835 | train_auc: 0.944 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [200 / 1130] avg_train_loss: 0.4827 | train_auc: 0.938 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [300 / 1130] avg_train_loss: 0.4749 | train_auc: 0.9374 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [400 / 1130] avg_train_loss: 0.4703 | train_auc: 0.9415 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [500 / 1130] avg_train_loss: 0.4526 | train_auc: 0.9494 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [600 / 1130] avg_train_loss: 0.4569 | train_auc: 0.9455 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [700 / 1130] avg_train_loss: 0.4738 | train_auc: 0.9407 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [800 / 1130] avg_train_loss: 0.4769 | train_auc: 0.9385 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [900 / 1130] avg_train_loss: 0.4743 | train_auc: 0.9395 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [1000 / 1130] avg_train_loss: 0.4779 | train_auc: 0.9388 | lr : 7.289999999999999e-09
Epoch [88 / 100] Step: [1100 / 1130] avg_train_loss: 0.472 | train_auc: 0.9402 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 88 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.399 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 88 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.466 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 88 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5976 | val_auc: 0.6032 | lr: 7.289999999999999e-09
[Epoch: 88 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7124 | val_auc: 0.5806 | lr: 7.289999999999999e-09
[Epoch: 88 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7405 | val_auc: 0.6359 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 89
[TRAIN] Train model
Epoch [89 / 100] Step: [100 / 1130] avg_train_loss: 0.5171 | train_auc: 0.9142 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [200 / 1130] avg_train_loss: 0.5143 | train_auc: 0.9124 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [300 / 1130] avg_train_loss: 0.4735 | train_auc: 0.9311 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [400 / 1130] avg_train_loss: 0.4636 | train_auc: 0.9392 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [500 / 1130] avg_train_loss: 0.493 | train_auc: 0.9277 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [600 / 1130] avg_train_loss: 0.5119 | train_auc: 0.9216 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [700 / 1130] avg_train_loss: 0.5074 | train_auc: 0.922 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [800 / 1130] avg_train_loss: 0.5019 | train_auc: 0.9251 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [900 / 1130] avg_train_loss: 0.5054 | train_auc: 0.9217 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [1000 / 1130] avg_train_loss: 0.5061 | train_auc: 0.9222 | lr : 7.289999999999999e-09
Epoch [89 / 100] Step: [1100 / 1130] avg_train_loss: 0.5053 | train_auc: 0.9226 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 89 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3659 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 89 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4551 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 89 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5696 | val_auc: 0.6455 | lr: 7.289999999999999e-09
[Epoch: 89 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6931 | val_auc: 0.5772 | lr: 7.289999999999999e-09
[Epoch: 89 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7174 | val_auc: 0.6355 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 90
[TRAIN] Train model
Epoch [90 / 100] Step: [100 / 1130] avg_train_loss: 0.5211 | train_auc: 0.9284 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [200 / 1130] avg_train_loss: 0.5129 | train_auc: 0.9238 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [300 / 1130] avg_train_loss: 0.5188 | train_auc: 0.9145 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [400 / 1130] avg_train_loss: 0.5289 | train_auc: 0.9085 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [500 / 1130] avg_train_loss: 0.5122 | train_auc: 0.9155 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [600 / 1130] avg_train_loss: 0.5073 | train_auc: 0.9175 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [700 / 1130] avg_train_loss: 0.5032 | train_auc: 0.9213 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [800 / 1130] avg_train_loss: 0.5079 | train_auc: 0.9183 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [900 / 1130] avg_train_loss: 0.5028 | train_auc: 0.9187 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [1000 / 1130] avg_train_loss: 0.4906 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [90 / 100] Step: [1100 / 1130] avg_train_loss: 0.4854 | train_auc: 0.9296 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 90 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3637 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 90 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4288 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 90 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5639 | val_auc: 0.5741 | lr: 7.289999999999999e-09
[Epoch: 90 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7053 | val_auc: 0.5263 | lr: 7.289999999999999e-09
[Epoch: 90 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7361 | val_auc: 0.6087 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 91
[TRAIN] Train model
Epoch [91 / 100] Step: [100 / 1130] avg_train_loss: 0.4746 | train_auc: 0.9508 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [200 / 1130] avg_train_loss: 0.4772 | train_auc: 0.9416 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [300 / 1130] avg_train_loss: 0.4839 | train_auc: 0.9382 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [400 / 1130] avg_train_loss: 0.4779 | train_auc: 0.9411 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [500 / 1130] avg_train_loss: 0.4823 | train_auc: 0.9401 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [600 / 1130] avg_train_loss: 0.4798 | train_auc: 0.9386 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [700 / 1130] avg_train_loss: 0.4811 | train_auc: 0.9359 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [800 / 1130] avg_train_loss: 0.4822 | train_auc: 0.9352 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [900 / 1130] avg_train_loss: 0.4867 | train_auc: 0.934 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [1000 / 1130] avg_train_loss: 0.4868 | train_auc: 0.9332 | lr : 7.289999999999999e-09
Epoch [91 / 100] Step: [1100 / 1130] avg_train_loss: 0.4919 | train_auc: 0.9299 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 91 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4232 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 91 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5144 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 91 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6146 | val_auc: 0.6587 | lr: 7.289999999999999e-09
[Epoch: 91 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7179 | val_auc: 0.5891 | lr: 7.289999999999999e-09
[Epoch: 91 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7342 | val_auc: 0.6404 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 92
[TRAIN] Train model
Epoch [92 / 100] Step: [100 / 1130] avg_train_loss: 0.4647 | train_auc: 0.9046 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [200 / 1130] avg_train_loss: 0.4665 | train_auc: 0.9349 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [300 / 1130] avg_train_loss: 0.4967 | train_auc: 0.9195 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [400 / 1130] avg_train_loss: 0.5096 | train_auc: 0.9147 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [500 / 1130] avg_train_loss: 0.527 | train_auc: 0.9046 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [600 / 1130] avg_train_loss: 0.5322 | train_auc: 0.9012 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [700 / 1130] avg_train_loss: 0.5255 | train_auc: 0.9081 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [800 / 1130] avg_train_loss: 0.5202 | train_auc: 0.913 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [900 / 1130] avg_train_loss: 0.511 | train_auc: 0.9195 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [1000 / 1130] avg_train_loss: 0.5092 | train_auc: 0.9228 | lr : 7.289999999999999e-09
Epoch [92 / 100] Step: [1100 / 1130] avg_train_loss: 0.5049 | train_auc: 0.9256 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 92 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.365 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 92 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4428 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 92 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5509 | val_auc: 0.7381 | lr: 7.289999999999999e-09
[Epoch: 92 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6763 | val_auc: 0.6486 | lr: 7.289999999999999e-09
[Epoch: 92 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7205 | val_auc: 0.6613 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 93
[TRAIN] Train model
Epoch [93 / 100] Step: [100 / 1130] avg_train_loss: 0.5421 | train_auc: 0.9036 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [200 / 1130] avg_train_loss: 0.4847 | train_auc: 0.9273 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [300 / 1130] avg_train_loss: 0.508 | train_auc: 0.9151 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [400 / 1130] avg_train_loss: 0.4989 | train_auc: 0.9202 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [500 / 1130] avg_train_loss: 0.5095 | train_auc: 0.9189 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [600 / 1130] avg_train_loss: 0.5081 | train_auc: 0.9209 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [700 / 1130] avg_train_loss: 0.5046 | train_auc: 0.9239 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [800 / 1130] avg_train_loss: 0.5058 | train_auc: 0.9261 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [900 / 1130] avg_train_loss: 0.4968 | train_auc: 0.9288 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [1000 / 1130] avg_train_loss: 0.4946 | train_auc: 0.9295 | lr : 7.289999999999999e-09
Epoch [93 / 100] Step: [1100 / 1130] avg_train_loss: 0.4977 | train_auc: 0.9288 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 93 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3554 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 93 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4221 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 93 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5502 | val_auc: 0.5899 | lr: 7.289999999999999e-09
[Epoch: 93 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6781 | val_auc: 0.5637 | lr: 7.289999999999999e-09
[Epoch: 93 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7076 | val_auc: 0.6355 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 94
[TRAIN] Train model
Epoch [94 / 100] Step: [100 / 1130] avg_train_loss: 0.4352 | train_auc: 0.9705 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [200 / 1130] avg_train_loss: 0.4393 | train_auc: 0.9662 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [300 / 1130] avg_train_loss: 0.4479 | train_auc: 0.957 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [400 / 1130] avg_train_loss: 0.4521 | train_auc: 0.9547 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [500 / 1130] avg_train_loss: 0.4669 | train_auc: 0.9483 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [600 / 1130] avg_train_loss: 0.469 | train_auc: 0.9457 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [700 / 1130] avg_train_loss: 0.473 | train_auc: 0.9421 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [800 / 1130] avg_train_loss: 0.467 | train_auc: 0.9435 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [900 / 1130] avg_train_loss: 0.4634 | train_auc: 0.9449 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [1000 / 1130] avg_train_loss: 0.4649 | train_auc: 0.9435 | lr : 7.289999999999999e-09
Epoch [94 / 100] Step: [1100 / 1130] avg_train_loss: 0.4802 | train_auc: 0.9361 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 94 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4009 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 94 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4724 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 94 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5862 | val_auc: 0.6058 | lr: 7.289999999999999e-09
[Epoch: 94 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7063 | val_auc: 0.5467 | lr: 7.289999999999999e-09
[Epoch: 94 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7216 | val_auc: 0.6279 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 95
[TRAIN] Train model
Epoch [95 / 100] Step: [100 / 1130] avg_train_loss: 0.4908 | train_auc: 0.9248 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [200 / 1130] avg_train_loss: 0.4616 | train_auc: 0.9384 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [300 / 1130] avg_train_loss: 0.4918 | train_auc: 0.9287 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [400 / 1130] avg_train_loss: 0.4801 | train_auc: 0.9367 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [500 / 1130] avg_train_loss: 0.4712 | train_auc: 0.9425 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [600 / 1130] avg_train_loss: 0.4623 | train_auc: 0.9468 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [700 / 1130] avg_train_loss: 0.4613 | train_auc: 0.9444 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [800 / 1130] avg_train_loss: 0.4731 | train_auc: 0.9399 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [900 / 1130] avg_train_loss: 0.4721 | train_auc: 0.9387 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [1000 / 1130] avg_train_loss: 0.4777 | train_auc: 0.9367 | lr : 7.289999999999999e-09
Epoch [95 / 100] Step: [1100 / 1130] avg_train_loss: 0.4825 | train_auc: 0.9342 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 95 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3697 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 95 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4384 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 95 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.54 | val_auc: 0.7619 | lr: 7.289999999999999e-09
[Epoch: 95 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6623 | val_auc: 0.6613 | lr: 7.289999999999999e-09
[Epoch: 95 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7127 | val_auc: 0.6613 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 96
[TRAIN] Train model
Epoch [96 / 100] Step: [100 / 1130] avg_train_loss: 0.5198 | train_auc: 0.8896 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [200 / 1130] avg_train_loss: 0.4998 | train_auc: 0.9182 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [300 / 1130] avg_train_loss: 0.4844 | train_auc: 0.9313 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [400 / 1130] avg_train_loss: 0.5066 | train_auc: 0.926 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [500 / 1130] avg_train_loss: 0.4991 | train_auc: 0.9268 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [600 / 1130] avg_train_loss: 0.5087 | train_auc: 0.9244 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [700 / 1130] avg_train_loss: 0.5121 | train_auc: 0.9212 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [800 / 1130] avg_train_loss: 0.4991 | train_auc: 0.9275 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [900 / 1130] avg_train_loss: 0.5062 | train_auc: 0.9228 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [1000 / 1130] avg_train_loss: 0.5102 | train_auc: 0.9202 | lr : 7.289999999999999e-09
Epoch [96 / 100] Step: [1100 / 1130] avg_train_loss: 0.5056 | train_auc: 0.9233 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 96 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3993 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 96 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.4552 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 96 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5836 | val_auc: 0.5397 | lr: 7.289999999999999e-09
[Epoch: 96 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.703 | val_auc: 0.5289 | lr: 7.289999999999999e-09
[Epoch: 96 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7318 | val_auc: 0.6087 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 97
[TRAIN] Train model
Epoch [97 / 100] Step: [100 / 1130] avg_train_loss: 0.5317 | train_auc: 0.8995 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [200 / 1130] avg_train_loss: 0.5329 | train_auc: 0.9047 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [300 / 1130] avg_train_loss: 0.5255 | train_auc: 0.9097 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [400 / 1130] avg_train_loss: 0.5182 | train_auc: 0.9112 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [500 / 1130] avg_train_loss: 0.5124 | train_auc: 0.9128 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [600 / 1130] avg_train_loss: 0.5023 | train_auc: 0.9206 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [700 / 1130] avg_train_loss: 0.4962 | train_auc: 0.9247 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [800 / 1130] avg_train_loss: 0.489 | train_auc: 0.926 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [900 / 1130] avg_train_loss: 0.4943 | train_auc: 0.9254 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [1000 / 1130] avg_train_loss: 0.4945 | train_auc: 0.9256 | lr : 7.289999999999999e-09
Epoch [97 / 100] Step: [1100 / 1130] avg_train_loss: 0.4907 | train_auc: 0.9285 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 97 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.432 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 97 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5204 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 97 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.6136 | val_auc: 0.709 | lr: 7.289999999999999e-09
[Epoch: 97 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7226 | val_auc: 0.6138 | lr: 7.289999999999999e-09
[Epoch: 97 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7504 | val_auc: 0.6399 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 98
[TRAIN] Train model
Epoch [98 / 100] Step: [100 / 1130] avg_train_loss: 0.5269 | train_auc: 0.9294 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [200 / 1130] avg_train_loss: 0.5096 | train_auc: 0.9248 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [300 / 1130] avg_train_loss: 0.4799 | train_auc: 0.9378 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [400 / 1130] avg_train_loss: 0.4864 | train_auc: 0.9306 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [500 / 1130] avg_train_loss: 0.4748 | train_auc: 0.9344 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [600 / 1130] avg_train_loss: 0.4719 | train_auc: 0.9374 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [700 / 1130] avg_train_loss: 0.4807 | train_auc: 0.9308 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [800 / 1130] avg_train_loss: 0.4896 | train_auc: 0.9265 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [900 / 1130] avg_train_loss: 0.4815 | train_auc: 0.9301 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [1000 / 1130] avg_train_loss: 0.4733 | train_auc: 0.9337 | lr : 7.289999999999999e-09
Epoch [98 / 100] Step: [1100 / 1130] avg_train_loss: 0.4725 | train_auc: 0.9351 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 98 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3352 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 98 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.3866 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 98 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5121 | val_auc: 0.6481 | lr: 7.289999999999999e-09
[Epoch: 98 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6603 | val_auc: 0.5951 | lr: 7.289999999999999e-09
[Epoch: 98 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7025 | val_auc: 0.6533 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 99
[TRAIN] Train model
Epoch [99 / 100] Step: [100 / 1130] avg_train_loss: 0.4563 | train_auc: 0.9496 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [200 / 1130] avg_train_loss: 0.4507 | train_auc: 0.9523 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [300 / 1130] avg_train_loss: 0.4818 | train_auc: 0.9393 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [400 / 1130] avg_train_loss: 0.4934 | train_auc: 0.9292 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [500 / 1130] avg_train_loss: 0.4925 | train_auc: 0.9277 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [600 / 1130] avg_train_loss: 0.4929 | train_auc: 0.929 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [700 / 1130] avg_train_loss: 0.5017 | train_auc: 0.9251 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [800 / 1130] avg_train_loss: 0.5061 | train_auc: 0.9238 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [900 / 1130] avg_train_loss: 0.5053 | train_auc: 0.9252 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [1000 / 1130] avg_train_loss: 0.5022 | train_auc: 0.9264 | lr : 7.289999999999999e-09
Epoch [99 / 100] Step: [1100 / 1130] avg_train_loss: 0.4932 | train_auc: 0.9296 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 99 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.4334 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 99 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.5045 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 99 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.618 | val_auc: 0.6005 | lr: 7.289999999999999e-09
[Epoch: 99 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.7225 | val_auc: 0.5569 | lr: 7.289999999999999e-09
[Epoch: 99 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7448 | val_auc: 0.6132 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[TRAIN] EPOCH # 100
[TRAIN] Train model
Epoch [100 / 100] Step: [100 / 1130] avg_train_loss: 0.4572 | train_auc: 0.9541 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [200 / 1130] avg_train_loss: 0.5107 | train_auc: 0.9196 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [300 / 1130] avg_train_loss: 0.4807 | train_auc: 0.9337 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [400 / 1130] avg_train_loss: 0.4935 | train_auc: 0.9258 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [500 / 1130] avg_train_loss: 0.5095 | train_auc: 0.9181 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [600 / 1130] avg_train_loss: 0.4979 | train_auc: 0.9204 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [700 / 1130] avg_train_loss: 0.5039 | train_auc: 0.9198 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [800 / 1130] avg_train_loss: 0.5076 | train_auc: 0.9196 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [900 / 1130] avg_train_loss: 0.5065 | train_auc: 0.9206 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [1000 / 1130] avg_train_loss: 0.5016 | train_auc: 0.9218 | lr : 7.289999999999999e-09
Epoch [100 / 100] Step: [1100 / 1130] avg_train_loss: 0.5051 | train_auc: 0.9214 | lr : 7.289999999999999e-09
[EVALUATE] Evaluate model
[Epoch: 100 / 100 | Single batch number: 20 / 120] avg_val_loss: 0.3776 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 100 / 100 | Single batch number: 40 / 120] avg_val_loss: 0.451 | val_auc: nan | lr: 7.289999999999999e-09
[Epoch: 100 / 100 | Single batch number: 60 / 120] avg_val_loss: 0.5711 | val_auc: 0.5926 | lr: 7.289999999999999e-09
[Epoch: 100 / 100 | Single batch number: 80 / 120] avg_val_loss: 0.6943 | val_auc: 0.5577 | lr: 7.289999999999999e-09
[Epoch: 100 / 100 | Single batch number: 100 / 120] avg_val_loss: 0.7244 | val_auc: 0.6275 | lr: 7.289999999999999e-09
----------------------------------------------------------------------------------------------------
[INFO] Execution duration: 133.00 minutes 7.63 seconds
Completed Meniscus Sagittal Training
---------------------------------
[SEED] Setting seeds for reproducibility...
src/models-to-submit/pretrained
[COMBINE] Task: "meniscus"
[COMBINE] Device: cuda
[COMBINE] Trainig data. Plane: "axial" Slice "vertical"
[UTILS] Model name "model_base_meniscus_axial_train_auc_0.9862_val_auc_0.8388_train_loss_0.2329_val_loss_0.6567_epoch_55_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth" for "axial", Val AUC "0.8388", Architecture: "pretrained-resnet18", Augment: "albumentations-group" (prob 0.4)
Copying model...!
[COMBINE] Extracting predictions for task "meniscus" and plane "axial"
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[DATALOADER] __init__ task: meniscus, plane: axial, train: train
[DATALOADER] __init__ weights: [1, 1.8463476070528968]
  0%|          | 0/1130 [00:00<?, ?it/s]  0%|          | 1/1130 [00:04<1:20:28,  4.28s/it]  0%|          | 4/1130 [00:04<15:43,  1.19it/s]    1%|          | 6/1130 [00:04<09:17,  2.01it/s]  1%|          | 9/1130 [00:04<05:11,  3.60it/s]  1%|          | 12/1130 [00:04<03:20,  5.58it/s]  1%|▏         | 15/1130 [00:04<02:30,  7.42it/s]  2%|▏         | 18/1130 [00:05<02:00,  9.26it/s]  2%|▏         | 21/1130 [00:05<01:35, 11.66it/s]  2%|▏         | 24/1130 [00:05<01:18, 14.09it/s]  2%|▏         | 27/1130 [00:05<01:11, 15.36it/s]  3%|▎         | 30/1130 [00:05<01:06, 16.42it/s]  3%|▎         | 33/1130 [00:05<01:07, 16.28it/s]  3%|▎         | 35/1130 [00:05<01:05, 16.63it/s]  3%|▎         | 39/1130 [00:06<00:53, 20.42it/s]  4%|▍         | 43/1130 [00:06<00:44, 24.48it/s]  4%|▍         | 46/1130 [00:06<00:47, 22.91it/s]  4%|▍         | 50/1130 [00:06<00:42, 25.13it/s]  5%|▍         | 53/1130 [00:06<00:47, 22.83it/s]  5%|▍         | 56/1130 [00:06<00:48, 21.93it/s]  5%|▌         | 59/1130 [00:06<00:51, 20.68it/s]  5%|▌         | 62/1130 [00:07<00:52, 20.39it/s]  6%|▌         | 65/1130 [00:07<00:51, 20.80it/s]  6%|▌         | 68/1130 [00:07<00:55, 19.16it/s]  6%|▌         | 70/1130 [00:07<00:56, 18.70it/s]  6%|▋         | 73/1130 [00:07<00:51, 20.40it/s]  7%|▋         | 76/1130 [00:07<00:47, 22.29it/s]  7%|▋         | 79/1130 [00:07<00:44, 23.80it/s]  7%|▋         | 82/1130 [00:07<00:44, 23.75it/s]  8%|▊         | 85/1130 [00:08<00:45, 23.14it/s]  8%|▊         | 88/1130 [00:08<00:45, 22.81it/s]  8%|▊         | 91/1130 [00:08<00:46, 22.51it/s]  8%|▊         | 94/1130 [00:08<00:42, 24.16it/s]  9%|▊         | 97/1130 [00:08<00:42, 24.31it/s]  9%|▉         | 100/1130 [00:08<00:41, 24.90it/s]  9%|▉         | 104/1130 [00:08<00:37, 27.14it/s]  9%|▉         | 107/1130 [00:08<00:38, 26.77it/s] 10%|▉         | 110/1130 [00:09<00:42, 24.22it/s] 10%|█         | 113/1130 [00:09<00:39, 25.46it/s] 10%|█         | 116/1130 [00:09<00:41, 24.23it/s] 11%|█         | 120/1130 [00:09<00:38, 26.37it/s] 11%|█         | 123/1130 [00:09<00:39, 25.64it/s] 11%|█         | 126/1130 [00:09<00:41, 24.26it/s] 11%|█▏        | 129/1130 [00:09<00:40, 24.50it/s] 12%|█▏        | 132/1130 [00:10<00:44, 22.38it/s] 12%|█▏        | 137/1130 [00:10<00:36, 27.00it/s] 12%|█▏        | 141/1130 [00:10<00:35, 28.22it/s] 13%|█▎        | 145/1130 [00:10<00:32, 30.21it/s] 13%|█▎        | 149/1130 [00:10<00:41, 23.67it/s] 14%|█▎        | 153/1130 [00:10<00:37, 25.92it/s] 14%|█▍        | 157/1130 [00:10<00:33, 28.85it/s] 14%|█▍        | 161/1130 [00:11<00:32, 29.61it/s] 15%|█▍        | 165/1130 [00:11<00:32, 29.25it/s] 15%|█▍        | 169/1130 [00:11<00:35, 27.05it/s] 15%|█▌        | 173/1130 [00:11<00:32, 29.02it/s] 16%|█▌        | 177/1130 [00:11<00:35, 27.07it/s] 16%|█▌        | 182/1130 [00:11<00:30, 30.73it/s] 16%|█▋        | 186/1130 [00:11<00:36, 25.65it/s] 17%|█▋        | 189/1130 [00:12<00:36, 26.09it/s] 17%|█▋        | 193/1130 [00:12<00:32, 29.10it/s] 17%|█▋        | 197/1130 [00:12<00:33, 27.49it/s] 18%|█▊        | 202/1130 [00:12<00:28, 32.47it/s] 18%|█▊        | 206/1130 [00:12<00:30, 30.34it/s] 19%|█▊        | 210/1130 [00:12<00:30, 30.23it/s] 19%|█▉        | 214/1130 [00:12<00:37, 24.13it/s] 19%|█▉        | 217/1130 [00:13<00:37, 24.49it/s] 19%|█▉        | 220/1130 [00:13<00:36, 24.98it/s] 20%|█▉        | 224/1130 [00:13<00:34, 26.48it/s] 20%|██        | 228/1130 [00:13<00:31, 28.25it/s] 21%|██        | 232/1130 [00:13<00:30, 29.14it/s] 21%|██        | 235/1130 [00:13<00:32, 27.62it/s] 21%|██        | 239/1130 [00:13<00:29, 30.36it/s] 22%|██▏       | 243/1130 [00:13<00:31, 27.95it/s] 22%|██▏       | 247/1130 [00:14<00:33, 26.05it/s] 22%|██▏       | 250/1130 [00:14<00:35, 24.61it/s] 22%|██▏       | 254/1130 [00:14<00:32, 26.57it/s] 23%|██▎       | 257/1130 [00:14<00:33, 25.98it/s] 23%|██▎       | 261/1130 [00:14<00:31, 27.16it/s] 23%|██▎       | 264/1130 [00:14<00:34, 25.26it/s] 24%|██▎       | 267/1130 [00:14<00:33, 25.80it/s] 24%|██▍       | 272/1130 [00:15<00:27, 30.95it/s] 24%|██▍       | 276/1130 [00:15<00:27, 30.63it/s] 25%|██▍       | 280/1130 [00:15<00:34, 24.62it/s] 25%|██▌       | 285/1130 [00:15<00:32, 26.24it/s] 25%|██▌       | 288/1130 [00:15<00:33, 25.28it/s] 26%|██▌       | 292/1130 [00:15<00:32, 26.00it/s] 26%|██▋       | 297/1130 [00:15<00:27, 30.78it/s] 27%|██▋       | 301/1130 [00:16<00:31, 26.03it/s] 27%|██▋       | 304/1130 [00:16<00:32, 25.59it/s] 27%|██▋       | 309/1130 [00:16<00:28, 29.00it/s] 28%|██▊       | 314/1130 [00:16<00:25, 31.83it/s] 28%|██▊       | 318/1130 [00:16<00:26, 31.05it/s] 28%|██▊       | 322/1130 [00:16<00:24, 33.11it/s] 29%|██▉       | 327/1130 [00:16<00:21, 36.51it/s] 29%|██▉       | 331/1130 [00:17<00:25, 31.77it/s] 30%|██▉       | 335/1130 [00:17<00:27, 29.40it/s] 30%|███       | 339/1130 [00:17<00:28, 27.80it/s] 30%|███       | 342/1130 [00:17<00:28, 28.04it/s] 31%|███       | 346/1130 [00:17<00:27, 28.02it/s] 31%|███       | 349/1130 [00:17<00:27, 28.27it/s] 31%|███       | 352/1130 [00:17<00:27, 28.42it/s] 31%|███▏      | 355/1130 [00:17<00:27, 28.70it/s] 32%|███▏      | 358/1130 [00:18<00:26, 28.98it/s] 32%|███▏      | 361/1130 [00:18<00:26, 28.52it/s] 32%|███▏      | 365/1130 [00:18<00:25, 30.58it/s] 33%|███▎      | 369/1130 [00:18<00:25, 29.77it/s] 33%|███▎      | 373/1130 [00:18<00:23, 32.38it/s] 33%|███▎      | 378/1130 [00:18<00:21, 34.79it/s] 34%|███▍      | 382/1130 [00:18<00:21, 34.68it/s] 34%|███▍      | 386/1130 [00:18<00:23, 31.03it/s] 35%|███▍      | 390/1130 [00:19<00:22, 32.45it/s] 35%|███▍      | 394/1130 [00:19<00:22, 32.48it/s] 35%|███▌      | 398/1130 [00:19<00:24, 29.43it/s] 36%|███▌      | 402/1130 [00:19<00:25, 28.93it/s] 36%|███▌      | 406/1130 [00:19<00:23, 30.98it/s] 36%|███▋      | 410/1130 [00:19<00:23, 30.52it/s] 37%|███▋      | 414/1130 [00:19<00:24, 28.66it/s] 37%|███▋      | 419/1130 [00:19<00:22, 31.40it/s] 37%|███▋      | 423/1130 [00:20<00:23, 29.80it/s] 38%|███▊      | 427/1130 [00:20<00:28, 24.98it/s] 38%|███▊      | 431/1130 [00:20<00:26, 26.76it/s] 38%|███▊      | 435/1130 [00:20<00:24, 28.82it/s] 39%|███▉      | 439/1130 [00:20<00:23, 29.25it/s] 39%|███▉      | 443/1130 [00:20<00:25, 26.82it/s] 39%|███▉      | 446/1130 [00:21<00:26, 25.77it/s] 40%|███▉      | 451/1130 [00:21<00:22, 29.89it/s] 40%|████      | 455/1130 [00:21<00:23, 29.24it/s] 41%|████      | 459/1130 [00:21<00:23, 29.05it/s] 41%|████      | 463/1130 [00:21<00:21, 31.41it/s] 41%|████▏     | 467/1130 [00:21<00:20, 32.71it/s] 42%|████▏     | 471/1130 [00:21<00:21, 30.96it/s] 42%|████▏     | 475/1130 [00:21<00:20, 32.16it/s] 42%|████▏     | 479/1130 [00:22<00:19, 33.73it/s] 43%|████▎     | 483/1130 [00:22<00:20, 32.20it/s] 43%|████▎     | 487/1130 [00:22<00:21, 30.35it/s] 43%|████▎     | 491/1130 [00:22<00:19, 32.12it/s] 44%|████▍     | 495/1130 [00:22<00:22, 28.44it/s] 44%|████▍     | 499/1130 [00:22<00:22, 28.60it/s] 44%|████▍     | 502/1130 [00:22<00:24, 25.34it/s] 45%|████▍     | 506/1130 [00:23<00:22, 27.25it/s] 45%|████▌     | 509/1130 [00:23<00:25, 24.18it/s] 45%|████▌     | 513/1130 [00:23<00:22, 26.99it/s] 46%|████▌     | 517/1130 [00:23<00:22, 27.14it/s] 46%|████▌     | 520/1130 [00:23<00:24, 25.29it/s] 46%|████▋     | 523/1130 [00:23<00:24, 24.68it/s] 47%|████▋     | 528/1130 [00:23<00:22, 27.11it/s] 47%|████▋     | 532/1130 [00:24<00:22, 26.86it/s] 47%|████▋     | 536/1130 [00:24<00:20, 29.11it/s] 48%|████▊     | 539/1130 [00:24<00:20, 28.36it/s] 48%|████▊     | 542/1130 [00:24<00:23, 25.44it/s] 48%|████▊     | 545/1130 [00:24<00:24, 23.51it/s] 49%|████▊     | 549/1130 [00:24<00:22, 26.08it/s] 49%|████▉     | 554/1130 [00:24<00:18, 30.52it/s] 49%|████▉     | 558/1130 [00:24<00:20, 28.15it/s] 50%|████▉     | 562/1130 [00:25<00:20, 28.36it/s] 50%|█████     | 566/1130 [00:25<00:19, 29.68it/s] 50%|█████     | 570/1130 [00:25<00:21, 25.87it/s] 51%|█████     | 574/1130 [00:25<00:20, 26.58it/s] 51%|█████     | 577/1130 [00:25<00:21, 25.36it/s] 51%|█████▏    | 580/1130 [00:25<00:23, 23.05it/s] 52%|█████▏    | 583/1130 [00:26<00:24, 22.33it/s] 52%|█████▏    | 586/1130 [00:26<00:23, 23.02it/s] 52%|█████▏    | 589/1130 [00:26<00:25, 20.90it/s] 52%|█████▏    | 592/1130 [00:26<00:25, 21.19it/s] 53%|█████▎    | 596/1130 [00:26<00:22, 23.49it/s] 53%|█████▎    | 599/1130 [00:26<00:21, 24.62it/s] 53%|█████▎    | 603/1130 [00:26<00:20, 25.82it/s] 54%|█████▎    | 607/1130 [00:26<00:20, 25.94it/s] 54%|█████▍    | 610/1130 [00:27<00:20, 24.80it/s] 54%|█████▍    | 613/1130 [00:27<00:20, 25.10it/s] 55%|█████▍    | 618/1130 [00:27<00:18, 27.86it/s] 55%|█████▍    | 621/1130 [00:27<00:18, 27.20it/s] 55%|█████▌    | 625/1130 [00:27<00:17, 29.62it/s] 56%|█████▌    | 628/1130 [00:27<00:18, 27.25it/s] 56%|█████▌    | 631/1130 [00:27<00:18, 26.83it/s] 56%|█████▋    | 636/1130 [00:27<00:16, 30.68it/s] 57%|█████▋    | 640/1130 [00:28<00:18, 26.30it/s] 57%|█████▋    | 644/1130 [00:28<00:16, 29.29it/s] 57%|█████▋    | 648/1130 [00:28<00:16, 29.26it/s] 58%|█████▊    | 652/1130 [00:28<00:18, 26.50it/s] 58%|█████▊    | 655/1130 [00:28<00:17, 26.70it/s] 58%|█████▊    | 660/1130 [00:28<00:15, 30.94it/s] 59%|█████▉    | 664/1130 [00:28<00:14, 31.77it/s] 59%|█████▉    | 668/1130 [00:29<00:15, 30.31it/s] 59%|█████▉    | 672/1130 [00:29<00:14, 31.85it/s] 60%|█████▉    | 676/1130 [00:29<00:15, 29.43it/s] 60%|██████    | 680/1130 [00:29<00:14, 31.38it/s] 61%|██████    | 684/1130 [00:29<00:16, 27.07it/s] 61%|██████    | 687/1130 [00:29<00:17, 26.04it/s] 61%|██████    | 690/1130 [00:29<00:18, 23.44it/s] 61%|██████▏   | 694/1130 [00:30<00:16, 26.20it/s] 62%|██████▏   | 697/1130 [00:30<00:16, 26.65it/s] 62%|██████▏   | 700/1130 [00:30<00:16, 26.70it/s] 62%|██████▏   | 703/1130 [00:30<00:18, 23.07it/s] 62%|██████▏   | 706/1130 [00:30<00:18, 22.97it/s] 63%|██████▎   | 709/1130 [00:30<00:17, 23.72it/s] 63%|██████▎   | 713/1130 [00:30<00:15, 26.48it/s] 63%|██████▎   | 716/1130 [00:30<00:16, 25.58it/s] 64%|██████▎   | 719/1130 [00:31<00:16, 25.61it/s] 64%|██████▍   | 722/1130 [00:31<00:18, 22.41it/s] 64%|██████▍   | 725/1130 [00:31<00:17, 22.69it/s] 65%|██████▍   | 730/1130 [00:31<00:14, 27.21it/s] 65%|██████▍   | 733/1130 [00:31<00:15, 25.07it/s] 65%|██████▌   | 736/1130 [00:31<00:17, 22.93it/s] 65%|██████▌   | 739/1130 [00:31<00:16, 23.50it/s] 66%|██████▌   | 742/1130 [00:32<00:17, 22.25it/s] 66%|██████▌   | 746/1130 [00:32<00:14, 25.62it/s] 66%|██████▋   | 749/1130 [00:32<00:15, 24.34it/s] 67%|██████▋   | 752/1130 [00:32<00:14, 25.32it/s] 67%|██████▋   | 756/1130 [00:32<00:13, 27.54it/s] 67%|██████▋   | 759/1130 [00:32<00:13, 26.85it/s] 68%|██████▊   | 763/1130 [00:32<00:12, 29.10it/s] 68%|██████▊   | 766/1130 [00:32<00:14, 25.39it/s] 68%|██████▊   | 769/1130 [00:33<00:13, 25.81it/s] 68%|██████▊   | 773/1130 [00:33<00:12, 28.51it/s] 69%|██████▉   | 778/1130 [00:33<00:10, 33.46it/s] 69%|██████▉   | 782/1130 [00:33<00:12, 28.52it/s] 70%|██████▉   | 786/1130 [00:33<00:11, 30.56it/s] 70%|███████   | 791/1130 [00:33<00:09, 34.47it/s] 70%|███████   | 795/1130 [00:33<00:10, 32.21it/s] 71%|███████   | 799/1130 [00:34<00:11, 28.22it/s] 71%|███████   | 803/1130 [00:34<00:11, 27.92it/s] 71%|███████▏  | 807/1130 [00:34<00:10, 30.45it/s] 72%|███████▏  | 811/1130 [00:34<00:09, 32.02it/s] 72%|███████▏  | 815/1130 [00:34<00:11, 28.63it/s] 72%|███████▏  | 819/1130 [00:34<00:10, 28.42it/s] 73%|███████▎  | 823/1130 [00:34<00:10, 30.63it/s] 73%|███████▎  | 827/1130 [00:34<00:09, 32.72it/s] 74%|███████▎  | 831/1130 [00:35<00:11, 25.92it/s] 74%|███████▍  | 834/1130 [00:35<00:11, 25.79it/s] 74%|███████▍  | 837/1130 [00:35<00:12, 23.74it/s] 74%|███████▍  | 840/1130 [00:35<00:13, 21.82it/s] 75%|███████▍  | 844/1130 [00:35<00:11, 24.73it/s] 75%|███████▍  | 847/1130 [00:35<00:10, 25.90it/s] 75%|███████▌  | 851/1130 [00:35<00:10, 26.07it/s] 76%|███████▌  | 854/1130 [00:36<00:11, 24.15it/s] 76%|███████▌  | 858/1130 [00:36<00:10, 25.99it/s] 76%|███████▋  | 862/1130 [00:36<00:09, 26.84it/s] 77%|███████▋  | 865/1130 [00:36<00:10, 25.01it/s] 77%|███████▋  | 869/1130 [00:36<00:09, 26.41it/s] 77%|███████▋  | 872/1130 [00:36<00:10, 25.19it/s] 78%|███████▊  | 877/1130 [00:36<00:08, 29.89it/s] 78%|███████▊  | 881/1130 [00:37<00:08, 28.40it/s] 78%|███████▊  | 886/1130 [00:37<00:07, 32.70it/s] 79%|███████▉  | 890/1130 [00:37<00:07, 32.48it/s] 79%|███████▉  | 894/1130 [00:37<00:07, 30.80it/s] 79%|███████▉  | 898/1130 [00:37<00:07, 30.22it/s] 80%|███████▉  | 902/1130 [00:37<00:07, 32.14it/s] 80%|████████  | 906/1130 [00:37<00:07, 30.39it/s] 81%|████████  | 910/1130 [00:37<00:07, 29.78it/s] 81%|████████  | 914/1130 [00:38<00:07, 28.36it/s] 81%|████████  | 917/1130 [00:38<00:08, 24.29it/s] 81%|████████▏ | 920/1130 [00:38<00:08, 24.15it/s] 82%|████████▏ | 923/1130 [00:38<00:09, 21.89it/s] 82%|████████▏ | 926/1130 [00:38<00:08, 22.95it/s] 82%|████████▏ | 929/1130 [00:38<00:09, 21.74it/s] 83%|████████▎ | 933/1130 [00:39<00:09, 21.44it/s] 83%|████████▎ | 936/1130 [00:39<00:08, 23.09it/s] 83%|████████▎ | 939/1130 [00:39<00:08, 23.47it/s] 83%|████████▎ | 942/1130 [00:39<00:07, 24.16it/s] 84%|████████▎ | 945/1130 [00:39<00:07, 24.29it/s] 84%|████████▍ | 949/1130 [00:39<00:06, 27.39it/s] 84%|████████▍ | 952/1130 [00:39<00:06, 26.30it/s] 85%|████████▍ | 955/1130 [00:39<00:06, 27.16it/s] 85%|████████▍ | 959/1130 [00:40<00:06, 26.49it/s] 85%|████████▌ | 963/1130 [00:40<00:05, 28.14it/s] 86%|████████▌ | 967/1130 [00:40<00:05, 29.61it/s] 86%|████████▌ | 970/1130 [00:40<00:07, 22.77it/s] 86%|████████▌ | 974/1130 [00:40<00:06, 25.71it/s] 87%|████████▋ | 978/1130 [00:40<00:05, 28.70it/s] 87%|████████▋ | 982/1130 [00:40<00:05, 26.24it/s] 87%|████████▋ | 987/1130 [00:41<00:04, 29.97it/s] 88%|████████▊ | 991/1130 [00:41<00:04, 31.88it/s] 88%|████████▊ | 995/1130 [00:41<00:05, 26.12it/s] 88%|████████▊ | 998/1130 [00:41<00:04, 26.90it/s] 89%|████████▊ | 1002/1130 [00:41<00:04, 28.19it/s] 89%|████████▉ | 1005/1130 [00:41<00:04, 27.48it/s] 89%|████████▉ | 1008/1130 [00:41<00:04, 26.57it/s] 89%|████████▉ | 1011/1130 [00:41<00:04, 25.58it/s] 90%|████████▉ | 1014/1130 [00:42<00:04, 26.18it/s] 90%|█████████ | 1019/1130 [00:42<00:03, 32.24it/s] 91%|█████████ | 1023/1130 [00:42<00:03, 31.47it/s] 91%|█████████ | 1028/1130 [00:42<00:02, 34.30it/s] 91%|█████████▏| 1032/1130 [00:42<00:02, 33.58it/s] 92%|█████████▏| 1036/1130 [00:42<00:02, 32.19it/s] 92%|█████████▏| 1040/1130 [00:42<00:02, 32.19it/s] 92%|█████████▏| 1044/1130 [00:42<00:02, 31.00it/s] 93%|█████████▎| 1048/1130 [00:43<00:02, 29.87it/s] 93%|█████████▎| 1052/1130 [00:43<00:02, 31.79it/s] 94%|█████████▎| 1057/1130 [00:43<00:02, 35.10it/s] 94%|█████████▍| 1061/1130 [00:43<00:02, 32.99it/s] 94%|█████████▍| 1065/1130 [00:43<00:02, 31.37it/s] 95%|█████████▍| 1069/1130 [00:43<00:02, 27.39it/s] 95%|█████████▌| 1074/1130 [00:43<00:01, 29.96it/s] 95%|█████████▌| 1078/1130 [00:44<00:01, 29.08it/s] 96%|█████████▌| 1082/1130 [00:44<00:01, 29.86it/s] 96%|█████████▌| 1086/1130 [00:44<00:01, 29.31it/s] 96%|█████████▋| 1090/1130 [00:44<00:01, 29.88it/s] 97%|█████████▋| 1094/1130 [00:44<00:01, 28.67it/s] 97%|█████████▋| 1097/1130 [00:44<00:01, 27.49it/s] 97%|█████████▋| 1100/1130 [00:44<00:01, 26.80it/s] 98%|█████████▊| 1103/1130 [00:45<00:01, 25.10it/s] 98%|█████████▊| 1107/1130 [00:45<00:00, 26.43it/s] 98%|█████████▊| 1110/1130 [00:45<00:00, 23.98it/s] 98%|█████████▊| 1113/1130 [00:45<00:00, 25.23it/s] 99%|█████████▉| 1117/1130 [00:45<00:00, 26.26it/s] 99%|█████████▉| 1121/1130 [00:45<00:00, 26.46it/s] 99%|█████████▉| 1124/1130 [00:45<00:00, 27.25it/s]100%|█████████▉| 1128/1130 [00:45<00:00, 29.80it/s]100%|██████████| 1130/1130 [00:45<00:00, 24.57it/s]
[COMBINE] Trainig data. Plane: "coronal" Slice "vertical"
[UTILS] Model name "model_base_meniscus_coronal_train_auc_0.8001_val_auc_0.7969_train_loss_0.7178_val_loss_0.6362_epoch_6_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.4.pth" for "coronal", Val AUC "0.7969", Architecture: "pretrained-resnet18", Augment: "albumentations-group" (prob 0.4)
Copying model...!
[COMBINE] Extracting predictions for task "meniscus" and plane "coronal"
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[DATALOADER] __init__ task: meniscus, plane: coronal, train: train
[DATALOADER] __init__ weights: [1, 1.8463476070528968]
  0%|          | 0/1130 [00:00<?, ?it/s]  0%|          | 2/1130 [00:00<01:03, 17.84it/s]  0%|          | 4/1130 [00:00<00:59, 18.99it/s]  1%|          | 8/1130 [00:00<00:39, 28.23it/s]  1%|          | 11/1130 [00:00<00:44, 25.03it/s]  1%|          | 14/1130 [00:00<00:49, 22.66it/s]  2%|▏         | 19/1130 [00:00<00:38, 28.77it/s]  2%|▏         | 25/1130 [00:00<00:33, 32.87it/s]  3%|▎         | 30/1130 [00:01<00:32, 33.93it/s]  3%|▎         | 34/1130 [00:01<00:34, 32.13it/s]  3%|▎         | 38/1130 [00:01<00:34, 31.58it/s]  4%|▎         | 42/1130 [00:01<00:38, 28.47it/s]  4%|▍         | 45/1130 [00:01<00:38, 27.98it/s]  4%|▍         | 50/1130 [00:01<00:33, 32.57it/s]  5%|▍         | 54/1130 [00:01<00:33, 32.43it/s]  5%|▌         | 58/1130 [00:02<00:40, 26.16it/s]  5%|▌         | 61/1130 [00:02<00:39, 26.73it/s]  6%|▌         | 65/1130 [00:02<00:37, 28.60it/s]  6%|▌         | 69/1130 [00:02<00:35, 30.05it/s]  7%|▋         | 74/1130 [00:02<00:30, 34.25it/s]  7%|▋         | 78/1130 [00:02<00:32, 32.18it/s]  7%|▋         | 82/1130 [00:02<00:34, 30.75it/s]  8%|▊         | 86/1130 [00:02<00:34, 30.43it/s]  8%|▊         | 90/1130 [00:03<00:34, 29.91it/s]  8%|▊         | 94/1130 [00:03<00:35, 29.04it/s]  9%|▊         | 97/1130 [00:03<00:35, 28.71it/s]  9%|▉         | 100/1130 [00:03<00:43, 23.90it/s]  9%|▉         | 105/1130 [00:03<00:35, 28.90it/s] 10%|▉         | 109/1130 [00:03<00:35, 28.70it/s] 10%|█         | 113/1130 [00:03<00:34, 29.91it/s] 10%|█         | 117/1130 [00:03<00:33, 30.66it/s] 11%|█         | 122/1130 [00:04<00:31, 31.98it/s] 11%|█         | 126/1130 [00:04<00:32, 30.59it/s] 12%|█▏        | 131/1130 [00:04<00:29, 33.90it/s] 12%|█▏        | 136/1130 [00:04<00:30, 33.12it/s] 12%|█▏        | 140/1130 [00:04<00:34, 28.69it/s] 13%|█▎        | 146/1130 [00:04<00:28, 34.87it/s] 13%|█▎        | 150/1130 [00:04<00:27, 35.11it/s] 14%|█▎        | 154/1130 [00:05<00:30, 32.14it/s] 14%|█▍        | 158/1130 [00:05<00:31, 30.93it/s] 14%|█▍        | 162/1130 [00:05<00:31, 31.01it/s] 15%|█▍        | 167/1130 [00:05<00:28, 34.36it/s] 15%|█▌        | 172/1130 [00:05<00:25, 37.17it/s] 16%|█▌        | 178/1130 [00:05<00:23, 40.73it/s] 16%|█▌        | 183/1130 [00:05<00:23, 40.81it/s] 17%|█▋        | 189/1130 [00:05<00:21, 43.52it/s] 17%|█▋        | 194/1130 [00:06<00:22, 41.67it/s] 18%|█▊        | 199/1130 [00:06<00:25, 36.97it/s] 18%|█▊        | 203/1130 [00:06<00:27, 33.26it/s] 18%|█▊        | 207/1130 [00:06<00:35, 26.17it/s] 19%|█▉        | 212/1130 [00:06<00:30, 30.36it/s] 19%|█▉        | 216/1130 [00:06<00:29, 31.11it/s] 19%|█▉        | 220/1130 [00:07<00:30, 30.30it/s] 20%|█▉        | 224/1130 [00:07<00:29, 31.18it/s] 20%|██        | 228/1130 [00:07<00:31, 28.46it/s] 21%|██        | 232/1130 [00:07<00:30, 29.77it/s] 21%|██        | 236/1130 [00:07<00:28, 31.01it/s] 21%|██▏       | 242/1130 [00:07<00:25, 35.25it/s] 22%|██▏       | 246/1130 [00:07<00:24, 36.21it/s] 22%|██▏       | 250/1130 [00:07<00:25, 34.31it/s] 23%|██▎       | 255/1130 [00:08<00:23, 36.94it/s] 23%|██▎       | 259/1130 [00:08<00:25, 34.70it/s] 23%|██▎       | 263/1130 [00:08<00:29, 29.48it/s] 24%|██▎       | 267/1130 [00:08<00:27, 31.54it/s] 24%|██▍       | 271/1130 [00:08<00:27, 31.64it/s] 24%|██▍       | 275/1130 [00:08<00:27, 30.96it/s] 25%|██▍       | 279/1130 [00:08<00:33, 25.37it/s] 25%|██▌       | 283/1130 [00:09<00:30, 27.73it/s] 25%|██▌       | 287/1130 [00:09<00:29, 28.89it/s] 26%|██▌       | 291/1130 [00:09<00:30, 27.84it/s] 26%|██▋       | 297/1130 [00:09<00:24, 34.62it/s] 27%|██▋       | 301/1130 [00:09<00:23, 35.82it/s] 27%|██▋       | 305/1130 [00:09<00:23, 35.42it/s] 27%|██▋       | 309/1130 [00:09<00:23, 35.40it/s] 28%|██▊       | 315/1130 [00:09<00:21, 38.15it/s] 28%|██▊       | 321/1130 [00:10<00:19, 41.84it/s] 29%|██▉       | 326/1130 [00:10<00:18, 42.85it/s] 29%|██▉       | 331/1130 [00:10<00:21, 37.38it/s] 30%|██▉       | 335/1130 [00:10<00:25, 30.74it/s] 30%|███       | 339/1130 [00:10<00:29, 27.08it/s] 30%|███       | 343/1130 [00:10<00:27, 28.71it/s] 31%|███       | 348/1130 [00:10<00:24, 31.95it/s] 31%|███       | 352/1130 [00:11<00:27, 28.15it/s] 32%|███▏      | 356/1130 [00:11<00:25, 30.37it/s] 32%|███▏      | 360/1130 [00:11<00:24, 31.24it/s] 32%|███▏      | 364/1130 [00:11<00:26, 28.98it/s] 33%|███▎      | 368/1130 [00:11<00:26, 28.26it/s] 33%|███▎      | 374/1130 [00:11<00:21, 35.03it/s] 34%|███▎      | 379/1130 [00:11<00:19, 37.70it/s] 34%|███▍      | 384/1130 [00:12<00:21, 34.44it/s] 34%|███▍      | 389/1130 [00:12<00:20, 36.14it/s] 35%|███▍      | 395/1130 [00:12<00:18, 40.80it/s] 35%|███▌      | 400/1130 [00:12<00:21, 34.33it/s] 36%|███▌      | 404/1130 [00:12<00:22, 32.41it/s] 36%|███▌      | 409/1130 [00:12<00:20, 35.95it/s] 37%|███▋      | 413/1130 [00:12<00:19, 36.27it/s] 37%|███▋      | 417/1130 [00:13<00:21, 33.11it/s] 37%|███▋      | 421/1130 [00:13<00:20, 34.22it/s] 38%|███▊      | 426/1130 [00:13<00:19, 36.18it/s] 38%|███▊      | 430/1130 [00:13<00:19, 35.10it/s] 38%|███▊      | 434/1130 [00:13<00:24, 28.46it/s] 39%|███▉      | 440/1130 [00:13<00:20, 33.46it/s] 39%|███▉      | 445/1130 [00:13<00:19, 35.84it/s] 40%|███▉      | 449/1130 [00:13<00:18, 36.57it/s] 40%|████      | 454/1130 [00:14<00:17, 38.80it/s] 41%|████      | 459/1130 [00:14<00:19, 34.02it/s] 41%|████      | 464/1130 [00:14<00:19, 34.90it/s] 42%|████▏     | 469/1130 [00:14<00:18, 35.93it/s] 42%|████▏     | 473/1130 [00:14<00:18, 35.50it/s] 42%|████▏     | 478/1130 [00:14<00:17, 36.66it/s] 43%|████▎     | 482/1130 [00:14<00:17, 37.01it/s] 43%|████▎     | 486/1130 [00:15<00:20, 31.73it/s] 43%|████▎     | 490/1130 [00:15<00:19, 32.46it/s] 44%|████▎     | 494/1130 [00:15<00:21, 29.93it/s] 44%|████▍     | 498/1130 [00:15<00:22, 28.17it/s] 44%|████▍     | 502/1130 [00:15<00:21, 28.84it/s] 45%|████▍     | 505/1130 [00:15<00:21, 28.63it/s] 45%|████▍     | 508/1130 [00:15<00:23, 26.96it/s] 45%|████▌     | 512/1130 [00:15<00:20, 29.73it/s] 46%|████▌     | 516/1130 [00:16<00:19, 31.71it/s] 46%|████▌     | 520/1130 [00:16<00:23, 26.20it/s] 46%|████▋     | 523/1130 [00:16<00:27, 22.27it/s] 47%|████▋     | 527/1130 [00:16<00:23, 25.54it/s] 47%|████▋     | 531/1130 [00:16<00:22, 26.59it/s] 47%|████▋     | 534/1130 [00:16<00:23, 25.63it/s] 48%|████▊     | 538/1130 [00:16<00:20, 28.61it/s] 48%|████▊     | 542/1130 [00:17<00:20, 28.52it/s] 48%|████▊     | 545/1130 [00:17<00:22, 26.09it/s] 49%|████▊     | 549/1130 [00:17<00:21, 26.57it/s] 49%|████▉     | 554/1130 [00:17<00:18, 31.77it/s] 49%|████▉     | 559/1130 [00:17<00:16, 34.89it/s] 50%|████▉     | 564/1130 [00:17<00:15, 37.27it/s] 50%|█████     | 569/1130 [00:17<00:14, 40.07it/s] 51%|█████     | 574/1130 [00:17<00:16, 34.36it/s] 51%|█████     | 578/1130 [00:18<00:17, 31.41it/s] 52%|█████▏    | 582/1130 [00:18<00:17, 31.16it/s] 52%|█████▏    | 586/1130 [00:18<00:18, 29.76it/s] 52%|█████▏    | 591/1130 [00:18<00:15, 33.89it/s] 53%|█████▎    | 595/1130 [00:18<00:18, 28.60it/s] 53%|█████▎    | 599/1130 [00:18<00:17, 30.13it/s] 53%|█████▎    | 604/1130 [00:18<00:16, 32.60it/s] 54%|█████▍    | 608/1130 [00:19<00:15, 34.14it/s] 54%|█████▍    | 612/1130 [00:19<00:15, 32.89it/s] 55%|█████▍    | 616/1130 [00:19<00:15, 32.37it/s] 55%|█████▍    | 620/1130 [00:19<00:15, 32.63it/s] 55%|█████▌    | 624/1130 [00:19<00:15, 33.15it/s] 56%|█████▌    | 628/1130 [00:19<00:16, 29.93it/s] 56%|█████▌    | 633/1130 [00:19<00:16, 30.81it/s] 56%|█████▋    | 637/1130 [00:20<00:15, 31.04it/s] 57%|█████▋    | 641/1130 [00:20<00:16, 29.40it/s] 57%|█████▋    | 645/1130 [00:20<00:16, 28.68it/s] 57%|█████▋    | 649/1130 [00:20<00:15, 31.02it/s] 58%|█████▊    | 653/1130 [00:20<00:15, 30.84it/s] 58%|█████▊    | 657/1130 [00:20<00:15, 31.08it/s] 59%|█████▊    | 662/1130 [00:20<00:13, 34.97it/s] 59%|█████▉    | 666/1130 [00:21<00:17, 27.20it/s] 59%|█████▉    | 670/1130 [00:21<00:15, 29.86it/s] 60%|█████▉    | 674/1130 [00:21<00:14, 31.86it/s] 60%|██████    | 679/1130 [00:21<00:12, 35.02it/s] 60%|██████    | 683/1130 [00:21<00:13, 33.50it/s] 61%|██████    | 687/1130 [00:21<00:13, 33.70it/s] 61%|██████    | 691/1130 [00:21<00:13, 31.98it/s] 62%|██████▏   | 695/1130 [00:21<00:12, 33.86it/s] 62%|██████▏   | 699/1130 [00:22<00:14, 28.76it/s] 62%|██████▏   | 703/1130 [00:22<00:15, 28.00it/s] 62%|██████▏   | 706/1130 [00:22<00:15, 27.26it/s] 63%|██████▎   | 711/1130 [00:22<00:15, 26.24it/s] 63%|██████▎   | 716/1130 [00:22<00:13, 29.67it/s] 64%|██████▎   | 720/1130 [00:22<00:13, 29.60it/s] 64%|██████▍   | 724/1130 [00:22<00:14, 28.07it/s] 64%|██████▍   | 728/1130 [00:23<00:13, 30.35it/s] 65%|██████▍   | 732/1130 [00:23<00:14, 26.68it/s] 65%|██████▌   | 736/1130 [00:23<00:14, 28.04it/s] 65%|██████▌   | 739/1130 [00:23<00:15, 25.46it/s] 66%|██████▌   | 742/1130 [00:23<00:15, 25.51it/s] 66%|██████▌   | 745/1130 [00:23<00:15, 24.61it/s] 66%|██████▌   | 748/1130 [00:23<00:15, 25.24it/s] 66%|██████▋   | 751/1130 [00:23<00:15, 23.97it/s] 67%|██████▋   | 754/1130 [00:24<00:15, 24.57it/s] 67%|██████▋   | 759/1130 [00:24<00:11, 30.96it/s] 68%|██████▊   | 763/1130 [00:24<00:13, 28.01it/s] 68%|██████▊   | 767/1130 [00:24<00:12, 29.65it/s] 68%|██████▊   | 771/1130 [00:24<00:11, 32.18it/s] 69%|██████▊   | 776/1130 [00:24<00:10, 35.15it/s] 69%|██████▉   | 780/1130 [00:24<00:10, 34.22it/s] 69%|██████▉   | 785/1130 [00:24<00:09, 35.15it/s] 70%|██████▉   | 789/1130 [00:25<00:10, 33.93it/s] 70%|███████   | 793/1130 [00:25<00:10, 32.21it/s] 71%|███████   | 798/1130 [00:25<00:09, 34.14it/s] 71%|███████   | 802/1130 [00:25<00:09, 34.71it/s] 71%|███████▏  | 807/1130 [00:25<00:08, 37.37it/s] 72%|███████▏  | 814/1130 [00:25<00:07, 44.66it/s] 73%|███████▎  | 820/1130 [00:25<00:06, 47.20it/s] 73%|███████▎  | 825/1130 [00:25<00:06, 44.83it/s] 73%|███████▎  | 830/1130 [00:26<00:07, 39.40it/s] 74%|███████▍  | 835/1130 [00:26<00:07, 38.63it/s] 74%|███████▍  | 839/1130 [00:26<00:08, 36.15it/s] 75%|███████▍  | 844/1130 [00:26<00:08, 35.56it/s] 75%|███████▌  | 848/1130 [00:26<00:08, 34.52it/s] 75%|███████▌  | 852/1130 [00:26<00:08, 33.07it/s] 76%|███████▌  | 856/1130 [00:26<00:09, 29.56it/s] 76%|███████▌  | 860/1130 [00:27<00:08, 31.31it/s] 76%|███████▋  | 864/1130 [00:27<00:09, 29.36it/s] 77%|███████▋  | 868/1130 [00:27<00:09, 27.25it/s] 77%|███████▋  | 871/1130 [00:27<00:09, 27.77it/s] 78%|███████▊  | 877/1130 [00:27<00:07, 34.42it/s] 78%|███████▊  | 881/1130 [00:27<00:08, 30.73it/s] 78%|███████▊  | 885/1130 [00:27<00:07, 30.86it/s] 79%|███████▊  | 889/1130 [00:28<00:08, 29.10it/s] 79%|███████▉  | 893/1130 [00:28<00:07, 30.43it/s] 79%|███████▉  | 897/1130 [00:28<00:07, 31.85it/s] 80%|███████▉  | 902/1130 [00:28<00:06, 35.54it/s] 80%|████████  | 906/1130 [00:28<00:06, 33.25it/s] 81%|████████  | 910/1130 [00:28<00:06, 32.45it/s] 81%|████████  | 914/1130 [00:28<00:06, 32.16it/s] 81%|████████  | 918/1130 [00:28<00:06, 31.13it/s] 82%|████████▏ | 922/1130 [00:29<00:06, 31.81it/s] 82%|████████▏ | 927/1130 [00:29<00:05, 34.76it/s] 82%|████████▏ | 931/1130 [00:29<00:05, 34.96it/s] 83%|████████▎ | 935/1130 [00:29<00:06, 30.20it/s] 83%|████████▎ | 940/1130 [00:29<00:05, 33.52it/s] 84%|████████▎ | 944/1130 [00:29<00:05, 32.88it/s] 84%|████████▍ | 948/1130 [00:29<00:05, 34.62it/s] 84%|████████▍ | 952/1130 [00:29<00:05, 32.68it/s] 85%|████████▍ | 956/1130 [00:30<00:05, 31.04it/s] 85%|████████▍ | 960/1130 [00:30<00:05, 31.35it/s] 85%|████████▌ | 965/1130 [00:30<00:04, 35.79it/s] 86%|████████▌ | 969/1130 [00:30<00:04, 34.10it/s] 86%|████████▌ | 973/1130 [00:30<00:04, 34.33it/s] 87%|████████▋ | 978/1130 [00:30<00:04, 36.27it/s] 87%|████████▋ | 982/1130 [00:30<00:04, 33.89it/s] 87%|████████▋ | 988/1130 [00:30<00:03, 35.88it/s] 88%|████████▊ | 992/1130 [00:31<00:03, 36.12it/s] 88%|████████▊ | 996/1130 [00:31<00:03, 34.72it/s] 88%|████████▊ | 1000/1130 [00:31<00:03, 35.45it/s] 89%|████████▉ | 1005/1130 [00:31<00:03, 38.46it/s] 89%|████████▉ | 1009/1130 [00:31<00:03, 36.38it/s] 90%|████████▉ | 1013/1130 [00:31<00:03, 36.67it/s] 90%|█████████ | 1017/1130 [00:31<00:03, 36.63it/s] 90%|█████████ | 1022/1130 [00:31<00:02, 38.26it/s] 91%|█████████ | 1028/1130 [00:32<00:02, 41.89it/s] 91%|█████████▏| 1033/1130 [00:32<00:02, 40.47it/s] 92%|█████████▏| 1038/1130 [00:32<00:02, 38.21it/s] 92%|█████████▏| 1042/1130 [00:32<00:02, 35.79it/s] 93%|█████████▎| 1046/1130 [00:32<00:02, 33.61it/s] 93%|█████████▎| 1050/1130 [00:32<00:02, 33.49it/s] 93%|█████████▎| 1054/1130 [00:32<00:02, 31.88it/s] 94%|█████████▎| 1058/1130 [00:33<00:02, 27.42it/s] 94%|█████████▍| 1063/1130 [00:33<00:02, 31.94it/s] 94%|█████████▍| 1067/1130 [00:33<00:01, 32.22it/s] 95%|█████████▍| 1071/1130 [00:33<00:01, 29.75it/s] 95%|█████████▌| 1076/1130 [00:33<00:01, 31.33it/s] 96%|█████████▌| 1080/1130 [00:33<00:01, 30.83it/s] 96%|█████████▌| 1084/1130 [00:33<00:01, 31.43it/s] 96%|█████████▋| 1088/1130 [00:33<00:01, 31.41it/s] 97%|█████████▋| 1092/1130 [00:34<00:01, 28.66it/s] 97%|█████████▋| 1095/1130 [00:34<00:01, 26.46it/s] 97%|█████████▋| 1099/1130 [00:34<00:01, 27.89it/s] 98%|█████████▊| 1103/1130 [00:34<00:00, 29.65it/s] 98%|█████████▊| 1107/1130 [00:34<00:00, 28.09it/s] 98%|█████████▊| 1112/1130 [00:34<00:00, 31.68it/s] 99%|█████████▉| 1116/1130 [00:34<00:00, 31.17it/s] 99%|█████████▉| 1120/1130 [00:35<00:00, 32.55it/s] 99%|█████████▉| 1124/1130 [00:35<00:00, 33.75it/s]100%|█████████▉| 1128/1130 [00:35<00:00, 35.19it/s]100%|██████████| 1130/1130 [00:35<00:00, 32.01it/s]
[COMBINE] Trainig data. Plane: "sagittal" Slice "vertical"
[UTILS] Model name "model_base_meniscus_sagittal_train_auc_0.7040_val_auc_0.6553_train_loss_0.8191_val_loss_0.7721_epoch_4_arch_pretrained-resnet18_cut_vertical_augment_albumentations-group_augment-probability_0.9.pth" for "sagittal", Val AUC "0.6553", Architecture: "pretrained-resnet18", Augment: "albumentations-group" (prob 0.9)
Copying model...!
[COMBINE] Extracting predictions for task "meniscus" and plane "sagittal"
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[DATALOADER] __init__ task: meniscus, plane: sagittal, train: train
[DATALOADER] __init__ weights: [1, 1.8463476070528968]
  0%|          | 0/1130 [00:00<?, ?it/s]  0%|          | 3/1130 [00:00<00:43, 26.11it/s]  1%|          | 6/1130 [00:00<00:42, 26.57it/s]  1%|          | 11/1130 [00:00<00:40, 27.70it/s]  1%|          | 14/1130 [00:00<00:39, 28.02it/s]  2%|▏         | 18/1130 [00:00<00:38, 28.91it/s]  2%|▏         | 22/1130 [00:00<00:35, 31.27it/s]  2%|▏         | 26/1130 [00:00<00:42, 25.73it/s]  3%|▎         | 30/1130 [00:01<00:40, 27.00it/s]  3%|▎         | 34/1130 [00:01<00:39, 28.01it/s]  3%|▎         | 38/1130 [00:01<00:36, 29.91it/s]  4%|▎         | 42/1130 [00:01<00:37, 29.19it/s]  4%|▍         | 45/1130 [00:01<00:43, 25.16it/s]  4%|▍         | 49/1130 [00:01<00:38, 28.37it/s]  5%|▍         | 53/1130 [00:01<00:39, 27.35it/s]  5%|▍         | 56/1130 [00:02<00:42, 25.48it/s]  5%|▌         | 59/1130 [00:02<00:42, 25.47it/s]  6%|▌         | 63/1130 [00:02<00:37, 28.34it/s]  6%|▌         | 67/1130 [00:02<00:34, 30.39it/s]  6%|▋         | 71/1130 [00:02<00:32, 32.84it/s]  7%|▋         | 75/1130 [00:02<00:33, 31.84it/s]  7%|▋         | 79/1130 [00:02<00:30, 33.93it/s]  7%|▋         | 83/1130 [00:02<00:31, 33.03it/s]  8%|▊         | 87/1130 [00:02<00:30, 33.89it/s]  8%|▊         | 91/1130 [00:03<00:30, 33.75it/s]  8%|▊         | 95/1130 [00:03<00:32, 31.82it/s]  9%|▉         | 99/1130 [00:03<00:34, 29.51it/s]  9%|▉         | 103/1130 [00:03<00:32, 31.16it/s]  9%|▉         | 107/1130 [00:03<00:30, 33.31it/s] 10%|▉         | 111/1130 [00:03<00:33, 30.24it/s] 10%|█         | 115/1130 [00:03<00:31, 31.73it/s] 11%|█         | 120/1130 [00:04<00:30, 33.10it/s] 11%|█         | 125/1130 [00:04<00:28, 35.87it/s] 11%|█▏        | 129/1130 [00:04<00:28, 34.86it/s] 12%|█▏        | 133/1130 [00:04<00:31, 31.50it/s] 12%|█▏        | 137/1130 [00:04<00:33, 29.81it/s] 12%|█▏        | 141/1130 [00:04<00:35, 27.49it/s] 13%|█▎        | 145/1130 [00:04<00:32, 30.04it/s] 13%|█▎        | 149/1130 [00:04<00:33, 29.14it/s] 14%|█▎        | 153/1130 [00:05<00:33, 29.26it/s] 14%|█▍        | 156/1130 [00:05<00:34, 28.45it/s] 14%|█▍        | 159/1130 [00:05<00:35, 27.10it/s] 14%|█▍        | 163/1130 [00:05<00:33, 28.90it/s] 15%|█▍        | 166/1130 [00:05<00:34, 28.06it/s] 15%|█▌        | 170/1130 [00:05<00:34, 28.13it/s] 15%|█▌        | 174/1130 [00:05<00:31, 30.08it/s] 16%|█▌        | 178/1130 [00:05<00:31, 30.07it/s] 16%|█▌        | 182/1130 [00:06<00:31, 30.18it/s] 16%|█▋        | 186/1130 [00:06<00:31, 29.55it/s] 17%|█▋        | 189/1130 [00:06<00:33, 28.14it/s] 17%|█▋        | 193/1130 [00:06<00:30, 30.49it/s] 17%|█▋        | 197/1130 [00:06<00:30, 30.21it/s] 18%|█▊        | 201/1130 [00:06<00:33, 27.94it/s] 18%|█▊        | 204/1130 [00:06<00:33, 27.43it/s] 18%|█▊        | 207/1130 [00:07<00:33, 27.46it/s] 19%|█▊        | 210/1130 [00:07<00:33, 27.17it/s] 19%|█▉        | 213/1130 [00:07<00:33, 27.24it/s] 19%|█▉        | 217/1130 [00:07<00:32, 28.22it/s] 20%|█▉        | 221/1130 [00:07<00:29, 30.46it/s] 20%|█▉        | 225/1130 [00:07<00:29, 30.30it/s] 20%|██        | 230/1130 [00:07<00:26, 33.82it/s] 21%|██        | 234/1130 [00:07<00:28, 31.88it/s] 21%|██        | 238/1130 [00:08<00:29, 30.04it/s] 21%|██▏       | 242/1130 [00:08<00:27, 31.79it/s] 22%|██▏       | 247/1130 [00:08<00:26, 33.44it/s] 22%|██▏       | 251/1130 [00:08<00:26, 33.13it/s] 23%|██▎       | 255/1130 [00:08<00:27, 32.27it/s] 23%|██▎       | 259/1130 [00:08<00:26, 33.10it/s] 23%|██▎       | 263/1130 [00:08<00:27, 31.11it/s] 24%|██▎       | 267/1130 [00:08<00:29, 28.92it/s] 24%|██▍       | 271/1130 [00:09<00:29, 29.30it/s] 24%|██▍       | 275/1130 [00:09<00:28, 29.80it/s] 25%|██▍       | 279/1130 [00:09<00:29, 28.96it/s] 25%|██▌       | 283/1130 [00:09<00:28, 30.09it/s] 25%|██▌       | 287/1130 [00:09<00:29, 28.79it/s] 26%|██▌       | 290/1130 [00:09<00:29, 28.91it/s] 26%|██▌       | 294/1130 [00:09<00:26, 31.51it/s] 26%|██▋       | 298/1130 [00:09<00:25, 33.03it/s] 27%|██▋       | 302/1130 [00:10<00:25, 31.85it/s] 27%|██▋       | 306/1130 [00:10<00:26, 30.76it/s] 27%|██▋       | 310/1130 [00:10<00:25, 31.56it/s] 28%|██▊       | 315/1130 [00:10<00:23, 34.07it/s] 28%|██▊       | 319/1130 [00:10<00:23, 34.03it/s] 29%|██▊       | 323/1130 [00:10<00:23, 33.94it/s] 29%|██▉       | 327/1130 [00:10<00:24, 33.36it/s] 29%|██▉       | 331/1130 [00:10<00:27, 29.40it/s] 30%|██▉       | 335/1130 [00:11<00:29, 27.14it/s] 30%|███       | 339/1130 [00:11<00:27, 28.44it/s] 30%|███       | 342/1130 [00:11<00:31, 24.83it/s] 31%|███       | 346/1130 [00:11<00:30, 25.46it/s] 31%|███       | 349/1130 [00:11<00:29, 26.35it/s] 31%|███       | 352/1130 [00:11<00:29, 26.35it/s] 32%|███▏      | 357/1130 [00:11<00:25, 30.01it/s] 32%|███▏      | 361/1130 [00:12<00:24, 31.91it/s] 32%|███▏      | 365/1130 [00:12<00:24, 31.87it/s] 33%|███▎      | 369/1130 [00:12<00:24, 30.70it/s] 33%|███▎      | 373/1130 [00:12<00:23, 32.81it/s] 33%|███▎      | 377/1130 [00:12<00:21, 34.51it/s] 34%|███▎      | 381/1130 [00:12<00:21, 35.52it/s] 34%|███▍      | 385/1130 [00:12<00:23, 31.30it/s] 34%|███▍      | 389/1130 [00:12<00:22, 32.51it/s] 35%|███▍      | 393/1130 [00:13<00:22, 32.52it/s] 35%|███▌      | 398/1130 [00:13<00:21, 34.70it/s] 36%|███▌      | 402/1130 [00:13<00:22, 33.06it/s] 36%|███▌      | 406/1130 [00:13<00:21, 33.94it/s] 36%|███▋      | 410/1130 [00:13<00:21, 33.31it/s] 37%|███▋      | 414/1130 [00:13<00:21, 33.25it/s] 37%|███▋      | 418/1130 [00:13<00:22, 31.44it/s] 37%|███▋      | 422/1130 [00:13<00:21, 33.54it/s] 38%|███▊      | 426/1130 [00:14<00:21, 33.31it/s] 38%|███▊      | 430/1130 [00:14<00:20, 34.21it/s] 38%|███▊      | 434/1130 [00:14<00:22, 30.61it/s] 39%|███▉      | 438/1130 [00:14<00:21, 31.87it/s] 39%|███▉      | 443/1130 [00:14<00:20, 34.20it/s] 40%|███▉      | 447/1130 [00:14<00:20, 34.11it/s] 40%|███▉      | 451/1130 [00:14<00:20, 33.26it/s] 40%|████      | 455/1130 [00:14<00:19, 33.84it/s] 41%|████      | 459/1130 [00:15<00:21, 31.58it/s] 41%|████      | 464/1130 [00:15<00:18, 35.24it/s] 42%|████▏     | 469/1130 [00:15<00:18, 35.11it/s] 42%|████▏     | 473/1130 [00:15<00:19, 33.17it/s] 42%|████▏     | 477/1130 [00:15<00:20, 32.10it/s] 43%|████▎     | 481/1130 [00:15<00:20, 32.31it/s] 43%|████▎     | 485/1130 [00:15<00:19, 32.87it/s] 43%|████▎     | 489/1130 [00:15<00:21, 29.45it/s] 44%|████▎     | 493/1130 [00:16<00:20, 30.54it/s] 44%|████▍     | 497/1130 [00:16<00:20, 30.28it/s] 44%|████▍     | 502/1130 [00:16<00:19, 32.30it/s] 45%|████▍     | 506/1130 [00:16<00:19, 31.88it/s] 45%|████▌     | 510/1130 [00:16<00:18, 32.79it/s] 45%|████▌     | 514/1130 [00:16<00:18, 33.02it/s] 46%|████▌     | 518/1130 [00:16<00:18, 32.52it/s] 46%|████▌     | 522/1130 [00:17<00:19, 30.50it/s] 47%|████▋     | 526/1130 [00:17<00:21, 28.23it/s] 47%|████▋     | 530/1130 [00:17<00:20, 29.14it/s] 47%|████▋     | 534/1130 [00:17<00:19, 30.57it/s] 48%|████▊     | 538/1130 [00:17<00:19, 30.84it/s] 48%|████▊     | 542/1130 [00:17<00:18, 31.58it/s] 48%|████▊     | 546/1130 [00:17<00:18, 31.11it/s] 49%|████▊     | 550/1130 [00:17<00:21, 27.49it/s] 49%|████▉     | 554/1130 [00:18<00:20, 28.68it/s] 49%|████▉     | 557/1130 [00:18<00:19, 28.85it/s] 50%|████▉     | 562/1130 [00:18<00:18, 31.53it/s] 50%|█████     | 566/1130 [00:18<00:16, 33.23it/s] 51%|█████     | 571/1130 [00:18<00:15, 35.79it/s] 51%|█████     | 575/1130 [00:18<00:16, 33.04it/s] 51%|█████     | 579/1130 [00:18<00:16, 33.86it/s] 52%|█████▏    | 583/1130 [00:18<00:15, 34.21it/s] 52%|█████▏    | 587/1130 [00:19<00:16, 32.52it/s] 52%|█████▏    | 591/1130 [00:19<00:16, 32.80it/s] 53%|█████▎    | 595/1130 [00:19<00:16, 32.55it/s] 53%|█████▎    | 599/1130 [00:19<00:16, 31.99it/s] 53%|█████▎    | 603/1130 [00:19<00:15, 33.31it/s] 54%|█████▎    | 607/1130 [00:19<00:15, 33.75it/s] 54%|█████▍    | 611/1130 [00:19<00:15, 34.51it/s] 54%|█████▍    | 615/1130 [00:19<00:14, 34.81it/s] 55%|█████▍    | 619/1130 [00:20<00:15, 33.85it/s] 55%|█████▌    | 623/1130 [00:20<00:14, 35.42it/s] 55%|█████▌    | 627/1130 [00:20<00:14, 33.70it/s] 56%|█████▌    | 631/1130 [00:20<00:15, 31.77it/s] 56%|█████▌    | 635/1130 [00:20<00:16, 29.98it/s] 57%|█████▋    | 639/1130 [00:20<00:15, 31.66it/s] 57%|█████▋    | 643/1130 [00:20<00:14, 32.69it/s] 57%|█████▋    | 647/1130 [00:20<00:14, 34.02it/s] 58%|█████▊    | 651/1130 [00:21<00:14, 31.99it/s] 58%|█████▊    | 655/1130 [00:21<00:14, 33.71it/s] 58%|█████▊    | 659/1130 [00:21<00:14, 32.21it/s] 59%|█████▊    | 663/1130 [00:21<00:15, 30.13it/s] 59%|█████▉    | 667/1130 [00:21<00:14, 32.41it/s] 59%|█████▉    | 672/1130 [00:21<00:13, 35.11it/s] 60%|█████▉    | 676/1130 [00:21<00:12, 35.18it/s] 60%|██████    | 681/1130 [00:21<00:12, 37.00it/s] 61%|██████    | 685/1130 [00:21<00:12, 35.05it/s] 61%|██████    | 689/1130 [00:22<00:13, 33.50it/s] 61%|██████▏   | 693/1130 [00:22<00:13, 32.80it/s] 62%|██████▏   | 697/1130 [00:22<00:13, 32.12it/s] 62%|██████▏   | 701/1130 [00:22<00:13, 32.33it/s] 62%|██████▏   | 705/1130 [00:22<00:14, 30.00it/s] 63%|██████▎   | 709/1130 [00:22<00:13, 30.67it/s] 63%|██████▎   | 713/1130 [00:22<00:14, 29.31it/s] 63%|██████▎   | 716/1130 [00:23<00:14, 28.93it/s] 64%|██████▎   | 719/1130 [00:23<00:14, 27.81it/s] 64%|██████▍   | 723/1130 [00:23<00:13, 29.17it/s] 64%|██████▍   | 726/1130 [00:23<00:14, 28.09it/s] 65%|██████▍   | 730/1130 [00:23<00:14, 28.33it/s] 65%|██████▍   | 734/1130 [00:23<00:12, 31.00it/s] 65%|██████▌   | 738/1130 [00:23<00:13, 30.15it/s] 66%|██████▌   | 742/1130 [00:23<00:13, 29.26it/s] 66%|██████▌   | 745/1130 [00:24<00:13, 28.32it/s] 66%|██████▋   | 749/1130 [00:24<00:14, 27.11it/s] 67%|██████▋   | 752/1130 [00:24<00:13, 27.68it/s] 67%|██████▋   | 756/1130 [00:24<00:12, 30.46it/s] 67%|██████▋   | 760/1130 [00:24<00:11, 32.86it/s] 68%|██████▊   | 764/1130 [00:24<00:11, 31.78it/s] 68%|██████▊   | 768/1130 [00:24<00:11, 31.64it/s] 68%|██████▊   | 772/1130 [00:24<00:11, 31.72it/s] 69%|██████▊   | 776/1130 [00:25<00:11, 31.43it/s] 69%|██████▉   | 780/1130 [00:25<00:11, 31.35it/s] 69%|██████▉   | 784/1130 [00:25<00:10, 31.88it/s] 70%|██████▉   | 788/1130 [00:25<00:11, 30.73it/s] 70%|███████   | 792/1130 [00:25<00:11, 29.52it/s] 70%|███████   | 796/1130 [00:25<00:11, 30.23it/s] 71%|███████   | 800/1130 [00:25<00:10, 30.93it/s] 71%|███████   | 805/1130 [00:25<00:09, 34.07it/s] 72%|███████▏  | 809/1130 [00:26<00:09, 34.52it/s] 72%|███████▏  | 813/1130 [00:26<00:09, 33.90it/s] 72%|███████▏  | 817/1130 [00:26<00:09, 32.32it/s] 73%|███████▎  | 821/1130 [00:26<00:09, 30.94it/s] 73%|███████▎  | 825/1130 [00:26<00:09, 31.19it/s] 73%|███████▎  | 829/1130 [00:26<00:09, 31.87it/s] 74%|███████▎  | 833/1130 [00:26<00:09, 31.40it/s] 74%|███████▍  | 837/1130 [00:26<00:09, 31.67it/s] 74%|███████▍  | 841/1130 [00:27<00:09, 30.08it/s] 75%|███████▍  | 845/1130 [00:27<00:09, 31.08it/s] 75%|███████▌  | 849/1130 [00:27<00:08, 31.64it/s] 75%|███████▌  | 853/1130 [00:27<00:09, 30.72it/s] 76%|███████▌  | 857/1130 [00:27<00:10, 27.23it/s] 76%|███████▋  | 863/1130 [00:27<00:07, 34.32it/s] 77%|███████▋  | 867/1130 [00:27<00:07, 33.80it/s] 77%|███████▋  | 872/1130 [00:28<00:07, 35.42it/s] 78%|███████▊  | 876/1130 [00:28<00:07, 33.46it/s] 78%|███████▊  | 880/1130 [00:28<00:07, 32.56it/s] 78%|███████▊  | 884/1130 [00:28<00:07, 32.08it/s] 79%|███████▊  | 889/1130 [00:28<00:06, 35.81it/s] 79%|███████▉  | 893/1130 [00:28<00:06, 34.38it/s] 79%|███████▉  | 897/1130 [00:28<00:06, 34.47it/s] 80%|███████▉  | 901/1130 [00:28<00:06, 34.43it/s] 80%|████████  | 905/1130 [00:29<00:06, 33.87it/s] 80%|████████  | 909/1130 [00:29<00:06, 34.22it/s] 81%|████████  | 913/1130 [00:29<00:06, 35.13it/s] 81%|████████  | 917/1130 [00:29<00:06, 34.82it/s] 82%|████████▏ | 921/1130 [00:29<00:06, 34.44it/s] 82%|████████▏ | 925/1130 [00:29<00:06, 31.41it/s] 82%|████████▏ | 929/1130 [00:29<00:06, 31.51it/s] 83%|████████▎ | 933/1130 [00:29<00:06, 31.20it/s] 83%|████████▎ | 937/1130 [00:30<00:06, 30.75it/s] 83%|████████▎ | 941/1130 [00:30<00:05, 31.51it/s] 84%|████████▎ | 945/1130 [00:30<00:05, 33.02it/s] 84%|████████▍ | 949/1130 [00:30<00:05, 31.73it/s] 84%|████████▍ | 953/1130 [00:30<00:05, 29.79it/s] 85%|████████▍ | 957/1130 [00:30<00:05, 30.14it/s] 85%|████████▌ | 961/1130 [00:30<00:05, 30.25it/s] 85%|████████▌ | 965/1130 [00:30<00:05, 31.36it/s] 86%|████████▌ | 969/1130 [00:31<00:05, 29.50it/s] 86%|████████▌ | 972/1130 [00:31<00:05, 29.36it/s] 86%|████████▋ | 976/1130 [00:31<00:05, 30.26it/s] 87%|████████▋ | 980/1130 [00:31<00:04, 30.33it/s] 87%|████████▋ | 984/1130 [00:31<00:04, 30.16it/s] 87%|████████▋ | 988/1130 [00:31<00:04, 30.28it/s] 88%|████████▊ | 992/1130 [00:31<00:04, 31.64it/s] 88%|████████▊ | 996/1130 [00:31<00:04, 29.91it/s] 88%|████████▊ | 1000/1130 [00:32<00:04, 29.32it/s] 89%|████████▉ | 1004/1130 [00:32<00:03, 31.57it/s] 89%|████████▉ | 1008/1130 [00:32<00:04, 29.33it/s] 90%|████████▉ | 1012/1130 [00:32<00:03, 30.29it/s] 90%|████████▉ | 1016/1130 [00:32<00:03, 31.07it/s] 90%|█████████ | 1021/1130 [00:32<00:03, 33.09it/s] 91%|█████████ | 1026/1130 [00:32<00:02, 34.69it/s] 91%|█████████ | 1030/1130 [00:32<00:02, 36.00it/s] 92%|█████████▏| 1034/1130 [00:33<00:02, 34.43it/s] 92%|█████████▏| 1038/1130 [00:33<00:02, 35.55it/s] 92%|█████████▏| 1042/1130 [00:33<00:02, 34.61it/s] 93%|█████████▎| 1047/1130 [00:33<00:02, 37.61it/s] 93%|█████████▎| 1051/1130 [00:33<00:02, 37.36it/s] 93%|█████████▎| 1055/1130 [00:33<00:02, 36.14it/s] 94%|█████████▍| 1060/1130 [00:33<00:01, 37.20it/s] 94%|█████████▍| 1064/1130 [00:33<00:01, 36.45it/s] 95%|█████████▍| 1068/1130 [00:34<00:01, 33.92it/s] 95%|█████████▍| 1073/1130 [00:34<00:01, 36.54it/s] 95%|█████████▌| 1077/1130 [00:34<00:01, 32.41it/s] 96%|█████████▌| 1081/1130 [00:34<00:01, 30.71it/s] 96%|█████████▌| 1085/1130 [00:34<00:01, 31.36it/s] 96%|█████████▋| 1089/1130 [00:34<00:01, 30.83it/s] 97%|█████████▋| 1093/1130 [00:34<00:01, 27.22it/s] 97%|█████████▋| 1097/1130 [00:35<00:01, 29.14it/s] 97%|█████████▋| 1101/1130 [00:35<00:00, 29.29it/s] 98%|█████████▊| 1105/1130 [00:35<00:00, 30.54it/s] 98%|█████████▊| 1109/1130 [00:35<00:00, 30.11it/s] 98%|█████████▊| 1113/1130 [00:35<00:00, 29.46it/s] 99%|█████████▉| 1116/1130 [00:35<00:00, 29.00it/s] 99%|█████████▉| 1120/1130 [00:35<00:00, 30.40it/s] 99%|█████████▉| 1124/1130 [00:35<00:00, 31.89it/s]100%|█████████▉| 1128/1130 [00:36<00:00, 32.44it/s]100%|██████████| 1130/1130 [00:36<00:00, 31.32it/s]
[COMBINE] Training data: concatenating features for the planes
[COMBINE] Fitting a Logistic Regression model
[COMBINE] Extracting predictions for task "meniscus" and plane "axial"
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[DATALOADER] __init__ task: meniscus, plane: axial, train: valid
[DATALOADER] __init__ weights: [1, 1.3076923076923077]
  0%|          | 0/120 [00:00<?, ?it/s]  2%|▎         | 3/120 [00:00<00:04, 26.10it/s]  6%|▌         | 7/120 [00:00<00:04, 25.58it/s]  9%|▉         | 11/120 [00:00<00:03, 27.89it/s] 12%|█▏        | 14/120 [00:00<00:04, 26.24it/s] 14%|█▍        | 17/120 [00:00<00:03, 25.99it/s] 18%|█▊        | 21/120 [00:00<00:03, 28.29it/s] 21%|██        | 25/120 [00:00<00:03, 28.61it/s] 23%|██▎       | 28/120 [00:01<00:03, 25.52it/s] 26%|██▌       | 31/120 [00:01<00:03, 26.00it/s] 28%|██▊       | 34/120 [00:01<00:03, 26.18it/s] 31%|███       | 37/120 [00:01<00:03, 25.70it/s] 34%|███▍      | 41/120 [00:01<00:02, 28.87it/s] 37%|███▋      | 44/120 [00:01<00:02, 26.82it/s] 39%|███▉      | 47/120 [00:01<00:02, 27.04it/s] 42%|████▎     | 51/120 [00:01<00:02, 27.49it/s] 45%|████▌     | 54/120 [00:02<00:02, 26.53it/s] 48%|████▊     | 58/120 [00:02<00:02, 28.72it/s] 52%|█████▎    | 63/120 [00:02<00:01, 29.55it/s] 55%|█████▌    | 66/120 [00:02<00:01, 27.50it/s] 58%|█████▊    | 70/120 [00:02<00:01, 28.68it/s] 62%|██████▏   | 74/120 [00:02<00:01, 29.15it/s] 64%|██████▍   | 77/120 [00:02<00:01, 27.99it/s] 68%|██████▊   | 82/120 [00:02<00:01, 29.32it/s] 71%|███████   | 85/120 [00:03<00:01, 25.82it/s] 73%|███████▎  | 88/120 [00:03<00:01, 26.19it/s] 77%|███████▋  | 92/120 [00:03<00:00, 28.30it/s] 79%|███████▉  | 95/120 [00:03<00:00, 28.05it/s] 82%|████████▏ | 98/120 [00:03<00:00, 27.12it/s] 85%|████████▌ | 102/120 [00:03<00:00, 26.59it/s] 88%|████████▊ | 105/120 [00:03<00:00, 25.25it/s] 90%|█████████ | 108/120 [00:04<00:00, 23.30it/s] 92%|█████████▎| 111/120 [00:04<00:00, 20.60it/s] 95%|█████████▌| 114/120 [00:04<00:00, 21.02it/s] 98%|█████████▊| 117/120 [00:04<00:00, 21.54it/s]100%|██████████| 120/120 [00:04<00:00, 26.22it/s]
[COMBINE] Extracting predictions for task "meniscus" and plane "coronal"
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[DATALOADER] __init__ task: meniscus, plane: coronal, train: valid
[DATALOADER] __init__ weights: [1, 1.3076923076923077]
  0%|          | 0/120 [00:00<?, ?it/s]  3%|▎         | 4/120 [00:00<00:03, 34.05it/s]  7%|▋         | 8/120 [00:00<00:03, 36.93it/s] 10%|█         | 12/120 [00:00<00:03, 34.17it/s] 13%|█▎        | 16/120 [00:00<00:03, 31.76it/s] 18%|█▊        | 21/120 [00:00<00:02, 36.96it/s] 21%|██        | 25/120 [00:00<00:02, 35.02it/s] 24%|██▍       | 29/120 [00:00<00:03, 29.18it/s] 28%|██▊       | 33/120 [00:01<00:02, 31.85it/s] 31%|███       | 37/120 [00:01<00:02, 32.80it/s] 34%|███▍      | 41/120 [00:01<00:02, 34.64it/s] 38%|███▊      | 45/120 [00:01<00:02, 33.92it/s] 42%|████▏     | 50/120 [00:01<00:01, 37.52it/s] 45%|████▌     | 54/120 [00:01<00:01, 34.17it/s] 48%|████▊     | 58/120 [00:01<00:01, 34.93it/s] 52%|█████▎    | 63/120 [00:01<00:01, 36.64it/s] 56%|█████▌    | 67/120 [00:01<00:01, 35.85it/s] 60%|██████    | 72/120 [00:02<00:01, 38.83it/s] 63%|██████▎   | 76/120 [00:02<00:01, 35.59it/s] 68%|██████▊   | 81/120 [00:02<00:01, 38.66it/s] 71%|███████   | 85/120 [00:02<00:00, 37.61it/s] 75%|███████▌  | 90/120 [00:02<00:00, 38.02it/s] 78%|███████▊  | 94/120 [00:02<00:00, 36.34it/s] 82%|████████▏ | 98/120 [00:02<00:00, 35.70it/s] 85%|████████▌ | 102/120 [00:02<00:00, 36.10it/s] 88%|████████▊ | 106/120 [00:03<00:00, 30.56it/s] 92%|█████████▏| 110/120 [00:03<00:00, 29.82it/s] 95%|█████████▌| 114/120 [00:03<00:00, 27.93it/s] 98%|█████████▊| 117/120 [00:03<00:00, 26.18it/s]100%|██████████| 120/120 [00:03<00:00, 26.03it/s]100%|██████████| 120/120 [00:03<00:00, 33.10it/s]
[COMBINE] Extracting predictions for task "meniscus" and plane "sagittal"
[CHOOSE] Getting model: pretrained-resnet18
[PRE-TRAINED RESNET] Number of features: 512
[DATALOADER] __init__ task: meniscus, plane: sagittal, train: valid
[DATALOADER] __init__ weights: [1, 1.3076923076923077]
  0%|          | 0/120 [00:00<?, ?it/s]  4%|▍         | 5/120 [00:00<00:02, 43.71it/s]  8%|▊         | 10/120 [00:00<00:02, 42.73it/s] 12%|█▎        | 15/120 [00:00<00:02, 36.84it/s] 16%|█▌        | 19/120 [00:00<00:02, 34.01it/s] 20%|██        | 24/120 [00:00<00:02, 37.31it/s] 23%|██▎       | 28/120 [00:00<00:02, 33.48it/s] 27%|██▋       | 32/120 [00:00<00:02, 32.66it/s] 30%|███       | 36/120 [00:01<00:02, 33.86it/s] 33%|███▎      | 40/120 [00:01<00:02, 35.36it/s] 37%|███▋      | 44/120 [00:01<00:02, 35.39it/s] 41%|████      | 49/120 [00:01<00:01, 36.42it/s] 44%|████▍     | 53/120 [00:01<00:01, 35.50it/s] 48%|████▊     | 58/120 [00:01<00:01, 36.94it/s] 52%|█████▎    | 63/120 [00:01<00:01, 37.51it/s] 56%|█████▌    | 67/120 [00:01<00:01, 33.36it/s] 59%|█████▉    | 71/120 [00:02<00:01, 34.50it/s] 62%|██████▎   | 75/120 [00:02<00:01, 32.15it/s] 66%|██████▌   | 79/120 [00:02<00:01, 31.24it/s] 69%|██████▉   | 83/120 [00:02<00:01, 33.15it/s] 72%|███████▎  | 87/120 [00:02<00:00, 33.28it/s] 76%|███████▌  | 91/120 [00:02<00:00, 34.64it/s] 79%|███████▉  | 95/120 [00:02<00:00, 32.87it/s] 82%|████████▎ | 99/120 [00:02<00:00, 34.57it/s] 86%|████████▌ | 103/120 [00:02<00:00, 34.20it/s] 89%|████████▉ | 107/120 [00:03<00:00, 33.57it/s] 92%|█████████▎| 111/120 [00:03<00:00, 31.30it/s] 96%|█████████▌| 115/120 [00:03<00:00, 27.75it/s] 98%|█████████▊| 118/120 [00:03<00:00, 28.03it/s]100%|██████████| 120/120 [00:03<00:00, 33.32it/s]
[COMBINE] Evaluating data: concatenating features for the planes
[COMBINE] Logistic Regression coefficients: 3.6812, 2.0500, 1.4444
[COMBINE] ## Val AUC for task "meniscus" is: 0.8654 ##
[COMBINE] Model "my-data/models/training/pretrained/clf_meniscus_val_auc_0.8654.joblib" saved
Copying model...!
Execution duration: 2.00 minutes 23.67 seconds
All training runs completed!
